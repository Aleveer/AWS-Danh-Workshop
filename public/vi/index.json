[
{
	"uri": "http://localhost:1313/workshop-template/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Anh Danh\nMã sinh viên: 3121410103\nSố điện thoại: 0384876891\nEmail: danhanh.nguyen1643@gmail.com\nNgành: Công nghệ thông tin\nLớp: AWS082025\nTrường: Đại học Sài Gòn\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 09/09/2025 đến ngày 09/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Caching ngoại tuyến với AWS Amplify, Tanstack, AppSync và MongoDB Atlas Trong blog này, chúng tôi trình bày cách tạo một ứng dụng offline-first với giao diện người dùng lạc quan (optimistic UI) sử dụng AWS Amplify, AWS AppSync, và MongoDB Atlas. Các nhà phát triển thiết kế ứng dụng offline-first để hoạt động mà không cần kết nối internet đang hoạt động. Optimistic UI sau đó được xây dựng trên nền tảng phương pháp offline-first bằng cách cập nhật giao diện người dùng với những thay đổi dữ liệu dự kiến, mà không phụ thuộc vào phản hồi từ máy chủ. Phương pháp này thường sử dụng chiến lược cache cục bộ.\nCác ứng dụng sử dụng offline-first với optimistic UI mang lại nhiều cải tiến cho người dùng. Những cải tiến này bao gồm giảm nhu cầu triển khai màn hình tải, hiệu suất tốt hơn do truy cập dữ liệu nhanh hơn, độ tin cậy của dữ liệu khi ứng dụng ngoại tuyến, và hiệu quả chi phí. Mặc dù việc triển khai khả năng offline thủ công có thể tốn nhiều công sức, bạn có thể sử dụng các công cụ đơn giản hóa quá trình này.\nChúng tôi cung cấp một ứng dụng mẫu to-do hiển thị kết quả của các thao tác CRUD MongoDB Atlas ngay lập tức trên giao diện người dùng trước khi vòng lặp yêu cầu hoàn tất, cải thiện trải nghiệm người dùng. Nói cách khác, chúng tôi triển khai optimistic UI giúp dễ dàng hiển thị trạng thái tải và lỗi, đồng thời cho phép các nhà phát triển hoàn tác các thay đổi trên giao diện người dùng khi các lời gọi API không thành công. Việc triển khai tận dụng TanStack Query để xử lý các cập nhật optimistic UI cùng với AWS Amplify. Biểu đồ trong Hình 1 minh họa sự tương tác giữa giao diện người dùng và backend.\nTanStack Query là một thư viện quản lý trạng thái bất đồng bộ cho TypeScript/JavaScript, React, Solid, Vue, Svelte, và Angular. Nó đơn giản hóa việc tìm nạp, caching, đồng bộ hóa và cập nhật trạng thái máy chủ trong các ứng dụng web. Bằng cách tận dụng các cơ chế caching của TanStack Query, ứng dụng đảm bảo tính khả dụng của dữ liệu ngay cả khi không có kết nối mạng đang hoạt động. AWS Amplify đơn giản hóa quá trình phát triển, trong khi AWS AppSync cung cấp một lớp API GraphQL mạnh mẽ, và MongoDB Atlas cung cấp giải pháp cơ sở dữ liệu có thể mở rộng. Sự tích hợp này cho thấy cách caching ngoại tuyến của TanStack Query có thể được sử dụng hiệu quả trong kiến trúc ứng dụng full-stack.\nHình 1. Biểu đồ Tương tác\nỨng dụng mẫu triển khai chức năng to-do cổ điển và kiến trúc ứng dụng chính xác được hiển thị trong Hình 2. Stack bao gồm:\nMongoDB Atlas cho các dịch vụ cơ sở dữ liệu. AWS Amplify framework ứng dụng full-stack. AWS AppSync để quản lý API GraphQL. AWS Lambda Resolver cho điện toán serverless. Amazon Cognito để quản lý người dùng và xác thực. Hình 2. Kiến trúc\nTriển khai Ứng dụng Để triển khai ứng dụng trong tài khoản AWS của bạn, hãy làm theo các bước bên dưới. Sau khi triển khai, bạn có thể tạo người dùng, xác thực bản thân và tạo các mục to-do – xem Hình 8.\nThiết lập cluster MongoDB Atlas Làm theo liên kết để thiết lập cluster MongoDB Atlas, Cơ sở dữ liệu, Người dùng và Truy cập mạng\nThiết lập người dùng\nCấu hình Người dùng\nClone Repository GitHub Clone ứng dụng mẫu với lệnh sau git clone https://github.com/mongodb-partners/amplify-mongodb-tanstack-offline\nThiết lập thông tin xác thực AWS CLI (tùy chọn nếu bạn cần debug ứng dụng cục bộ) Nếu bạn muốn kiểm tra ứng dụng cục bộ bằng môi trường sandbox, bạn có thể thiết lập thông tin xác thực AWS tạm thời cục bộ: export AWS_ACCESS_KEY_ID=\rexport AWS_SECRET_ACCESS_KEY=\rexport AWS_SESSION_TOKEN= Triển khai Ứng dụng Todo trong AWS Amplify Mở console AWS Amplify và Chọn tùy chọn Github Hình 3. Chọn tùy chọn Github\nCấu hình Repository GitHub Hình 4. Cấu hình quyền repository\nChọn Repository GitHub và nhấp Next Hình 5. Chọn repository và branch\nĐặt tất cả các tùy chọn khác thành mặc định và triển khai Hình 6. Triển khai ứng dụng\nCấu hình Biến Môi trường Cấu hình các biến môi trường sau khi triển khai thành công\nHình 7. Cấu hình biến môi trường\nMở ứng dụng và kiểm tra Mở ứng dụng thông qua URL được cung cấp và kiểm tra ứng dụng.\nHình 8. Các mục todo mẫu\nKết quả MongoDB Atlas\nHình 9. Dữ liệu trong Mongo\nXem xét Ứng dụng Bây giờ ứng dụng đã được triển khai, hãy thảo luận về những gì xảy ra bên dưới và những gì đã được cấu hình cho chúng ta. Chúng tôi đã sử dụng quy trình làm việc dựa trên git của Amplify để lưu trữ ứng dụng web full-stack, serverless với triển khai liên tục. Amplify hỗ trợ nhiều framework khác nhau, bao gồm các framework server side rendered (SSR) như Next.js và Nuxt, các framework single page application (SPA) như React và Angular, và các trình tạo trang tĩnh (SSG) như Gatsby và Hugo. Trong trường hợp này, chúng tôi đã triển khai một ứng dụng dựa trên React SPA. Chúng ta có thể bao gồm các nhánh tính năng, tên miền tùy chỉnh, xem trước pull request, kiểm tra end-to-end, và chuyển hướng/viết lại. Amplify Hosting cung cấp quy trình làm việc dựa trên Git cho phép triển khai nguyên tử đảm bảo rằng các cập nhật chỉ được áp dụng sau khi toàn bộ triển khai hoàn tất.\nĐể triển khai ứng dụng của chúng tôi, chúng tôi đã sử dụng AWS Amplify Gen 2, đây là một công cụ được thiết kế để đơn giản hóa việc phát triển và triển khai các ứng dụng full-stack bằng TypeScript. Nó tận dụng AWS Cloud Development Kit (CDK) để quản lý tài nguyên đám mây, đảm bảo khả năng mở rộng và dễ sử dụng.\nTrước khi kết luận, điều quan trọng là hiểu tính đồng thời cập nhật của ứng dụng chúng ta. Chúng tôi đã triển khai một cơ chế giải quyết xung đột đơn giản optimistic first-come first-served. Cluster MongoDB Atlas lưu trữ các cập nhật theo thứ tự nó nhận được chúng. Trong trường hợp có xung đột cập nhật, cập nhật đến sau cùng sẽ ghi đè các cập nhật trước đó. Cơ chế này hoạt động tốt trong các ứng dụng nơi xung đột cập nhật hiếm khi xảy ra. Điều quan trọng là đánh giá cách này có thể hoặc không thể phù hợp với nhu cầu sản xuất của bạn, yêu cầu các phương pháp phức tạp hơn. TanStack cung cấp khả năng cho các cơ chế phức tạp hơn để xử lý các kịch bản kết nối khác nhau. Theo mặc định, TanStack Query cung cấp chế độ mạng \u0026ldquo;online\u0026rdquo;, nơi Queries và Mutations sẽ không được kích hoạt trừ khi bạn có kết nối mạng. Nếu một query chạy vì bạn đang online, nhưng bạn ngoại tuyến trong khi fetch vẫn đang diễn ra, TanStack Query cũng sẽ tạm dừng cơ chế thử lại. Các query bị tạm dừng sau đó sẽ tiếp tục chạy một khi bạn lấy lại kết nối mạng. Để cập nhật optimistic UI với các giá trị mới hoặc đã thay đổi, chúng ta cũng có thể cập nhật cache cục bộ với những gì chúng ta mong đợi phản hồi sẽ là. Phương pháp này hoạt động tốt cùng với chế độ mạng \u0026ldquo;online\u0026rdquo; của TanStack, nơi nếu ứng dụng không có kết nối mạng, các mutations sẽ không được kích hoạt, nhưng sẽ được thêm vào hàng đợi, nhưng cache cục bộ của chúng ta có thể được sử dụng để cập nhật UI. Dưới đây là một ví dụ chính về cách ứng dụng mẫu của chúng tôi cập nhật optimistic UI với mutation dự kiến.\nconst createMutation = useMutation({\rmutationFn: async (input: { content: string }) =\u0026gt; {\r// Sử dụng client Amplify để thực hiện yêu cầu đến AppSync\rconst { data } = await amplifyClient.mutations.addTodo(input);\rreturn data;\r},\r// Khi mutate được gọi:\ronMutate: async (newTodo) =\u0026gt; {\r// Hủy bỏ bất kỳ refetch nào đang diễn ra\r// để chúng không ghi đè cập nhật optimistic của chúng ta\rawait tanstackClient.cancelQueries({ queryKey: [\u0026#34;listTodo\u0026#34;] });\r// Chụp ảnh giá trị trước đó\rconst previousTodoList = tanstackClient.getQueryData([\u0026#34;listTodo\u0026#34;]);\r// Cập nhật optimistic với giá trị mới\rif (previousTodoList) {\rtanstackClient.setQueryData([\u0026#34;listTodo\u0026#34;], (old: Todo[]) =\u0026gt; [\r...old,\rnewTodo,\r]);\r}\r// Trả về một đối tượng context với giá trị đã chụp ảnh\rreturn { previousTodoList };\r},\r// Nếu mutation thất bại,\r// sử dụng context được trả về từ onMutate để hoàn tác\ronError: (err, newTodo, context) =\u0026gt; {\rconsole.error(\u0026#34;Error saving record:\u0026#34;, err, newTodo);\rif (context?.previousTodoList) {\rtanstackClient.setQueryData([\u0026#34;listTodo\u0026#34;], context.previousTodoList);\r}\r},\r// Luôn refetch sau lỗi hoặc thành công:\ronSettled: () =\u0026gt; {\rtanstackClient.invalidateQueries({ queryKey: [\u0026#34;listTodo\u0026#34;] });\r},\ronSuccess: () =\u0026gt; {\rtanstackClient.invalidateQueries({ queryKey: [\u0026#34;listTodo\u0026#34;] });\r},\r}); Chúng tôi hoan nghênh mọi PR triển khai các chiến lược giải quyết xung đột bổ sung.\nThử MongoDB Atlas trên AWS MarketPlace. Làm quen với AWS Amplify, Amplify Gen2 và AppSync. Để có hướng dẫn chi tiết về việc triển khai ứng dụng, tham khảo phần triển khai trong tài liệu của chúng tôi. Gửi PR với các cải tiến của bạn. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Giới thiệu các cuộc họp cộng đồng AWS CDK Chúng tôi rất vui mừng thông báo về chuỗi cuộc họp cộng đồng mới của chúng tôi cho dự án AWS Cloud Development Kit (CDK). Những cuộc họp này được thiết kế để mang lại cho mọi người, từ những người đóng góp có kinh nghiệm đến người dùng mới, một cơ hội định kỳ để học hỏi, đặt câu hỏi và chia sẻ phản hồi trực tiếp với nhóm AWS CDK. Chúng tôi cũng coi đây là một cơ hội tuyệt vời để tương tác với các thành viên khác trong cộng đồng AWS CDK.\nTại sao lại là các cuộc họp cộng đồng? Ban đầu, chúng tôi đã cân nhắc việc thành lập một mô hình quản trị chính thức hơn được gọi là \u0026ldquo;Hội đồng đóng góp\u0026rdquo;, nhưng đã quyết định chuyển sang một định dạng ít chính thức hơn, cởi mở và dễ tiếp cận hơn vì một số lý do:\nTính bao trùm rộng rãi hơn: Chúng tôi muốn khuyến khích sự tham gia từ tất cả các nhà phát triển quan tâm, không chỉ một nhóm nhỏ. Tương tác đơn giản hơn: Một cuộc họp ảo cho phép bất kỳ ai trong cộng đồng tham dự, đặt câu hỏi và cung cấp phản hồi mà không cần chính thức hóa các cấu trúc sở hữu hoặc quản trị. Bằng cách tổ chức các cuộc họp cộng đồng ảo, chúng tôi có thể tiếp tục cung cấp tính minh bạch và hợp tác mà cộng đồng đánh giá cao trong khi vẫn giữ được tính linh hoạt để đưa ra quyết định và thúc đẩy dự án tiến lên với AWS với tư cách là người duy trì dự án. Chúng tôi tin rằng đây là cách tốt nhất để tương tác với cộng đồng của chúng tôi một cách có ý nghĩa.\nChúng ta có thể gặp nhau thường xuyên như thế nào? Để đảm bảo chúng tôi sử dụng tốt nhất thời gian của mọi người, chúng tôi dự định gặp nhau hai lần mỗi quý. Tuy nhiên, lịch trình này có thể bị ảnh hưởng bởi các sự kiện đang diễn ra và các ngày lễ, vì vậy chúng tôi sẽ công bố ngày của cuộc họp tiếp theo cùng với chương trình nghị sự trong các vấn đề GitHub được đánh dấu \u0026ldquo;[Community Meeting] – Ngày họp\u0026rdquo;.\nNhững gì mong đợi Chúng tôi dự định bao gồm một hỗn hợp các chủ đề sau dựa trên sự quan tâm và tính liên quan:\nCập nhật lộ trình: Xem trước các tính năng sắp tới, cải tiến và ưu tiên dự án. Demo của nhóm: Các kỹ sư của chúng tôi sẽ trình diễn các chức năng mới hoặc các phương pháp hay nhất trong thực tế. Đánh giá RFC \u0026amp; Tầm nhìn/Tính năng: Cung cấp đầu vào trực tiếp về các tính năng được đề xuất hoặc hướng đi cho dự án AWS CDK. Hỏi đáp mở: Một cơ hội để bạn đặt câu hỏi trực tiếp với nhóm AWS CDK và các thành viên cộng đồng khác. Chủ đề \u0026amp; Phiên tương lai: Các sự kiện bổ sung như các phiên do cộng đồng dẫn dắt hoặc giờ làm việc có thể được giới thiệu dựa trên sự quan tâm. Tất cả các phiên sẽ được ghi lại và chia sẻ trên YouTube, đảm bảo rằng bất kỳ ai không thể tham dự trực tiếp vẫn có thể theo dõi. Chúng tôi cũng sẽ theo dõi các chương trình nghị sự và ghi chú trong các vấn đề GitHub được đánh dấu \u0026ldquo;[Community Meeting] – 6/24/25\u0026rdquo;, để bạn có thể dễ dàng theo dõi các điểm nổi bật của cuộc họp. Nếu bạn có bất kỳ câu hỏi hoặc chủ đề nào mà bạn muốn được đề cập trong cuộc họp, vui lòng thêm nhận xét vào vấn đề cho cuộc họp sắp tới.\nPhiên đầu tiên: 24 tháng 6, 2025, 8:00 – 9:00 PDT / 24 tháng 6, 2025, 17:00 – 18:00 PDT Để hỗ trợ cộng đồng toàn cầu của chúng tôi, chúng tôi sẽ có hai phiên vào ngày 24 tháng 6 – cuộc họp đầu tiên sẽ diễn ra lúc 8:00 PDT (tệp .ics), tiếp theo là phiên thứ hai lúc 17:00 PDT (tệp .ics). Chúng tôi sẽ chia sẻ chi tiết cuộc họp, bao gồm hướng dẫn tham gia, trong Không gian làm việc Slack cdk.dev và trên các vấn đề CDK GitHub được đánh dấu \u0026ldquo;[Community Meeting] – 6/24/25\u0026rdquo; trước đó.\nCách bạn có thể tham gia Đánh dấu lịch của bạn: Lưu ngày cho 24 tháng 6, 2025, 8:00 – 9:00 PDT HOẶC 17:00 – 18:00 PDT, và tìm kiếm liên kết cuộc họp của chúng tôi. Tham gia với chúng tôi trên Slack: Để biết thêm thông tin và cập nhật về các cuộc họp cộng đồng sắp tới, hãy tham gia kênh #community-meetings trong Không gian làm việc Slack cdk.dev. Tham gia phiên trực tiếp: Mang theo bất kỳ câu hỏi hoặc phản hồi nào bạn có về phát triển, sử dụng hoặc lộ trình AWS CDK. Cập nhật qua GitHub: Kiểm tra các vấn đề GitHub của chúng tôi được đánh dấu [Community Meeting] – \u0026ldquo;Ngày\u0026rdquo;, để biết chương trình nghị sự và ghi chú cuộc họp. Xem các bản ghi: Nếu bạn không thể tham dự sự kiện trực tiếp, hãy xem các bản ghi YouTube vào thời gian thuận tiện của bạn. Nhận xét với câu hỏi hoặc chủ đề: Thêm nhận xét vào vấn đề GitHub cho cuộc họp sắp tới với bất kỳ câu hỏi hoặc chủ đề nào bạn muốn chúng tôi đề cập. Tại sao điều này quan trọng Nhóm AWS CDK vẫn cam kết thúc đẩy dự án tiến lên và duy trì quyền sở hữu, đồng thời tiếp tục làm việc công khai với cộng đồng. Chúng tôi đánh giá cao đầu vào và quan điểm từ cộng đồng vì chúng rất quan trọng để định hình tương lai của AWS CDK. Những cuộc họp này cung cấp một diễn đàn định kỳ cho mọi người trong cộng đồng để có tiếng nói của họ được lắng nghe một cách trực tiếp và tương tác, vượt ra ngoài các con đường truyền thống như các vấn đề GitHub hoặc pull requests.\nTham gia khảo sát của chúng tôi Như một phần trong cam kết của chúng tôi để xây dựng một cộng đồng mạnh mẽ và thịnh vượng xung quanh AWS CDK, chúng tôi muốn nghe từ bạn! Trong suốt năm, chúng tôi sẽ gửi các cuộc khảo sát định kỳ để có thêm hiểu biết về những gì đang hoạt động và nơi chúng tôi có thể cải thiện. Cuộc khảo sát đầu tiên của chúng tôi bắt đầu với blog này và sẽ kết thúc vào ngày 1 tháng 7, 2025.\nTham gia khảo sát ngay bây giờ\nVui lòng lưu ngày (24 tháng 6, 2025 @ 8:00 – 9:00 PDT HOẶC 17:00 – 18:00 PDT) và lên kế hoạch tham gia với chúng tôi cho cuộc họp cộng đồng AWS CDK đầu tiên. Nếu bạn có ý tưởng cho các mục chương trình nghị sự hoặc muốn chia sẻ một demo, hãy tự do đề xuất chúng trên vấn đề GitHub cho cuộc họp sắp tới. Chúng tôi mong muốn kết nối với bạn, trả lời câu hỏi của bạn và làm việc cùng nhau để làm cho AWS CDK trở nên tốt hơn.\nHẹn gặp lại bạn!\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Bảo mật API ứng dụng Express trong 5 phút với Cedar Hôm nay, dự án mã nguồn mở Cedar đã công bố phiên bản authorization-for-expressjs, một gói mã nguồn mở giúp đơn giản hóa việc sử dụng ngôn ngữ chính sách Cedar và công cụ phân quyền để xác minh quyền truy cập ứng dụng. Phiên bản này cho phép các nhà phát triển thêm phân quyền dựa trên chính sách vào API framework web Express của họ trong vài phút, và không cần thực hiện bất kỳ cuộc gọi dịch vụ từ xa nào.\nExpress là một framework ứng dụng web Node.js tối giản và linh hoạt cung cấp một bộ tính năng mạnh mẽ cho các ứng dụng web và di động. Tích hợp chuẩn hóa này với Cedar yêu cầu ít hơn 90% mã so với việc các nhà phát triển tự viết các mẫu tích hợp, giúp tiết kiệm thời gian và công sức cho các nhà phát triển và cải thiện tư thế bảo mật ứng dụng bằng cách giảm lượng mã tích hợp tùy chỉnh.\nVí dụ, nếu bạn đang xây dựng một ứng dụng cửa hàng thú cưng sử dụng framework Express, sử dụng tính năng authorization-for-expressjs bạn có thể tạo các chính sách phân quyền để chỉ nhân viên cửa hàng mới có thể truy cập API để thêm thú cưng. Triển khai chuẩn hóa này cho middleware phân quyền Express thay thế nhu cầu về mã tùy chỉnh và tự động ánh xạ các yêu cầu khách hàng thành các thành phần principal, action và resource của chúng, sau đó thành các yêu cầu phân quyền Cedar.\nTại sao nên tách biệt phân quyền với Cedar? Truyền thống, các nhà phát triển triển khai phân quyền trong ứng dụng của họ bằng cách nhúng logic phân quyền trực tiếp vào mã ứng dụng. Logic phân quyền được nhúng này được thiết kế để hỗ trợ một vài quyền, nhưng khi ứng dụng phát triển, thường có nhu cầu hỗ trợ các trường hợp sử dụng phức tạp hơn với các yêu cầu phân quyền bổ sung. Các nhà phát triển cập nhật từng bước logic phân quyền được nhúng để hỗ trợ các trường hợp sử dụng phức tạp này, dẫn đến mã phức tạp và khó bảo trì. Khi độ phức tạp của mã tăng lên, việc phát triển thêm mô hình bảo mật và thực hiện kiểm toán quyền trở nên khó khăn hơn, dẫn đến một ứng dụng liên tục trở nên khó bảo trì hơn trong suốt vòng đời của nó.\nCedar cho phép bạn tách biệt logic phân quyền khỏi ứng dụng của bạn. Việc tách biệt phân quyền khỏi mã ứng dụng mang lại nhiều lợi ích bao gồm giải phóng các nhóm phát triển để tập trung vào logic ứng dụng và đơn giản hóa việc kiểm toán ứng dụng và truy cập tài nguyên. Cedar là một ngôn ngữ mã nguồn mở và bộ công cụ phát triển phần mềm (SDK) để viết và thực thi các chính sách phân quyền cho ứng dụng của bạn. Bạn chỉ định các quyền chi tiết như các chính sách Cedar, và ứng dụng của bạn phân quyền các yêu cầu truy cập bằng cách gọi Cedar SDK. Ví dụ, bạn có thể sử dụng chính sách Cedar bên dưới để cho phép người dùng nhân viên gọi API POST /pets trong ứng dụng PetStore mẫu.\npermit (\rprincipal,\raction in [Action::\u0026#34;POST /pets\u0026#34;], resource\r) when {\rprincipal.jobLevel = \u0026#34;employee\u0026#34;\r}; Một thách thức tiềm ẩn trong việc áp dụng Cedar có thể là nỗ lực ban đầu cần thiết để định nghĩa các chính sách Cedar và cập nhật mã ứng dụng của bạn để gọi Cedar SDK để phân quyền các yêu cầu API. Bài đăng blog này cho thấy cách các nhà phát triển ứng dụng web sử dụng framework Express có thể dễ dàng triển khai phân quyền cấp API với Cedar—chỉ thêm vài chục dòng mã trong ứng dụng của bạn, thay vì hàng trăm dòng.\nHướng dẫn từng bước này sử dụng ứng dụng PetStore mẫu để cho thấy cách truy cập vào API có thể được hạn chế dựa trên các nhóm người dùng. Bạn có thể tìm thấy ứng dụng Pet Store mẫu trong kho lưu trữ cedar-policy trên GitHub.\nTổng quan API ứng dụng Pet Store Ứng dụng PetStore được sử dụng để quản lý một cửa hàng thú cưng. Cửa hàng thú cưng được xây dựng bằng Express trên Node.js và expose các API sau:\nGET /pets – trả về một trang các thú cưng có sẵn trong PetStore. POST /pets – thêm thú cưng được chỉ định vào PetStore. GET /pets/{petId} – trả về thú cưng được chỉ định tìm thấy trong PetStore. POST /pets/{petId}/sale – đánh dấu một thú cưng là đã bán. Ứng dụng này không cho phép tất cả người dùng truy cập tất cả API. Thay vào đó, nó thực thi các quy tắc sau:\nCả người dùng khách hàng và nhân viên đều được phép thực hiện các thao tác đọc.\nGET /pets\nGET /pets/{petId}\nChỉ nhân viên mới được phép thực hiện các thao tác ghi.\nPOST /pets\nPOST /pets/{petId}/sale\nTriển khai phân quyền cho API Pet Store Hãy cùng đi qua cách bảo mật API ứng dụng của bạn bằng Cedar sử dụng gói mới cho Express. Ứng dụng ban đầu, không có phân quyền, có thể được tìm thấy trong thư mục start; sử dụng cái này để theo dõi cùng với blog. Bạn có thể tìm thấy ứng dụng hoàn chỉnh, với phân quyền đã được thêm vào, trong thư mục finish.\nThêm gói Cedar Authorization Middleware Gói Cedar Authorization Middleware sẽ được sử dụng để tạo schema Cedar, tạo các chính sách phân quyền mẫu và thực hiện phân quyền trong ứng dụng của bạn.\nChạy lệnh npm này để thêm dependency @cedar-policy/authorization-for-expressjs vào ứng dụng của bạn.\nnpm i --save @cedar-policy/authorization-for-expressjs Tạo Schema Cedar từ API của bạn Schema Cedar định nghĩa mô hình phân quyền cho một ứng dụng, bao gồm các loại thực thể trong ứng dụng và các hành động mà người dùng được phép thực hiện. Các chính sách của bạn được xác thực với schema này khi bạn chạy ứng dụng.\nGói authorization-for-expressjs có thể phân tích đặc tả OpenAPI của ứng dụng của bạn và tạo schema Cedar. Cụ thể, đối tượng paths là bắt buộc trong đặc tả của bạn.\nLưu ý: Nếu bạn không có đặc tả OpenAPI, bạn có thể tạo một cái bằng công cụ bạn chọn. Có một số thư viện mã nguồn mở để làm điều này cho Express; bạn có thể cần thêm một số mã vào ứng dụng của bạn, tạo đặc tả OpenAPI, và sau đó xóa mã đó. Ngoài ra, một số công cụ dựa trên AI sinh tạo như CLI Amazon Q Developer rất hiệu quả trong việc tạo các tài liệu đặc tả OpenAPI. Bất kể bạn tạo đặc tả như thế nào, hãy đảm bảo xác thực đầu ra chính xác từ công cụ.\nĐối với ứng dụng mẫu, một tài liệu đặc tả OpenAPI có tên openapi.json đã được bao gồm.\nVới đặc tả OpenAPI, bạn có thể tạo schema Cedar bằng cách chạy lệnh generateSchema được liệt kê ở đây.\n// schema được lưu trữ trong file v4.cedarschema.json trong root của package.\rnpx @cedar-policy/authorization-for-expressjs generate-schema --api-spec openapi.json --namespace PetStoreApp --mapping-type SimpleRest Định nghĩa các chính sách phân quyền Nếu không có chính sách nào được cấu hình, Cedar sẽ từ chối tất cả các yêu cầu phân quyền. Chúng ta sẽ thêm các chính sách cấp quyền truy cập vào API chỉ trong các nhóm người dùng được ủy quyền.\nChạy lệnh này để tạo các chính sách Cedar mẫu. Sau đó bạn có thể tùy chỉnh các chính sách này dựa trên trường hợp sử dụng của bạn.\nnpx @cedar-policy/authorization-for-expressjs generate-policies --schema v4.cedarschema.json Trong ứng dụng PetStore, hai chính sách mẫu được tạo, policy_1.cedar và policy_2.cedar.\npolicy_1.cedar cung cấp quyền cho người dùng trong nhóm người dùng admin để thực hiện bất kỳ hành động nào trên bất kỳ tài nguyên nào.\n// policy_1.cedar\r// Cho phép nhóm người dùng admin truy cập mọi thứ\rpermit (\rprincipal in PetStoreApp::UserGroup::\u0026#34;admin\u0026#34;,\raction,\rresource\r); policy_2.cedar cung cấp quyền truy cập chi tiết hơn cho tất cả các hành động riêng lẻ được định nghĩa trong schema Cedar với một placeholder cho một nhóm cụ thể.\n// policy_2.cedar\r// Cho phép kiểm soát nhóm người dùng chi tiết hơn, thay đổi hành động theo nhu cầu\rpermit (\rprincipal in PetStoreApp::UserGroup::\u0026#34;ENTER_THE_USER_GROUP_HERE\u0026#34;,\raction in\r[PetStoreApp::Action::\u0026#34;GET /pets\u0026#34;,\rPetStoreApp::Action::\u0026#34;POST /pets\u0026#34;,\rPetStoreApp::Action::\u0026#34;GET /pets/{petId}\u0026#34;,\rPetStoreApp::Action::\u0026#34;POST /pets/{petId}/sale\u0026#34;],\rresource\r); Lưu ý rằng nếu bạn chỉ định một operationId trong đặc tả OpenAPI, tên hành động được định nghĩa trong Schema Cedar sẽ sử dụng operationId đó thay vì định dạng mặc định \u0026ldquo; /\u0026rdquo;. Trong trường hợp này, đảm bảo việc đặt tên Actions trong Chính sách Cedar của bạn khớp với việc đặt tên Actions trong Schema Cedar của bạn.\nVí dụ, nếu bạn muốn gọi hành động của bạn là AddPet thay vì POST /pets, bạn có thể đặt operationId trong đặc tả OpenAPI của bạn thành AddPet. Hành động kết quả trong chính sách Cedar sẽ là PetStoreApp::Action::\u0026quot;AddPet\u0026quot;\nVì chúng ta không có người dùng admin trong trường hợp sử dụng của chúng ta, chúng ta có thể chỉ thay thế nội dung của policy_1.cedar bằng các chính sách được sử dụng cho nhóm người dùng customer.\nTrong trường hợp sử dụng thực tế, hãy cân nhắc đổi tên các file chính sách Cedar của bạn dựa trên nội dung của chúng. Ví dụ, allow_customer_group.cedar\n// policy_1.cedar\r// Cho phép nhóm người dùng customer truy cập getAllPets và getPetById\rpermit (\rprincipal in PetStoreApp::UserGroup::\u0026#34;customer\u0026#34;,\raction in\r[PetStoreApp::Action::\u0026#34;GET /pets\u0026#34;,\rPetStoreApp::Action::\u0026#34;GET /pets/{petId}\u0026#34;],\rresource\r); Người dùng employee có quyền truy cập tất cả các thao tác API. Chúng ta có thể chỉ cần thêm nhóm employee vào file policy_2.cedar để đáp ứng các yêu cầu phân quyền cho người dùng employee.\n// policy_2.cedar\r// Cho phép nhóm người dùng employee truy cập tất cả các hành động API\rpermit (\rprincipal in PetStoreApp::UserGroup::\u0026#34;employee\u0026#34;,\raction in\r[PetStoreApp::Action::\u0026#34;GET /pets\u0026#34;,\rPetStoreApp::Action::\u0026#34;POST /pets\u0026#34;,\rPetStoreApp::Action::\u0026#34;GET /pets/{petId}\u0026#34;,\rPetStoreApp::Action::\u0026#34;POST /pets/{petId}/sale\u0026#34;],\rresource\r); Lưu ý: Đối với các ứng dụng lớn với các chính sách phân quyền phức tạp, có thể khó khăn để phân tích và kiểm toán các quyền thực tế được cung cấp bởi nhiều chính sách khác nhau. Chúng tôi cũng gần đây đã mã nguồn mở Cedar Analysis CLI để giúp các nhà phát triển thực hiện phân tích chính sách trên các chính sách của họ. Bạn có thể tìm hiểu thêm về công cụ mới này trong bài đăng blog Introducing Cedar Analysis: Open Source Tools for Verifying Authorization Policies.\nCập nhật mã ứng dụng để gọi Cedar và phân quyền truy cập API Ứng dụng sẽ sử dụng middleware Cedar để phân quyền mọi yêu cầu với các chính sách Cedar. Trước đó chúng ta đã cài đặt dependency, bây giờ chúng ta cần cập nhật mã.\nĐầu tiên thêm gói vào dự án và định nghĩa CedarInlineAuthorizationEngine và ExpressAuthorizationMiddleware. Khối mã này có thể được thêm vào đầu file app.js.\nconst { ExpressAuthorizationMiddleware, CedarInlineAuthorizationEngine } = require (\u0026#39;@cedar-policy/authorization-for-expressjs\u0026#39;);\rconst policies = [\rfs.readFileSync(path.join(__dirname, \u0026#39;policies\u0026#39;, \u0026#39;policy_1.cedar\u0026#39;), \u0026#39;utf8\u0026#39;),\rfs.readFileSync(path.join(__dirname, \u0026#39;policies\u0026#39;, \u0026#39;policy_2.cedar\u0026#39;), \u0026#39;utf8\u0026#39;)\r];\rconst cedarAuthorizationEngine = new CedarInlineAuthorizationEngine({\rstaticPolicies: policies.join(\u0026#39;\\n\u0026#39;),\rschema: {\rtype: \u0026#39;jsonString\u0026#39;,\rschema: fs.readFileSync(path.join(__dirname, \u0026#39;v4.cedarschema.json\u0026#39;), \u0026#39;utf8\u0026#39;),\r}\r});\rconst expressAuthorization = new ExpressAuthorizationMiddleware({\rschema: {\rtype: \u0026#39;jsonString\u0026#39;,\rschema: fs.readFileSync(path.join(__dirname, \u0026#39;v4.cedarschema.json\u0026#39;), \u0026#39;utf8\u0026#39;),\r},\rauthorizationEngine: cedarAuthorizationEngine,\rprincipalConfiguration: {\rtype: \u0026#39;custom\u0026#39;,\rgetPrincipalEntity: principalEntityFetcher\r},\rskippedEndpoints: [\r{httpVerb: \u0026#39;get\u0026#39;, path: \u0026#39;/login\u0026#39;},\r{httpVerb: \u0026#39;get\u0026#39;, path: \u0026#39;/api-spec/v3\u0026#39;},\r],\rlogger: {\rdebug: s =\u0026gt; console.log(s),\rlog: s =\u0026gt; console.log(s),\r}\r}); Tiếp theo thêm middleware Express Authorization vào ứng dụng\nconst app = express();\rapp.use(express.json());\rapp.use(verifyToken()) // xác thực token người dùng\r// ... các middleware pre-authz khác\rapp.use(expressAuthorization.middleware);\r// ... các middleware pre-authz khác Thêm mã ứng dụng để cấu hình người dùng Công cụ phân quyền Cedar yêu cầu các nhóm người dùng và thuộc tính để phân quyền các yêu cầu. Middleware phân quyền dựa vào hàm được truyền cho getPrincipalEntity trong cấu hình ban đầu để tạo thực thể principal. Bạn cần triển khai hàm này để tạo thực thể người dùng.\nMã ví dụ này cung cấp một hàm để tạo thực thể người dùng. Nó giả định rằng người dùng đã được xác thực bởi một middleware trước đó và thông tin liên quan được lưu trữ trong đối tượng request. Nó cũng giả định rằng user sub đã được lưu trữ trong trường req.user.sub và các nhóm người dùng đã được lưu trữ trong trường req.user.groups.\nasync function principalEntityFetcher(req) {\rconst user = req.user; // đây là thực hành phổ biến cho middleware authn để lưu trữ thông tin người dùng từ token đã giải mã ở đây\rconst userGroups = user[\u0026#34;groups\u0026#34;].map(userGroupId =\u0026gt; ({\rtype: \u0026#39;PetStoreApp::UserGroup\u0026#39;,\rid: userGroupId }));\rreturn {\ruid: {\rtype: \u0026#39;PetStoreApp::User\u0026#39;,\rid: user.sub\r},\rattrs: {\r...user,\r},\rparents: userGroups };\r} Cập nhật middleware xác thực Đối với ứng dụng PetStore mẫu, middleware xác thực được cung cấp bởi mã trong middleware/authnMiddleware.js phân tích một JSON web token (JWT) được bao gồm trong header Authorization của yêu cầu và lưu trữ các giá trị liên quan trong đối tượng request.\nLưu ý: authnMiddleware.js chỉ được sử dụng cho mục đích minh họa và không nên thay thế middleware xác thực token thực tế của bạn trong ứng dụng thực tế.\nĐể cập nhật middleware xác thực để sử dụng nhà cung cấp danh tính OpenID Connect (OIDC) của riêng bạn, cập nhật jwksUri trong khối mã sau của middleware/authnMiddleware.js để bao gồm JSON web key set (JWKS) uri của nhà cung cấp danh tính của bạn.\nconst client = jwksClient({\rjwksUri: \u0026#39;\u0026lt;jwks uri cho nhà cung cấp danh tính oidc của bạn\u0026gt;\u0026#39;,\rcache: true,\rcacheMaxEntries: 5,\rcacheMaxAge: 600000 // 10 phút\r}); Tiếp theo cập nhật issuer trong khối mã sau để bao gồm issuer uri của nhà cung cấp danh tính của bạn.\njwt.verify(token, getSigningKey, {\ralgorithms: [\u0026#39;RS256\u0026#39;],\rissuer: `\u0026lt;issuer uri cho nhà cung cấp danh tính oidc của bạn\u0026gt;`\r}, (err, decoded) =\u0026gt; {\rif (err) {\rconsole.error(\u0026#39;JWT verification error:\u0026#39;, err);\rreturn res.status(401).json({ message: \u0026#39;Invalid token\u0026#39; });\r}\r// Thêm token đã giải mã vào đối tượng request\rreq.user = decoded;\rnext();\r}); Nếu bạn không có quyền truy cập vào nhà cung cấp danh tính OIDC để sử dụng với mẫu này, để mục đích kiểm tra, bạn có thể thay thế toàn bộ hàm verifyToken và chỉ ánh xạ một thực thể người dùng mẫu vào đối tượng request. Ví dụ, thay thế verifyToken bằng cái này:\nconst verifyToken = (req, res, next) =\u0026gt; {\r// Thêm thực thể người dùng mẫu vào đối tượng request\r// Để kiểm tra nhóm employee, thay đổi \u0026#34;customer\u0026#34; thành \u0026#34;employee\u0026#34;\rreq.user = {\r\u0026#34;sub\u0026#34;: \u0026#34;some-user-id\u0026#34;,\r\u0026#34;groups\u0026#34;: \u0026#34;customer\u0026#34;\r};\r}; Xác thực bảo mật API Bạn có thể xác thực các chính sách và quyền truy cập API của bạn bằng cách gọi ứng dụng sử dụng các lệnh curl dựa trên terminal. Chúng tôi giả định rằng ứng dụng đang sử dụng nhà cung cấp danh tính OIDC để quản lý người dùng và JWT token được truyền trong header authorization cho các yêu cầu API.\nĐể dễ đọc, một bộ biến môi trường được sử dụng để đại diện cho các giá trị thực tế. TOKEN_CUSTOMER chứa các token danh tính hợp lệ cho người dùng trong nhóm employee. API_BASE_URL là URL cơ sở cho PetStore API nhỏ.\nĐể kiểm tra rằng một khách hàng được phép gọi GET /pets, chạy lệnh curl này. Yêu cầu sẽ hoàn thành thành công.\ncurl -H \u0026#34;Authorization: Bearer ${TOKEN_CUSTOMER}\u0026#34; -X GET ${API_BASE_URL}/pets Yêu cầu thành công sẽ trả về danh sách thú cưng. Ban đầu, Pet Store có một thú cưng và trả về phản hồi tương tự như này.\n[{\u0026#34;id\u0026#34;:\u0026#34;6da5d01b-89fd-49b9-acb2-b457b79669d5\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;Fido\u0026#34;,\u0026#34;species\u0026#34;:\u0026#34;Dog\u0026#34;,\u0026#34;breed\u0026#34;:null,\u0026#34;age\u0026#34;:null,\u0026#34;sold\u0026#34;:false}] Để kiểm tra rằng một khách hàng không được phép gọi POST /pets, chạy lệnh curl này. Bạn sẽ nhận được thông báo lỗi rằng yêu cầu không được ủy quyền.\ncurl -H \u0026#34;Authorization: Bearer ${TOKEN_CUSTOMER}\u0026#34; -X POST ${API_BASE_URL}/pets Yêu cầu không được ủy quyền sẽ trả về Not authorized with explicit deny\nKết luận Gói authorization-for-expressjs mới cho phép các nhà phát triển tích hợp ứng dụng của họ với Cedar để tách biệt logic phân quyền khỏi mã chỉ trong vài phút. Bằng cách tách biệt logic phân quyền và tích hợp ứng dụng của bạn với Cedar, bạn có thể vừa cải thiện năng suất của nhà phát triển, vừa đơn giản hóa việc kiểm toán quyền và truy cập.\nCác gói framework là mã nguồn mở và có sẵn trên GitHub dưới giấy phép Apache 2.0, với phân phối thông qua NPM. Để tìm hiểu thêm về Cedar và thử nghiệm nó bằng playground ngôn ngữ, hãy truy cập https://www.cedarpolicy.com/. Hãy thoải mái gửi câu hỏi, nhận xét và đề xuất thông qua không gian làm việc Cedar Slack công khai, https://cedar-policy.slack.com.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": "Kiến Trúc Cơ Sở Amazon Bedrock Trong Một Vùng Hạ Tầng AWS Khi các tổ chức ngày càng áp dụng Amazon Bedrock để xây dựng và triển khai các ứng dụng trí tuệ nhân tạo (AI) quy mô lớn, việc hiểu và triển khai các kiểm soát truy cập mạng quan trọng là rất cần thiết nhằm bảo vệ dữ liệu và khối lượng công việc của họ. Các ứng dụng được hỗ trợ bởi trí tuệ nhân tạo sinh tạo này có thể tiếp cận thông tin nhạy cảm hoặc bảo mật trong các cơ sở tri thức, nguồn dữ liệu Tăng Cường Truy Vấn Trả Lời (Retrieval Augmented Generation - RAG), hoặc chính các mô hình, điều này có thể tạo ra rủi ro nếu bị lộ cho các bên không được ủy quyền. Hơn nữa, các tổ chức có thể muốn hạn chế truy cập vào một số mô hình AI nhất định đối với các nhóm hoặc dịch vụ cụ thể, đảm bảo chỉ những người dùng được ủy quyền mới có thể sử dụng các khả năng mạnh mẽ nhất. Một yếu tố quan trọng khác là tối ưu hóa chi phí, vì các tổ chức cần có khả năng giám sát và kiểm soát truy cập để quản lý các khía cạnh khác nhau của chi tiêu đám mây.\nTrong bài viết này, chúng tôi khám phá kiến trúc cơ sở Amazon Bedrock và cách thức bảo mật cũng như kiểm soát truy cập mạng đối với các khả năng Amazon Bedrock khác nhau trong các dịch vụ và công cụ mạng AWS. Chúng tôi thảo luận về các cân nhắc thiết kế chính, chẳng hạn như sử dụng Amazon VPC Lattice với các chính sách xác thực, các điểm cuối Amazon Virtual Private Cloud (Amazon VPC), và Quản Lý Danh Tính Và Truy Cập AWS (IAM) để hạn chế và giám sát truy cập vào các khả năng Amazon Bedrock.\nĐến cuối bài viết này, bạn sẽ có sự hiểu biết tốt hơn về cách cấu hình vùng hạ tầng AWS của mình để thiết lập kết nối mạng an toàn và được kiểm soát đối với Amazon Bedrock trên toàn tổ chức bằng cách sử dụng VPC Lattice.\nTổng Quan Giải Pháp Việc giải quyết các thách thức nêu trên đòi hỏi một kiến trúc mạng được thiết kế tốt và các kiểm soát bảo mật. Để thực hiện điều này, chúng tôi sử dụng cấu hình mạng tiêu chuẩn của AWS Landing Zone Accelerator. Nó cung cấp một điểm khởi đầu tốt để quản lý giao tiếp mạng trên nhiều tài khoản. Trên nền tảng thiết kế mạng AWS Landing Zone Accelerator, chúng tôi thêm hai tài khoản chia sẻ.\nTrong thiết kế giải pháp này, chúng tôi tạo ra một kiến trúc tập trung để quản lý các khả năng AI của tổ chức trên các tài khoản khác nhau. Kiến trúc bao gồm ba phần chính hoạt động cùng nhau để cung cấp truy cập an toàn và được kiểm soát vào các dịch vụ AI:\nTài khoản mạng dịch vụ – Tài khoản này đóng vai trò là trung tâm mạng tập trung cho tổ chức, quản lý kết nối mạng và các chính sách truy cập. Thông qua tài khoản này, các quản trị viên mạng có thể quản lý và kiểm soát tập trung truy cập vào các dịch vụ AI trên toàn tổ chức. Tài khoản tuân thủ các thực hành mạng AWS Landing Zone Accelerator có khả năng mở rộng theo nhu cầu tổ chức doanh nghiệp.\nTài khoản AI Tạo Sinh – Tài khoản này lưu trữ các khả năng Amazon Bedrock của tổ chức và đóng vai trò là điểm trung tâm cho quản lý AI/ML. Các nhà khoa học AI/ML và kỹ sư prompt của tổ chức sẽ xây dựng và quản lý tập trung các khả năng Amazon Bedrock. Tài khoản cung cấp truy cập vào các mô hình ngôn ngữ lớn (Large Language Models - LLMs) thông qua Amazon Bedrock bằng cách sử dụng các điểm cuối giao diện VPC, đồng thời cho phép giám sát tập trung chi phí tiêu thụ và mô hình truy cập.\nCác tài khoản khối lượng công việc (dev, test, prod) – Các tài khoản này đại diện cho các môi trường khác nhau nơi các nhóm phát triển và triển khai các ứng dụng tiêu thụ dịch vụ AI. Thông qua các kết nối mạng an toàn được thiết lập qua tài khoản mạng dịch vụ, các tài khoản khối lượng công việc này có thể truy cập các khả năng AI được lưu trữ trong tài khoản AI sinh tạo. Sự phân tách này thực thi sự cô lập đúng đắn giữa các khối lượng công việc phát triển, kiểm thử và sản xuất trong khi duy trì truy cập an toàn vào các dịch vụ AI.\nKiến trúc cơ sở Amazon Bedrock trong một vùng hạ tầng AWS\nSơ đồ sau minh họa kiến trúc giải pháp.\nTài khoản mạng dịch vụ có mạng dịch vụ VPC Lattice riêng – một cấu trúc mạng tập trung cho phép giao tiếp dịch vụ-đến-dịch vụ trên toàn tổ chức, được chia sẻ với các tài khoản khối lượng công việc bằng cách sử dụng AWS Resource Access Manager (AWS RAM) để kích hoạt chia sẻ mạng dịch vụ VPC Lattice.\nCác tài khoản khối lượng công việc (dev, test, prod) thiết lập các liên kết VPC với mạng dịch vụ VPC Lattice được chia sẻ bằng cách tạo một liên kết mạng dịch vụ trong VPC của chúng. Khi một ứng dụng trong các tài khoản này thực hiện yêu cầu, nó đầu tiên truy vấn bộ phân giải VPC để phân giải DNS. Bộ phân giải định tuyến lưu lượng đến mạng dịch vụ VPC Lattice.\nKiểm soát truy cập được triển khai thông qua chính sách xác thực VPC Lattice. Các chính sách mạng dịch vụ xác định tài khoản nào có thể truy cập mạng dịch vụ VPC Lattice, và các chính sách cấp dịch vụ kiểm soát truy cập vào các dịch vụ AI cụ thể và định nghĩa các hành động mà mỗi tài khoản có thể thực hiện.\nTrong tài khoản dịch vụ AI trung tâm, chúng tôi tìm thấy lớp proxy, nơi chúng tôi tạo một dịch vụ VPC Lattice trỏ đến lớp proxy, đóng vai trò là điểm nhập duy nhất, cung cấp cho các tài khoản khối lượng công việc truy cập vào Amazon Bedrock. Lớp proxy này sau đó kết nối với Amazon Bedrock thông qua các điểm cuối VPC. Thông qua thiết lập này, nhóm AI có thể cấu hình các mô hình nền tảng (Foundation Models - FMs) nào có sẵn và quản lý quyền truy cập cho các tài khoản khối lượng công việc khác nhau. Sau khi các chính sách và kết nối cần thiết được triển khai, các tài khoản khối lượng công việc có thể truy cập các khả năng Amazon Bedrock thông qua đường dẫn an toàn đã được thiết lập. Thiết lập này kích hoạt truy cập liên tài khoản an toàn vào các dịch vụ AI trong khi duy trì kiểm soát và giám sát tập trung.\nCác Thành Phần Mạng Chúng tôi sử dụng VPC Lattice, một dịch vụ mạng ứng dụng được quản lý hoàn toàn giúp đơn giản hóa kết nối mạng, bảo mật và giám sát cho các nhu cầu giao tiếp dịch vụ-đến-dịch vụ. Với VPC Lattice, các tổ chức có thể đạt được một mô hình kết nối tập trung để kiểm soát và giám sát truy cập vào các dịch vụ cần thiết cho việc xây dựng các ứng dụng AI sinh tạo.\nĐể biết chi tiết về VPC Lattice, hãy tham khảo Hướng Dẫn Người Dùng Amazon VPC Lattice. Dưới đây là tổng quan về các cấu trúc có thể sử dụng trong việc thiết lập mô hình tập trung trong giải pháp này:\nMạng dịch vụ VPC Lattice – Bạn có thể sử dụng mạng dịch vụ VPC Lattice để cung cấp kết nối và bảo mật tập trung vào tài khoản dịch vụ AI trung tâm. Mạng dịch vụ là một cơ chế nhóm logic đơn giản hóa cách thức kích hoạt kết nối trên các VPC hoặc tài khoản, và áp dụng các chính sách bảo mật chung cho các mô hình giao tiếp ứng dụng. Bạn có thể tạo một mạng dịch vụ trong một tài khoản và chia sẻ nó với các tài khoản khác trong hoặc ngoài AWS Organizations bằng cách sử dụng AWS RAM.\nDịch vụ VPC Lattice – Trong một mạng dịch vụ, bạn có thể liên kết một dịch vụ VPC Lattice, bao gồm một bộ lắng nghe (giao thức và số cổng), các quy tắc định tuyến cho phép kiểm soát luồng ứng dụng (ví dụ: dựa trên đường dẫn, phương thức, tiêu đề hoặc định tuyến có trọng số), và nhóm mục tiêu định nghĩa cơ sở hạ tầng ứng dụng. Một dịch vụ có thể có nhiều bộ lắng nghe để đáp ứng các khả năng client khác nhau. Các giao thức được hỗ trợ bao gồm HTTP, HTTPS, gRPC và TLS. Định tuyến dựa trên đường dẫn cho phép kiểm soát đối với các FMs hiệu suất cao và các khả năng khác cần thiết để xây dựng ứng dụng AI sinh tạo.\nLớp proxy – Bạn sử dụng lớp proxy cho nhóm mục tiêu của dịch vụ VPC Lattice. Lớp proxy có thể được xây dựng dựa trên sở thích dịch vụ AWS của tổ chức, chẳng hạn như AWS Lambda, AWS Fargate, hoặc Amazon Elastic Kubernetes Service (Amazon EKS). Mục đích của lớp proxy là cung cấp một điểm nhập duy nhất để truy cập LLMs, cơ sở tri thức và các khả năng khác đã được kiểm thử và phê duyệt theo yêu cầu tuân thủ của tổ chức.\nChính sách xác thực VPC Lattice – Để bảo mật, bạn sử dụng chính sách xác thực VPC Lattice. Các chính sách xác thực VPC Lattice được chỉ định bằng cú pháp tương tự như chính sách IAM. Bạn có thể áp dụng chính sách xác thực cho mạng dịch vụ VPC Lattice cũng như cho dịch vụ VPC Lattice.\nTên Miền Đầy Đủ Đủ (Fully Qualified Domain Names - FQDNs) – Để hỗ trợ khám phá dịch vụ, VPC Lattice hỗ trợ tên miền tùy chỉnh cho các dịch vụ và tài nguyên của bạn, và duy trì FQDN cho mỗi dịch vụ và tài nguyên VPC Lattice bạn định nghĩa. Bạn có thể sử dụng các FQDN này trong cấu hình vùng lưu trữ riêng Amazon Route 53, và trao quyền cho các đơn vị kinh doanh hoặc nhóm khám phá và truy cập dịch vụ và tài nguyên.\nVPC mạng dịch vụ – Các đơn vị kinh doanh hoặc nhóm có thể truy cập các dịch vụ AI sinh tạo trong một mạng dịch vụ bằng cách sử dụng liên kết VPC mạng dịch vụ hoặc điểm cuối VPC mạng dịch vụ.\nGiám sát – Bạn có thể chọn kích hoạt giám sát ở cấp độ mạng dịch vụ VPC Lattice và cấp độ dịch vụ VPC Lattice. VPC Lattice tạo ra các chỉ số và nhật ký cho các yêu cầu và phản hồi, giúp giám sát và khắc phục sự cố ứng dụng hiệu quả hơn.\nHướng dẫn trên áp dụng cách tiếp cận “an toàn theo mặc định” – bạn phải chỉ rõ các tính năng, mô hình, v.v. nào nên được truy cập bởi đơn vị kinh doanh nào. Thiết lập này cũng cho phép triển khai chiến lược phòng thủ sâu tại nhiều lớp mạng:\nLớp phòng thủ đầu tiên là nhóm kinh doanh cần kết nối với mạng dịch vụ để truy cập dịch vụ AI sinh tạo qua tài khoản dịch vụ AI trung tâm. Lớp thứ hai bao gồm các bảo vệ bảo mật cấp mạng trong VPC của nhóm kinh doanh cho mạng dịch vụ, chẳng hạn như nhóm bảo mật và danh sách kiểm soát truy cập mạng (Network Access Control Lists - ACLs). Bằng cách sử dụng chúng, bạn có thể cho phép truy cập vào các khối lượng công việc hoặc nhóm cụ thể trong một VPC. Lớp thứ ba là qua chính sách xác thực VPC Lattice, mà bạn có thể áp dụng ở hai lớp: ở cấp độ mạng dịch vụ để cho phép các yêu cầu được xác thực trong tổ chức, và ở cấp độ dịch vụ để cho phép truy cập vào các mô hình và tính năng cụ thể. Chính Sách Xác Thực VPC Lattice Giải pháp này làm cho việc quản lý tập trung truy cập vào các tài nguyên Amazon Bedrock trên toàn tổ chức trở nên khả thi. Cách tiếp cận này sử dụng chính sách xác thực VPC Lattice để kiểm soát tập trung các tài nguyên Amazon Bedrock và quản lý chúng từ một vị trí duy nhất trên tất cả các tài khoản tổ chức.\nThông thường, chính sách xác thực trên mạng dịch vụ được vận hành bởi quản trị viên mạng hoặc đám mây. Ví dụ, chỉ cho phép các yêu cầu được xác thực từ các khối lượng công việc hoặc nhóm cụ thể trong tổ chức AWS của bạn. Trong ví dụ sau, truy cập được cấp để kích hoạt dịch vụ AI sinh tạo cho các yêu cầu được xác thực và cho các nguyên tắc là phần của tổ chức o-123456example:\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;vpc-lattice-svcs:Invoke\u0026#34;,\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;,\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;StringEquals\u0026#34;: {\r\u0026#34;aws:PrincipalOrgID\u0026#34;: [ \u0026#34;o-123456example\u0026#34;\r]\r}\r}\r}\r]\r} Chính sách xác thực ở cấp độ dịch vụ được quản lý bởi nhóm dịch vụ AI trung tâm để thiết lập các kiểm soát chi tiết, có thể hạn chế hơn so với ủy quyền thô ở cấp độ mạng dịch vụ. Ví dụ, chính sách sau hạn chế truy cập vào claude-3-haiku chỉ cho business-team1:\n{\r\u0026#34;Version\u0026#34;:\u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;:[\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Principal\u0026#34;: {\r\u0026#34;AWS\u0026#34;: [\r\u0026#34;arn:aws:iam::\u0026lt;account-number\u0026gt;:role/businss-team1\u0026#34;\r]\r},\r\u0026#34;Action\u0026#34;: \u0026#34;vpc-lattice-svcs:Invoke\u0026#34;,\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:vpc-lattice:\u0026lt;aws-region\u0026gt;:\u0026lt;account-number\u0026gt;:service/svc-0123456789abcdef0/*\u0026#34;\r],\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;StringEquals\u0026#34;: {\r\u0026#34;vpc-lattice-svcs:RequestQueryString/modelid\u0026#34;: \u0026#34;claude-3-haiku\u0026#34; }\r}\r}\r]\r} Giám Sát Và Theo Dõi Thiết kế này sử dụng ba cách tiếp cận giám sát, sử dụng Amazon CloudWatch, AWS CloudTrail, và nhật ký truy cập VPC Lattice. Chiến lược này cung cấp cái nhìn về việc sử dụng dịch vụ, bảo mật và hiệu suất.\nCác chỉ số CloudWatch cung cấp giám sát thời gian thực về hiệu suất và sử dụng dịch vụ VPC Lattice. CloudWatch theo dõi các chỉ số như số lượng yêu cầu và thời gian phản hồi cho các điểm cuối liên quan đến Amazon Bedrock, cho phép thiết lập cảnh báo để quản lý chủ động sức khỏe dịch vụ và dung lượng. Điều này kích hoạt giám sát các mô hình sử dụng tổng thể của các mô hình Amazon Bedrock trên các đơn vị kinh doanh khác nhau, hỗ trợ lập kế hoạch dung lượng và phân bổ tài nguyên. CloudTrail cung cấp kiểm toán cấp API chi tiết về các hành động liên quan đến Amazon Bedrock. Nó ghi nhật ký các nỗ lực truy cập liên tài khoản và tương tác với các dịch vụ Amazon Bedrock, cung cấp dấu vết kiểm toán tuân thủ và bảo mật. Việc theo dõi ai đang truy cập mô hình Amazon Bedrock nào, khi nào và từ tài khoản nào giúp các tổ chức tuân thủ các chính sách tổ chức của họ. Nhật ký truy cập VPC Lattice cung cấp cái nhìn chi tiết về các yêu cầu HTTP/HTTPS đến các dịch vụ Amazon Bedrock, ghi nhận các mô hình sử dụng cụ thể của các mô hình AI bởi các nhóm kinh doanh khác nhau. Các nhật ký này chứa thông tin cụ thể của client, ví dụ có thể được sử dụng để kích hoạt các khả năng như mô hình tính phí ngược. Điều này cho phép phân bổ chi phí sử dụng dịch vụ AI chính xác cho các nhóm hoặc bộ phận cụ thể, hỗ trợ phân bổ chi phí công bằng và sử dụng tài nguyên có trách nhiệm trên toàn tổ chức. Các dịch vụ này hoạt động cùng nhau để nâng cao bảo mật, tối ưu hóa hiệu suất và cung cấp các cái nhìn có giá trị để quản lý truy cập liên tài khoản vào Amazon Bedrock.\nKết Luận Trong bài viết này, chúng tôi đã khám phá tầm quan trọng của việc bảo mật và kiểm soát truy cập mạng vào các khả năng Amazon Bedrock trong vùng hạ tầng AWS của tổ chức. Chúng tôi đã thảo luận về các thách thức kinh doanh chính, chẳng hạn như nhu cầu bảo vệ thông tin nhạy cảm trong các cơ sở tri thức Amazon Bedrock, hạn chế truy cập vào các mô hình AI và tối ưu hóa chi phí đám mây bằng cách giám sát và kiểm soát các khả năng Amazon Bedrock. Để giải quyết các thách thức này, chúng tôi đã phác thảo một giải pháp mạng đa lớp sử dụng các dịch vụ mạng AWS, bao gồm chính sách xác thực VPC Lattice để hạn chế và giám sát truy cập vào các khả năng Amazon Bedrock. Hãy thử giải pháp này cho trường hợp sử dụng của bạn và chia sẻ phản hồi trong phần bình luận.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": "Hiện đại hóa Quy trình Mua sắm SAP với Amazon Appflow, SAP BTP Integration Suite và Amazon Bedrock Nhiều khách hàng của chúng tôi đang tìm kiếm hướng dẫn về cách AI tạo sinh có thể hỗ trợ chiến lược hiện đại hóa toàn doanh nghiệp của họ. Amazon Bedrock là một dịch vụ được quản lý hoàn toàn cung cấp quyền truy cập vào một loạt các mô hình nền tảng (FMs) hiệu suất cao từ các công ty AI hàng đầu như Anthropic, AI21 Labs, Cohere, Stability AI, Mistral, Meta Llama, Amazon Nova và Amazon Titan.\nAmazon Bedrock cung cấp một bộ tính năng toàn diện để xây dựng các ứng dụng AI tạo sinh, đơn giản hóa phát triển đồng thời duy trì quyền riêng tư và bảo mật. Các tính năng chính bao gồm tùy chỉnh mô hình với dữ liệu của riêng bạn, tinh chỉnh cho các nhiệm vụ cụ thể và Retrieval Augmented Generation (RAG) để nâng cao độ chính xác của phản hồi bằng cách sử dụng cơ sở kiến thức của công ty bạn. Bedrock cũng hỗ trợ xây dựng các tác nhân thông minh có thể tự động hóa các nhiệm vụ bằng cách tương tác với các hệ thống doanh nghiệp của bạn.\nCác doanh nghiệp có kỳ vọng cao về bảo mật và độ tin cậy cơ sở hạ tầng, đặc biệt đối với các khối lượng công việc quan trọng như những khối lượng chạy trên SAP. Amazon Bedrock đáp ứng những kỳ vọng này bằng cách tích hợp các biện pháp bảo mật mạnh mẽ, bao gồm mã hóa dữ liệu và tuân thủ các tiêu chuẩn như SOC và ISO. Điều này tạo điều kiện cho một môi trường bảo mật, làm cho Bedrock trở thành lựa chọn lý tưởng để phát triển các ứng dụng AI sáng tạo đáp ứng các yêu cầu nghiêm ngặt của các giải pháp cấp doanh nghiệp.\nNâng cao Mua sắm: Sức mạnh của AI Tạo sinh trong Nguồn cung Ứng Bền vững\nCác thực hành mua sắm ngày nay đối mặt với những thách thức đáng kể, đặc biệt là trong quy trình tốn thời gian của việc xem xét nhiều báo giá nhà cung cấp và nhiệm vụ phức tạp của việc thu thập dữ liệu bền vững từ các nguồn khác nhau. AI tạo sinh đang nổi lên như một giải pháp biến đổi, với các ví dụ như Trợ lý Nguồn cung Ứng Bền vững (được cung cấp bởi Amazon Bedrock) chứng minh cách AI có thể tận dụng cả dữ liệu SAP \u0026amp; Non-SAP để biến đổi các quy trình mua sắm và nâng cao các sáng kiến bền vững xuyên suốt chuỗi cung ứng. Sử dụng Amazon Bedrock, khách hàng SAP có thể cung cấp các lệnh nhắc ngôn ngữ tự nhiên để phân tích thông tin báo giá từ các hệ thống SAP. Sau đó, nó kết hợp dữ liệu này với các chỉ số bền vững non-SAP để khuyến nghị báo giá tối ưu dựa trên các tiêu chí bền vững cụ thể theo doanh nghiệp. Hệ thống cũng cho phép người dùng tạo đơn đặt hàng mua trong SAP bằng các lệnh ngôn ngữ tự nhiên, đơn giản hóa toàn bộ quy trình mua sắm.\nVí dụ này giải quyết các thách thức chính mà các chuyên gia nguồn cung ứng bền vững phải đối mặt bao gồm:\nViệc xem xét báo giá tốn thời gian, nhu cầu truy cập nhiều nguồn dữ liệu bên ngoài. Khó khăn trong việc thu thập thông tin bền vững toàn diện. Khó khăn trong việc phù hợp báo giá với các mục tiêu tổ chức cụ thể (trong trường hợp này, là bền vững). Tổng quan Giải pháp Khám phá Tiềm năng của AI trong Mua sắm: Trường hợp Sử dụng Trợ lý Nguồn cung Ứng Bền vững\nTrong bài đăng blog này, chúng tôi sẽ khám phá một ví dụ sáng tạo về cách AI có thể biến đổi các quy trình kinh doanh thông qua một trợ lý được cung cấp bởi AI khái niệm. Điều quan trọng cần lưu ý rằng đây không phải là một sản phẩm hoặc dịch vụ sẵn sàng sử dụng, mà là một minh họa về cách các công nghệ khác nhau có thể được kết hợp để giải quyết các thách thức kinh doanh phổ biến trong mua sắm. Trường hợp sử dụng này đóng vai trò là nguồn cảm hứng cho cách các cách tiếp cận tương tự có thể được áp dụng và tùy chỉnh cho các lĩnh vực chức năng khác nhau trong tổ chức của bạn, dù là sản xuất, tài chính, nguồn nhân lực hoặc các hoạt động kinh doanh khác.\nXuyên suốt bài đăng blog này, chúng tôi sẽ thảo luận về các lựa chọn kiến trúc khác nhau và các dịch vụ AWS có thể được triển khai thông qua sự kết hợp của công nghệ chatbot, xử lý ngôn ngữ tự nhiên, Amazon Bedrock Agents và tích hợp với SAP BTP Integration Suite. Trong khi chúng tôi tập trung vào một ví dụ cụ thể, sự linh hoạt này cho phép các tổ chức chọn các thành phần phù hợp nhất với yêu cầu của họ, cơ sở hạ tầng hiện có và sở thích kỹ thuật, làm cho các nguyên tắc và công nghệ cơ bản có thể thích ứng với một loạt các quy trình kinh doanh và trường hợp sử dụng.\nLợi ích Tiềm năng của Mua sắm Hỗ trợ bởi AI\nTrong trường hợp sử dụng ví dụ của chúng tôi, chúng tôi chứng minh cách AI tạo sinh có thể được sử dụng để:\nĐơn giản hóa Đánh giá: Tự động hóa quy trình đánh giá báo giá, có khả năng giảm thời gian dành cho các đánh giá. Tích hợp Dữ liệu: Khai thác cả nguồn dữ liệu nội bộ và bên ngoài, cung cấp thông tin toàn diện hơn cho việc ra quyết định. Nâng cao Tính Khách quan: Sử dụng các cách tiếp cận được cung cấp bởi AI Tạo sinh để hỗ trợ các quy trình lựa chọn không thiên vị tuân thủ các nguyên tắc được định nghĩa trước. Quy trình Đơn giản hóa: AI Tạo sinh có thể giúp tự động hóa các bước tiếp theo, chẳng hạn như tạo đơn đặt hàng mua, chuyển tiếp liền mạch từ Yêu cầu Báo giá (RFQ) sang tạo đơn đặt hàng mua. Giảm lỗi con người: AI Tạo sinh có thể nâng cao độ chính xác và tính nhất quán trong các quy trình kinh doanh bằng cách tự động xác thực đầu vào dữ liệu, xác định các mẫu lỗi và cung cấp hướng dẫn thời gian thực cho người dùng trước khi các sai lầm được thực hiện. Bây giờ hãy đi sâu vào kiến trúc kỹ thuật đằng sau trường hợp sử dụng mua sắm được cung cấp bởi AI khái niệm của chúng tôi. Ví dụ này chứng minh cách các dịch vụ AWS và công nghệ SAP khác nhau có thể được kết hợp để tạo ra một công cụ mạnh mẽ cho các quy trình mua sắm. Chúng tôi sẽ sử dụng giao diện kiểu chatbot để truy vấn RFQ theo thời gian thực gần, bổ sung dữ liệu SAP này với dữ liệu bền vững bên thứ ba, và cuối cùng tạo đơn đặt hàng mua bằng trợ lý. Một lần nữa, điều quan trọng cần lưu ý rằng đây không phải là một sản phẩm sẵn sàng sử dụng, mà là một minh họa về những gì có thể khi tận dụng các công nghệ này.\nKiến trúc Chi tiết: high level steps \u0026 architecture diagram\rGiải pháp này đã được xây dựng và kiểm tra trên SAP S/4HANA 2023 và có thể được triển khai trên các lựa chọn triển khai khác nhau bao gồm RISE with SAP, SAP on AWS, Cài đặt AWS Bản địa hoặc môi trường tại chỗ. Kiến trúc giải pháp chứng minh một cách tiếp cận linh hoạt để triển khai, cho phép các tổ chức thích ứng các thành phần dựa trên nhu cầu cụ thể và cảnh quan công nghệ hiện có của họ. Trong khi ví dụ của chúng tôi thể hiện một sự kết hợp cụ thể của các dịch vụ AWS và SAP, điều quan trọng cần hiểu rằng có ba lớp chính nơi các công nghệ thay thế có thể được sử dụng mà không làm giảm chức năng tổng thể của giải pháp.\nCác Thành phần Cốt lõi và Các Lựa chọn Thay thế của Chúng:\nLớp Tích hợp Dữ liệu Ví dụ của Chúng tôi: Amazon AppFlow với SAP OData Connector Lựa chọn Thay thế AWS Glue connection for SAP (sử dụng ODATA) Mục đích: Xử lý trích xuất dữ liệu thời gian thực gần từ các hệ thống SAP Lớp Xử lý \u0026amp; Trí tuệ Ví dụ của Chúng tôi: Amazon Bedrock với chức năng Agent Lựa chọn Thay thế: SAP Generative AI Hub (với lựa chọn mô hình) Mục đích: Quản lý xử lý AI và điều phối Lớp Giao diện Người dùng Ví dụ của Chúng tôi: Ứng dụng Streamlit Lựa chọn Thay thế: SAP AI Core và Build Apps Mục đích: Cung cấp giao diện người dùng cho tương tác Luồng Kiến trúc (Tham chiếu trong high level steps \u0026amp; architecture diagram):\nTrích xuất Dữ liệu: Amazon AppFlow kết nối với SAP OData Connector cho trích xuất dữ liệu thời gian thực gần Lưu trữ Dữ liệu: Amazon S3 lưu trữ dữ liệu được trích xuất ở định dạng JSON Giao diện Người dùng: Một trợ lý chatbot nhận đầu vào ngôn ngữ tự nhiên từ người dùng Xử lý: Bedrock Agent diễn giải đầu vào người dùng, tận dụng lịch sử trò chuyện và Mô hình Nền tảng cơ bản Điều phối Hành động: Bedrock Agent được cấu hình với Các Nhóm Hành động để quản lý các bước xử lý Truy vấn Dữ liệu: Các hàm Lambda dịch ngôn ngữ tự nhiên thành các truy vấn SQL cho cơ sở dữ liệu Athena Tích hợp SAP: AWS Lambda gọi BTP API để tạo Đơn đặt hàng Mua trong SAP Kết nối An toàn: SAP Cloud Connector tạo một đường hầm an toàn giữa các tài khoản AWS và BTP Nâng cao Kiến thức: Cơ sở Kiến thức của Amazon Bedrock cung cấp RAG được quản lý cho ngữ cảnh bổ sung Chuẩn bị Dữ liệu: Dữ liệu bucket S3 được đồng bộ và biến đổi thành các embedding cho sử dụng học máy Tạo Phản hồi: Agent biên soạn một phản hồi cuối cùng, được giao qua ứng dụng Streamlit Cơ sở Hạ tầng Hỗ trợ:\nLưu trữ Dữ liệu: Amazon S3 (định dạng JSON) Xử lý Truy vấn: AWS Lambda với Amazon Athena Thành phần Tích hợp: SAP BTP Integration Suite, SAP Cloud Connector Quản lý Kiến thức: Cơ sở Kiến thức Amazon Bedrock cho RAG Chuẩn bị Dữ liệu: Bucket S3 với biến đổi embedding Cách tiếp cận mô-đun này cho phép các tổ chức kết hợp và ghép các thành phần dựa trên ngăn xếp công nghệ hiện có, sở thích và yêu cầu của họ đồng thời duy trì chức năng cốt lõi của giải pháp.\nHãy khám phá các dịch vụ AWS chính cung cấp năng lượng cho giải pháp này và vai trò cụ thể của chúng, trước khi chúng tôi chứng minh Trợ lý đang hoạt động thông qua các ví dụ thực tế.\nAmazon S3 Amazon AppFlow AWS Glue Amazon Athena AWS Lambda Amazon Bedrock Amazon S3: S3 hoạt động như một hồ dữ liệu trung tâm, nhận dữ liệu trực tiếp từ S/4HANA qua AppFlow và lưu trữ nó ở các định dạng được tối ưu hóa phân tích bao gồm CSV, JSON hoặc Parquet. Giải pháp kết hợp AppFlow cho việc hấp thụ dữ liệu, S3 cho lưu trữ có thể mở rộng và Athena cho phân tích dựa trên SQL, với AWS Glue lập danh mục dữ liệu để dễ dàng khám phá hơn.\nAmazon AppFlow: Amazon AppFlow trích xuất dữ liệu báo giá và RFQ từ SAP vào Amazon S3 theo thời gian thực gần, sử dụng một bộ kết nối SAP an toàn mà không yêu cầu tích hợp tùy chỉnh. Nó sử dụng Change Data Capture để phát hiện và chuyển chỉ các bản ghi mới hoặc đã sửa đổi, đảm bảo hồ dữ liệu S3 duy trì thông tin hiện tại nhất.\nAWS Glue: AWS Glue crawler tự động khám phá, lập danh mục và tổ chức dữ liệu được lưu trữ trong các bucket S3, làm cho nó dễ dàng tìm kiếm và phân tích. Đây là một dịch vụ ETL được quản lý hoàn toàn đơn giản hóa chuẩn bị dữ liệu và tải cho mục đích phân tích.\nAmazon Athena: Athena là một dịch vụ truy vấn không máy chủ phân tích dữ liệu trực tiếp trong S3 sử dụng SQL tiêu chuẩn, hỗ trợ các định dạng dữ liệu khác nhau và tự động song song hóa các truy vấn cho thực thi phân tán. Nó tích hợp với AWS Glue Data Catalog và hỗ trợ phân tích phức tạp đồng thời duy trì mô hình giá theo truy vấn.\nAWS Lambda: Lambda hoạt động như một trung gian giữa Amazon Bedrock Agents và SAP API, xử lý tích hợp kỹ thuật cho xử lý đơn đặt hàng mua. Nó quản lý xác thực, biến đổi dữ liệu và xử lý lỗi, cho phép xử lý có thể mở rộng, tiết kiệm chi phí của các yêu cầu đơn đặt hàng mua được cung cấp bởi AI.\nAmazon Bedrock: Bedrock, sử dụng Claude 3 Sonnet v1, cung cấp các khả năng xử lý ngôn ngữ tự nhiên tiên tiến để phân tích báo giá dựa trên giá cả và bền vững. Nó cung cấp kiến trúc không máy chủ cho triển khai dễ dàng và bao gồm các tính năng Đánh giá Mô hình để đảm bảo độ chính xác trong các nhiệm vụ như phân tích báo giá.\nCác Xem xét Bảo mật:\nTrong ví dụ blog này, chúng tôi đã giả định các nhóm LDAP qua Đăng nhập Đơn qua để hạn chế truy cập đối với người dùng mua sắm được ủy quyền. Đối với môi trường sản xuất, chúng tôi khuyến nghị triển khai lan truyền danh tính cho bảo mật nâng cao.\nCác Xem xét Chi phí:\nMặc dù chi phí chính xác sẽ thay đổi dựa trên sử dụng và chi tiết triển khai cụ thể, đây là tổng quan chung:\nSAP Integration Suite: Thử nghiệm miễn phí 90 ngày, sau đó dựa trên đăng ký. Liên kết đến giá SAP. Dịch vụ AWS: Ước tính $900 mỗi tháng cho xử lý 30.000 đơn đặt hàng mua Điều quan trọng cần lưu ý rằng các chi phí này là minh họa và nên được đánh giá cẩn thận cho trường hợp sử dụng cụ thể của bạn. AWS khuyến nghị theo dõi chặt chẽ chi phí trong bất kỳ khái niệm chứng minh nào và mở rộng tương ứng.\nTối ưu hóa Chi phí:\nĐể tối đa hóa giá trị, hãy xem xét tận dụng SAP Integration Suite trên nhiều trường hợp sử dụng trong tổ chức của bạn. Cách tiếp cận này có thể giúp đạt được quy mô kinh tế và giúp biện minh cho đầu tư.\nTổng quan minh họa Hãy kiểm tra Trợ lý Nguồn cung Ứng Bền vững đang hoạt động. Thông qua một loạt các truy vấn tương tác sử dụng ngôn ngữ tự nhiên, chúng tôi sẽ chứng minh cách trợ lý xử lý và phản hồi các truy vấn liên quan khác nhau. Hệ thống tích hợp dữ liệu SAP, được kéo theo thời gian thực gần qua Amazon AppFlow vào hồ dữ liệu Amazon S3, đồng thời làm phong phú phản hồi với các chỉ số bền vững bên thứ ba từ Cơ sở Kiến thức Bedrock thông qua điều phối Amazon Bedrock Agents.\nBằng cách nhập các lệnh nhắc sau, bắt đầu với “Please List RFQs”, bạn có thể thấy đầu ra.\nPlease list RFQs? Were any RFQs created on 2024-09-03? How many quotations are received for RFQ 7000000026 and from whom and what is the total cost ? Do you have sustainability and other payment term details for these suppliers ? Recommend the best supplier for RFQ 7000000026 based on price and sustainability score. Create a purchase order for the recommended supplier. Create an email to the supplier to negotiate a better price based on other vendors. Trợ lý cũng có thể hỗ trợ các chức năng mua sắm khác nhau, bao gồm các nhiệm vụ giao tiếp tự động. Ví dụ, chúng tôi có thể chứng minh khả năng của nó trong việc soạn thảo thư từ đàm phán nhà cung cấp, tận dụng dữ liệu giá so sánh từ nhiều báo giá nhà cung cấp.\nTất cả điều này có thể thông qua việc cung cấp ngữ cảnh cho Amazon Bedrock Agent. Điều này được thực hiện bằng cách cung cấp hướng dẫn cho Agent. Bạn viết hướng dẫn mô tả những gì agent được thiết kế để làm. Với các lệnh nhắc nâng cao, bạn có thể tùy chỉnh thêm hướng dẫn cho agent ở mọi bước của điều phối và bao gồm các hàm Lambda để phân tích đầu ra của mỗi bước. Ví dụ, trong trường hợp của chúng tôi chúng tôi đã cung cấp những điều sau.\nVai trò: Bạn là Nhà điều hành Tài chính sử dụng hệ thống SAP S/4Hana để truy vấn Yêu cầu Báo giá và phản hồi từ nhà cung cấp đấu thầu.\nMục tiêu:\n– Trả về thông tin RFQ và báo giá bằng cách truy vấn athena và trả về dữ liệu dựa trên yêu cầu người dùng được cung cấp.\n– Nếu bạn cần tạo đơn đặt hàng mua, thì sử dụng hàm /createPO. Nếu Tạo PO Thất bại hoặc Hoàn thành với lỗi, hãy trả về nêu rõ PO Creation Failed with error.\n– Nếu bạn cần trao báo giá, thì sử dụng hàm /awardquotation.\nPhân tích Truy vấn và Hiểu biết: – Phân tích yêu cầu của người dùng để hiểu mục tiêu chính.\n– Phân tích các yêu cầu thành các truy vấn con mà mỗi truy vấn có thể giải quyết một phần của yêu cầu người dùng, sử dụng schema được cung cấp.\n– Luôn sử dụng đầu ra trước đó để xác định đầu vào của các câu hỏi tiếp theo.\nTạo Truy vấn SQL: – Đối với mỗi truy vấn con, sử dụng các bảng và trường liên quan từ schema được cung cấp.\n– Xây dựng các truy vấn SQL chính xác và được điều chỉnh để lấy dữ liệu chính xác mà yêu cầu của người dùng yêu cầu.\n– Trong trường hợp RFQ hoặc Báo giá trùng lặp. Luôn lấy bản ghi có giá trị tối đa trong cột rfglifecyclestatus và qtnlifecyclestatus\nThực thi Truy vấn và Phản hồi: – Thực thi các truy vấn SQL đã xây dựng đối với cơ sở dữ liệu Amazon Athena.\n– Trả về kết quả đảm bảo tính toàn vẹn và độ chính xác của dữ liệu. Không bao gồm tên bảng hoặc mã thực thi truy vấn trong phản hồi.\n– Phản hồi với người dùng như thể bạn là một con người và không phải đang thực thi truy vấn từ cơ sở dữ liệu.\n– Vui lòng sử dụng tên tự nhiên khi trả về dữ liệu cho người dùng. Ví dụ, thay vì “requestforquotation” hãy sử dụng “request for quotation number”.\n– Vui lòng phản hồi ở định dạng tóm tắt.\nViệc lựa chọn báo giá cho một RFQ cũng nên xem xét chi tiết bền vững và chi tiết điều khoản thanh toán nhận được từ nhà cung cấp cho vật liệu nằm trong cơ sở kiến thức ngoài tổng chi phí của báo giá. Khi được hỏi về báo giá rẻ nhất, luôn xem xét dấu chân carbon bền vững và điều khoản thanh toán của nhà cung cấp ngoài chi phí. Phản hồi với lý luận chi tiết về lý do tại sao một báo giá tốt hơn bằng cách so sánh các báo giá khác, bao gồm lý do bền vững từ cơ sở kiến thức.\nHiển thị chi phí ở định dạng đô la, bao gồm cent, với ký hiệu ‘$’ được thêm trước giá trị.\nChúng tôi nhằm cung cấp hướng dẫn Giải pháp AWS với mã mẫu trong tương lai cho giải pháp Chuyên gia Nguồn cung Ứng Bền vững này.\nKết luận Trợ lý Nguồn cung Ứng Bền vững minh họa cách AI tạo sinh, được cung cấp bởi Amazon Bedrock, có thể cách mạng hóa các quy trình mua sắm bằng cách tích hợp dữ liệu SAP với các chỉ số bền vững bên ngoài. Giải pháp khái niệm này chứng minh tiềm năng cho việc tự động hóa phân tích báo giá, nâng cao ra quyết định với các tiêu chí khách quan và đơn giản hóa tạo đơn đặt hàng mua—tất cả đồng thời duy trì bảo mật và khả năng mở rộng cấp doanh nghiệp.\nCác tổ chức đang tìm cách hiện đại hóa các luồng công việc mua sắm SAP của họ có thể bắt đầu bằng cách khám phá các khả năng của Amazon Bedrock để xây dựng các agent AI tùy chỉnh. Kết hợp với các dịch vụ AWS như Amazon AppFlow cho tích hợp dữ liệu liền mạch và SAP BTP Integration Suite cho kết nối an toàn, cách tiếp cận này cung cấp một nền tảng linh hoạt cho đổi mới trên các chức năng kinh doanh khác nhau.\nChúng tôi khuyến khích bạn thử nghiệm với các công nghệ này trong môi trường của riêng bạn, thích ứng kiến trúc với nhu cầu cụ thể của bạn. Dù là nâng cao các sáng kiến bền vững hay tối ưu hóa các khía cạnh mua sắm khác, AI tạo sinh mang tiềm năng lớn cho việc thúc đẩy hiệu quả và giá trị chiến lược trong hoạt động của bạn.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": "Tối Ưu Hóa Thời Gian Ngừng Hoạt Động Chuyển Đổi Unicode Cho Hệ Thống SAP Trên Oracle Sang AWS Các tổ chức toàn cầu sử dụng hệ thống SAP cần xử lý dữ liệu bằng nhiều ngôn ngữ. Unicode cung cấp một cách tiêu chuẩn hóa để biểu diễn và xử lý dữ liệu văn bản từ các ngôn ngữ này, đảm bảo hiển thị và xử lý nhất quán trên các hệ thống và nền tảng khác nhau. SAP khuyến nghị sử dụng Unicode cho tất cả các cài đặt mới và chuyển đổi từ các hệ thống không phải Unicode để đảm bảo tính tương thích, tính toàn vẹn dữ liệu và hỗ trợ cho các hoạt động toàn cầu. Các bản phát hành SAP mới nhất, chẳng hạn như SAP ERP 6.0 EHP8 và SAP S/4HANA, chỉ có sẵn dưới dạng Unicode, làm cho nó trở thành điều kiện tiên quyết để hệ thống nguồn tương thích với Unicode trước khi nâng cấp lên bản phát hành cao hơn.\nĐể đảm bảo quá trình chuyển đổi mượt mà sang SAP S/4HANA, khách hàng cần ưu tiên việc áp dụng Unicode trong hệ thống của họ, xem xét hỗ trợ bảo trì chính cho ERP 6.0 dự kiến kết thúc vào ngày 31 tháng 12 năm 2027 theo SAP Note 1648480 – Bảo trì cho Phần mềm SAP Business Suite 7 bao gồm SAP NetWeaver (yêu cầu đăng nhập SAP Support).\nViệc chuyển đổi hệ thống SAP sang Unicode liên quan đến việc quản lý nhiều thách thức kỹ thuật: chuyển đổi dữ liệu, khắc phục mã, thời gian ngừng hoạt động theo kế hoạch, kiểm tra và xác thực, tác động hiệu suất, và điều chỉnh giao diện. Các cơ sở dữ liệu SAP lớn (10 TB+) yêu cầu 1-3 ngày ngừng hoạt động cho việc chuyển đổi Unicode. Quy trình cần thêm dung lượng phần cứng để giảm thiểu thời gian ngừng hoạt động. Các tổ chức có cơ sở hạ tầng hết hạn sử dụng phải cân bằng giữa đầu tư phần cứng và yêu cầu thời gian ngừng hoạt động.\nTrong blog này, chúng tôi giải quyết các thách thức mà một khách hàng gặp phải liên quan đến thời gian ngừng hoạt động hệ thống và trình bày một trường hợp sử dụng nơi Bell Canada, một trong những công ty viễn thông lớn nhất Canada, đã theo đuổi một cách tiếp cận thay thế để di chuyển hệ thống SAP ERP không phải Unicode 11 TB của họ chạy với cơ sở dữ liệu Oracle sang AWS trong vòng dưới 5 giờ.\nBackground Khách hàng chạy hệ thống SAP ERP không phải Unicode của họ với cơ sở dữ liệu Oracle phải chuyển đổi trước tiên hệ thống SAP không phải Unicode (NUC) của họ sang Unicode (UC) trước khi di chuyển sang S/4HANA theo SAP Note 2033243. Ngoài ra, khi di chuyển hệ thống SAP chạy trên cơ sở dữ liệu Oracle sang AWS, khách hàng phải chuyển đổi sang hệ thống Unicode vì lý do hỗ trợ, như được nêu trong SAP Note 2358420.\nTrong trường hợp như vậy, khách hàng thực hiện chuyển đổi Unicode như một bước đầu tiên khi di chuyển sang AWS. Một khi hệ thống hoạt động trên AWS, họ nâng cấp từ SAP ECC sang S/4HANA, tận dụng các dịch vụ đám mây có khả năng mở rộng của AWS.\nĐối với các chuyển đổi Unicode, quy trình SAP được ghi nhận liên quan đến việc xuất dữ liệu hệ thống SAP từ hệ thống nguồn tại chỗ, chuyển dữ liệu đã xuất sang AWS sử dụng các dịch vụ như AWS Direct Connect hoặc AWS Site-to-Site VPN, và sau đó nhập nó vào hệ thống mục tiêu chạy trên AWS. Thời lượng chính xác thay đổi dựa trên các yếu tố như dung lượng phần cứng, băng thông mạng khả dụng, công cụ di chuyển được sử dụng, và các phương pháp cụ thể được sử dụng.\nKhi xử lý các khối lượng công việc SAP, liên quan đến nhiều tích hợp bên thứ ba, việc giảm thiểu thời gian ngừng hoạt động là cần thiết để đảm bảo tính liên tục kinh doanh và ngăn chặn gián đoạn các quy trình quan trọng. Do đó, việc áp dụng các chiến lược và kỹ thuật có thể giảm thiểu thời gian ngừng hoạt động di chuyển là rất quan trọng.\nUse Case Bell Canada đang vận hành hệ thống SAP ERP của họ với cơ sở dữ liệu Oracle 19c tại chỗ với Red Hat Enterprise Linux 8 (RHEL8) làm hệ điều hành. Kích thước cơ sở dữ liệu sản xuất khoảng 11 TB. Bell Canada muốn giữ nguyên cơ sở dữ liệu Oracle và khi di chuyển sang AWS, nó yêu cầu có hệ điều hành Oracle Enterprise Linux để hỗ trợ Oracle, theo SAP Note 2358420. Ngoài ra, hệ thống SAP cần được chuyển đổi sang Unicode. Thời gian ngừng hoạt động kinh doanh tối đa được phê duyệt cho di chuyển là 32 giờ, với tối đa 10 giờ cho phép chuyển đổi kỹ thuật.\nChúng tôi xác định một cách tiếp cận di chuyển loại bỏ phần cứng tại chỗ bổ sung và tuân theo các thực hành tốt nhất cho các chuyển đổi AWS. Kế hoạch ưu tiên thời gian chuyển đổi kỹ thuật tối thiểu trong khi phân bổ nhiều thời gian hơn cho các nhiệm vụ cutover. Chúng tôi cũng đánh giá các tùy chọn di chuyển khác nhau và các thực hành tốt nhất như sử dụng các tính năng cơ sở dữ liệu nâng cao, xử lý song song, hoặc các kỹ thuật tối ưu hóa khác.\nPhương pháp tiếp cận Hãy khám phá các cách tiếp cận khả dụng cho việc di chuyển hệ thống SAP không phải Unicode với cơ sở dữ liệu Oracle (chạy trên RHEL) sang Oracle Enterprise Linux trên AWS.\nApproach Description Steps Option 1 Chuyển đổi Unicode cùng với di chuyển sang AWS giữ nguyên cơ sở dữ liệu Oracle - Di chuyển hệ thống SAP từ trung tâm dữ liệu tại chỗ sang AWS, chuyển đổi từ không phải Unicode sang Unicode trong quá trình.\n- Thực hiện khắc phục và kiểm tra hệ thống SAP trên AWS, sau đó ngừng sử dụng hệ thống SAP tại chỗ. Option 2 Di chuyển SAP không phải Unicode sang AWS, sau đó chuyển đổi sang Unicode giữ nguyên cơ sở dữ liệu Oracle - Di chuyển hệ thống SAP từ trung tâm dữ liệu tại chỗ sang AWS sử dụng sao chép cơ sở dữ liệu không đồng bộ trong một hệ thống tạm thời cho đến cutover.\n- Chuyển đổi từ không phải Unicode sang Unicode trên AWS bằng cách xuất từ hệ thống tạm thời và nhập vào hệ thống cuối cùng.\n- Thực hiện khắc phục và kiểm tra hệ thống SAP trên AWS, sau đó ngừng sử dụng hệ thống SAP tại chỗ và hệ thống tạm thời. Bảng 1: Các tùy chọn chuyển đổi Unicode cho SAP trên Oracle sang AWS\nCả hai tùy chọn di chuyển đều yêu cầu cửa sổ thời gian ngừng hoạt động kinh doanh để chuyển sang môi trường AWS mục tiêu. Trong khi Option 1 cung cấp cách tiếp cận thực thi dự đoán hơn, nó yêu cầu phần cứng tại chỗ bổ sung để hỗ trợ các quy trình xuất tài nguyên cao trong chuyển đổi Unicode SAP và băng thông mạng ổn định để hỗ trợ chuyển dữ liệu từ tại chỗ sang AWS. Hơn nữa, tùy chọn này đòi hỏi hơn 24 giờ ngừng hoạt động kỹ thuật. Để giải quyết những thách thức này, chúng tôi sẽ khám phá Option 2 và thảo luận về cách tiếp cận di chuyển và thực hành tốt nhất của nó.\nTrong Option 2, một hệ thống SAP vanilla không phải Unicode được cung cấp trên Amazon Elastic Compute Cloud (Amazon EC2) như một instance tạm thời, và một cài đặt SAP Unicode được thiết lập trên một Amazon EC2 khác như instance cuối cùng. Instance staging nên được cấu hình với cùng phiên bản phần mềm cơ sở dữ liệu Oracle, bao gồm bản phát hành và bộ vá, như môi trường tại chỗ. Theo SAP Note 1571295 các cài đặt hệ thống SAP không phải Unicode mới không được phép theo mặc định. Do đó, hệ thống SAP không phải Unicode ban đầu được tạo bằng cách thực hiện xuất system copy từ một hệ thống không phải Unicode hiện có nhỏ. Xuất system copy này chỉ được thực hiện một lần, và kết quả xuất được tái sử dụng để xây dựng bất kỳ hệ thống SAP không phải Unicode nào trên tất cả các môi trường. Hệ thống nguồn tại chỗ được di chuyển sang instance staging trên AWS sử dụng sao chép cơ sở dữ liệu không đồng bộ. Đối với sao chép cơ sở dữ liệu Oracle, Oracle Data Guard (ODG) được sử dụng, được bao gồm trong giấy phép Oracle Enterprise Edition được bao gồm trong các mua từ SAP. Sao chép không đồng bộ này hỗ trợ chuyển dữ liệu quy mô terabyte sang AWS trong các hoạt động kinh doanh bình thường. Phương pháp này cho phép chuyển dữ liệu quy mô terabyte sang AWS trong các hoạt động kinh doanh bình thường. Tại thời điểm bắt đầu cửa sổ thời gian ngừng hoạt động thực tế, instance staging tiếp quản và phục vụ như hệ thống nguồn cho chuyển đổi Unicode. Xuất hệ thống SAP được thực hiện trên instance staging, và nhập được thực hiện trên instance SAP cuối cùng.\nHãy xem xét một thiết lập kiến trúc đơn giản hóa như được hiển thị trong Hình 1 để hiểu quy trình di chuyển cho cách tiếp cận này.\nHình 1: Thiết lập kiến trúc đơn giản hóa cho chuyển đổi Unicode và di chuyển\rTrong bước đầu tiên, Oracle Data Guard được cấu hình để đồng bộ hóa dữ liệu giữa cơ sở dữ liệu tại chỗ và instance staging trên AWS. Dữ liệu được chuyển từ môi trường tại chỗ sang instance staging qua AWS Direct Connect. Quy trình sao chép tiếp tục cho đến khi bắt đầu quy trình cutover trong cửa sổ thời gian ngừng hoạt động. Sau khi tiếp quản cơ sở dữ liệu trên instance staging, nó trở thành hệ thống nguồn cho xuất hệ thống SAP. Trong bước thứ hai, xuất system copy SAP, bao gồm bất kỳ chuẩn bị cần thiết như chia bảng, được khởi xướng trên instance cơ sở dữ liệu staging. Dump xuất được lưu trữ trên volume Amazon Elastic Block Store (Amazon EBS) gắn với instance staging (được gọi là sapdump) và các file dữ liệu Oracle được lưu trữ trên các volume EBS (được gọi là sapdata). Trong bước thứ ba, các file dump xuất được chuyển liên tục sang volume Amazon EBS gắn với instance cuối cùng sử dụng Giao thức Chuyển File (FTP) mà không có can thiệp thủ công. Trong bước thứ tư, quy trình nhập được bắt đầu trên instance cơ sở dữ liệu cuối cùng, chạy song song với quy trình xuất. Bằng cách sử dụng cách tiếp cận di chuyển song song sử dụng các công cụ SAP như Software Provisioning Manager (SWPM) và SAP Migration Monitor, quy trình xuất/nhập được song song hóa. Sau khi hoàn thành xuất/nhập, hệ thống SAP mục tiêu được khởi động, và các bước hậu xử lý được thực hiện trên instance cuối cùng. Sau đó, instance staging được tắt và cuối cùng bị chấm dứt.\nSơ đồ đơn giản hóa ở trên trong Hình 1 không bao gồm các thành phần liên quan đến thiết lập tính sẵn sàng cao (HA) để đơn giản hóa. Tuy nhiên, các hệ thống sản xuất cần cấu hình tính sẵn sàng cao tùy thuộc vào yêu cầu kinh doanh. Để biết thông tin về thiết lập tính sẵn sàng cao với cơ sở dữ liệu Oracle trên AWS cho các cài đặt SAP NetWeaver, vui lòng tham khảo blog High availability design and solution for SAP NetWeaver installations with Oracle Data Guard (Fast-Start Failover).\nKhách hàng nên nhận được sự đồng ý của SAP để tạm thời chạy hệ thống SAP không phải Unicode trong thời lượng cutover (không có bất kỳ người dùng cuối nào trên đó) và xác thực cách tiếp cận qua một proof of concept (POC) ở đầu dự án.\nBest practices Hãy đi sâu vào các thực hành tốt nhất đã giúp giảm thiểu thời gian ngừng hoạt động trong chuyển đổi kỹ thuật. Để hiểu rõ hơn điều này, chúng tôi sẽ xem xét các hướng dẫn và thực hành được thực hiện trong từng giai đoạn của di chuyển hệ thống. Hình 2 hiển thị các giai đoạn cấp cao cho chuyển đổi Unicode và di chuyển hệ thống SAP dựa trên Oracle.\nHình 2: Các giai đoạn trong chuyển đổi Unicode và di chuyển hệ thống SAP dựa trên Oracle\rLập kế hoạch\nTrong giai đoạn lập kế hoạch, chúng tôi khuyến nghị xem xét các chiến lược để giảm kích thước các bảng kỹ thuật lớn. Kiểm tra chéo xem các công việc tái tổ chức tiêu chuẩn có được lên lịch để ngăn chặn các bảng kỹ thuật phát triển vô hạn không. Ví dụ, tuân theo các hướng dẫn trong SAP Note 1616768 cho các bảng BALDAT và BALHDR sẽ có lợi nếu các bảng log này đã trở nên quá lớn.\nQuy trình chuyển đổi Unicode yêu cầu các kiểm tra chuẩn bị cụ thể, bao gồm các báo cáo chạy lâu như SDBI_CLUSTER_CHECKS và UCCHECK. Chúng tôi khuyên nên chạy các báo cáo này vài tháng trước khi chuyển đổi thực tế. Cách tiếp cận chủ động này giúp xác định và giảm thiểu các vấn đề tiềm ẩn liên quan đến bảng cluster và cung cấp cái nhìn sâu sắc về nỗ lực phát triển cần thiết cho các điều chỉnh liên quan đến Unicode. Các kiểm tra này là một phần của hướng dẫn chuyển đổi Unicode như được đề cập trong SAP Note 551344.\nKhi chuyển sang Unicode và chuẩn bị cho cơ sở hạ tầng mục tiêu, bạn phải đánh giá các yêu cầu phần cứng liên quan đến Unicode được chỉ định trong SAP Note 1139642. Việc di chuyển terabyte dữ liệu sẽ cần kết nối mạng đáng tin cậy với băng thông yêu cầu giữa nguồn tại chỗ và AWS, đạt được bằng AWS Direct Connect hoặc AWS Site-to-Site VPN.\nMở các cổng yêu cầu cho các dịch vụ SAP và cơ sở dữ liệu Oracle trong tường lửa liên quan và security group để duy trì truy cập mạng nhất quán suốt quy trình di chuyển. Đối với các dịch vụ SAP, chẳng hạn như SAP Application Server, SAP Central Services, và SAP Software Provisioning Manager (SWPM), tham khảo tài liệu SAP “ TCP/IP Ports of All SAP Products“. Đối với cơ sở dữ liệu Oracle và sao chép Oracle Data Guard, mở Oracle Net Services Listener port được cấu hình cho các kết nối client Oracle đến cơ sở dữ liệu, cổng LOCAL_LISTENER được cấu hình cho các cơ sở dữ liệu pluggable ứng dụng (PDB) trong kiến trúc multi-tenant container database (CDB), cũng như các cổng cho listener Oracle Data Guard, nếu không sử dụng các cổng listener Oracle Net tiêu chuẩn. Tất cả các cổng này đều có thể cấu hình thủ công, và bạn nên lấy số cổng thực tế đang sử dụng từ thiết lập hiện tại.\nNếu cơ sở dữ liệu nguồn được mã hóa, tạo Oracle Wallet yêu cầu trên các hệ thống mục tiêu và sao chép tất cả các chứng chỉ SSL cần thiết từ Oracle Wallet của hệ thống nguồn. Ngoài ra, các dịch vụ listener cần được cấu hình để lắng nghe trên giao thức TCPS thay vì giao thức TCP tiêu chuẩn. Những thay đổi giao thức này phải được cập nhật trong các cấu hình tường lửa đã thực hiện trước đó.\nTrong quy trình di chuyển, việc giám sát tổng sử dụng CPU và IOPS (Input/Output Operations Per Second) là rất quan trọng. Tùy thuộc vào sử dụng CPU và IOPS dự kiến trong di chuyển, yêu cầu tăng giới hạn dịch vụ AWS. Khi nâng cấp loại instance để phù hợp với nhiều CPU hơn trong di chuyển, đảm bảo rằng hạn ngạch giới hạn instance EC2 của tài khoản AWS của bạn cho khu vực mục tiêu cho phép loại instance mong muốn và dung lượng CPU. Ví dụ, yêu cầu di chuyển 250.000 IOPS vượt quá giới hạn dịch vụ mặc định 100.000 cho “IOPS cho Provisioned IOPS SSD (io2) volume” và “IOPS modifications cho Provisioned IOPS SSD (io2) volumes”. Trong các trường hợp như vậy, bạn nên chủ động yêu cầu tăng các giới hạn này lên giá trị yêu cầu trước khi khởi xướng di chuyển. Xem xét chi tiết hạn ngạch và giới hạn trong tài liệu Amazon EC2 quotas và Amazon EBS limits.\nTrong khi di chuyển sang Unicode, các tham số hệ thống SAP cho hệ thống Unicode mục tiêu sẽ cần được điều chỉnh như được nêu trong SAP Note 790099. Tùy thuộc vào hợp đồng hỗ trợ với SAP, bạn nên xem xét sử dụng dịch vụ “Going Live Functional Upgrade service” do SAP cung cấp, cung cấp các khuyến nghị cơ bản cho hệ thống Unicode. SAP Note 2360708 cung cấp thêm thông tin về cách yêu cầu dịch vụ hỗ trợ từ SAP. Xem xét thực hiện các thay đổi tham số sớm trong môi trường không sản xuất trước khi bắt đầu kiểm tra chấp nhận người dùng. Cách tiếp cận chủ động này cho phép các đội ngũ kinh doanh và kỹ thuật đánh giá tác động của các thay đổi này và lập kế hoạch tốt hơn cho các điều chỉnh tham số tương tự trong môi trường sản xuất.\nXây dựng hệ thống\nTrong giai đoạn xây dựng, cơ sở hạ tầng được cung cấp cho cả hệ thống SAP không phải Unicode và Unicode. Hệ thống không phải Unicode phục vụ như một instance staging tạm thời, chỉ được sử dụng trong quy trình di chuyển, trong khi hệ thống Unicode phục vụ như instance cuối cùng. Một khi cơ sở hạ tầng sẵn sàng, các build vanilla SAP được thực hiện cho cả hai hệ thống không phải Unicode và Unicode. Việc xây dựng các hệ thống vanilla này cho phép thực hiện các kiểm tra kỹ thuật chuẩn bị, chẳng hạn như kiểm tra tính sẵn sàng cao, trước. Như luôn luôn, hãy đảm bảo tận dụng lợi ích linh hoạt của đám mây để tắt các instance EC2 của bạn khi chúng không được sử dụng, điều này sẽ giúp giảm chi phí phần cứng.\nKhi thiết kế bố trí đĩa cơ sở dữ liệu, lập kế hoạch số lượng Amazon EBS volumes, Amazon EBS volume types chẳng hạn như General Purpose SSD (gp3) hoặc Provisioned IOPS SSD (io2), và striping yêu cầu với Logical Volume Manager (LVM) để tối ưu hóa hiệu suất thông lượng.\nCuối cùng, kiểm tra các hạn chế EC2 của bạn. Như được nêu trong hướng dẫn người dùng Amazon EBS-optimized instance types, “Hiệu suất EBS của một instance bị giới hạn bởi giới hạn hiệu suất của loại instance, hoặc hiệu suất tổng hợp của các volume gắn kèm, bất kể cái nào nhỏ hơn”. Nếu khối lượng công việc của bạn yêu cầu hiệu suất IOPS cao và nhất quán, độ trễ thấp, độ bền cao, và bạn sẵn sàng trả phí cao cấp, các volume io2 là lựa chọn tốt hơn. Tuy nhiên, nếu khối lượng công việc của bạn có yêu cầu IOPS trung bình và chi phí là mối quan tâm, các volume gp3 là lựa chọn tiết kiệm chi phí hơn trong khi vẫn cung cấp hiệu suất và độ bền tốt. Để biết thêm thông tin chi tiết về đặc tính hiệu suất và trường hợp sử dụng của các volume gp3 và io2, bạn có thể tham khảo tài liệu AWS về Amazon EBS volume types.\nCác volume Provisioned IOPS SSD (io2) cung cấp độ bền cao nhất và độ trễ thấp nhất trong số các loại volume Amazon EBS, làm cho chúng phù hợp cho các ứng dụng quan trọng với yêu cầu hiệu suất khắt khe. Để biết thêm thông tin chi tiết về các volume Provisioned IOPS SSD (io2), bao gồm đặc tính hiệu suất, cung cấp, và thực hành tốt nhất, vui lòng tham khảo tài liệu AWS về Provisioned IOPS SSD (io2) Block Express volumes.\nMột ví dụ bố trí đĩa được cung cấp cho một instance cơ sở dữ liệu Oracle trong Bảng 2, bao gồm hai volume Amazon EBS io2 6.300 GB và 110.000 IOPS mỗi cái. Với striping, cấu hình này cung cấp thông lượng từ 3437.5 MB/s đến 8.000 MB/s.\nEBS Volumes Volume Group Volume Type Description File system EBS Size (GB) IOPS EBS Throughput (at 16 KiB I/O size) EBS Throughput (at 256 KiB I/O size) Volume 1 VG-DB io2 Database data files /oracle//sapdata\u0026lt;1..n\u0026gt; 6,300 110,000 1,718.75 MB/s 4,000 MB/s Volume 2 VG-DB io2 Database data files 6,300 110,000 1,718.75 MB/s 4,000 MB/s Total 12,600 220,000 3,437.5 MB/s 8,000 MB/s Bảng 2: Mẫu bố trí đĩa cho instance cơ sở dữ liệu Oracle\nThiết lập ODG / Sao chép / Giám sát\nGiải pháp gốc của Oracle, Oracle Data Guard (ODG), được sử dụng để tạo một bản sao nhất quán về giao dịch của cơ sở dữ liệu tại chỗ trên máy chủ cơ sở dữ liệu staging trong AWS. Ban đầu, Oracle Recovery Manager (RMAN) được sử dụng để tạo một bản sao của cơ sở dữ liệu tại chỗ trên máy chủ staging. Sau đó, Data Guard Broker được cấu hình cho change data capture (CDC), đảm bảo rằng tất cả các thay đổi dữ liệu được thực hiện trên cơ sở dữ liệu tại chỗ được ghi nhận và áp dụng cho cơ sở dữ liệu staging mục tiêu theo thời gian thực.\nCác kênh song song được sử dụng để tối đa hóa thông lượng sao chép. Vì RMAN sử dụng một large pool dành riêng cho các hoạt động sao lưu và khôi phục, cơ sở dữ liệu staging mục tiêu cần được cấu hình với các tham số LARGE_POOL_SIZE và SGA_MAX_SIZE. Các quy trình máy chủ IO cần được thêm vào người viết cơ sở dữ liệu (DBWR) để tối ưu hóa quy trình viết trong hoạt động khôi phục bằng cách tận dụng khả năng async IO của hệ điều hành.\nĐể nâng cao thêm quy trình chuyển đổi, ngay trước cutover, mở rộng instance Amazon EC2 cơ sở dữ liệu staging và mục tiêu để đáp ứng yêu cầu chuyển đổi. Ngoài ra, các điều chỉnh cần thiết cho các tham số cơ sở dữ liệu Oracle, ví dụ MEMORY_TARGET và MEMORY_MAX_TARGET trong các cơ sở dữ liệu được cấu hình với quản lý bộ nhớ tự động, để tận dụng đầy đủ các tài nguyên bổ sung. Trong chuyển đổi, cả hai cơ sở dữ liệu staging và mục tiêu được đặt ở chế độ NOARCHIVELOG để giảm thiểu chi phí liên quan đến lưu trữ log.\nCác bước chuẩn bị Unicode trong thời gian hoạt động / Các bước trước di chuyển\nChuyển đổi Unicode được thực hiện như một phần của quy trình system copy SAP. Trong quá trình này, hệ thống được xuất từ nguồn ở định dạng Unicode và sau đó được nhập vào hệ thống SAP mục tiêu. SAP System Copy Guide, và “Unicode conversion guide” như được đề cập trong SAP Note 551344), cung cấp hướng dẫn chi tiết cho quy trình này.\nTrước khi xuất và nhập Unicode có thể diễn ra, hệ thống phải trải qua một loạt các kiểm tra chuẩn bị, cả trong thời gian hoạt động và thời gian ngừng hoạt động. Các kiểm tra này được nêu trong hướng dẫn chuyển đổi Unicode. Các kiểm tra và báo cáo thời gian hoạt động được thực hiện trên hệ thống tại chỗ, trong khi các báo cáo và kiểm tra yêu cầu thời gian ngừng hoạt động hệ thống được thực hiện trên instance staging trên AWS, sau khi tiếp quản hệ thống.\nGiảm tải\nTrong thời gian ngừng hoạt động kinh doanh theo lịch, các hệ thống được khóa một cách nhẹ nhàng cho người dùng cuối. Một khi các giao diện giao tiếp được dừng, các hệ thống được chuẩn bị cho quy trình di chuyển. Trong giai đoạn này, các nhiệm vụ chuẩn bị được thực hiện như được nêu trong SAP system copy guide, bao gồm tạm dừng công việc batch, vô hiệu hóa cảnh báo, dừng xử lý nền, giải quyết các cập nhật bị hủy hoặc đang chờ, và xóa các bảng tạm thời không hợp lệ v.v. Các bước này đảm bảo di chuyển mượt mà bằng cách đưa các hệ thống đến trạng thái nhất quán trước khi các hoạt động di chuyển thực tế bắt đầu.\nTiếp quản\nSau khi xác nhận rằng các hệ thống chính và standby được đồng bộ hóa, hệ thống staging (trên AWS) được tiếp quản. Việc tiếp quản này được xác thực sử dụng quy trình switchover của Oracle Data Guard (ODG). Sau khi tiếp quản thành công, cấu hình ODG được loại bỏ để ngăn chặn bất kỳ giao tiếp ngược nào từ hệ thống mục tiêu đến môi trường tại chỗ. Sau đó, loại instance và các tham số liên quan đến cơ sở dữ liệu được điều chỉnh trước khi khởi xướng quy trình system copy.\nSao chép hệ thống (Xuất / Nhập / Giám sát)\nĐể tối ưu hóa quy trình system copy, bắt đầu bằng việc xác định các bảng hàng đầu từ danh sách DB02 hệ thống và lập kế hoạch chia các bảng lớn (ví dụ: bảng lớn hơn 20 GB). Các kỹ thuật như Package Splitting và Table Splitting được sử dụng để kích hoạt xử lý song song của xuất và nhập bảng. Chạy SAP migration time analyzer có thể cung cấp cái nhìn tổng hợp về xuất và nhập gói, cho phép xác định các cơ hội tối ưu hóa thêm. Bài tập tối ưu hóa này có thể yêu cầu nhiều lần chạy thử để xác định thứ tự đúng.\nĐối với các bảng lớn, việc chia có thể cần thiết để xử lý xuất và nhập song song. Trong khi bạn có tùy chọn sử dụng SAPup/R3ta (theo SAP system copy guide section 2.6.4) hoặc một splitter cụ thể cơ sở dữ liệu được hỗ trợ, trong trường hợp di chuyển hệ thống dựa trên Oracle, xem xét sử dụng splitter Oracle để chia bảng hiệu quả theo SAP Note 1043380.\nCác cài đặt và cấu hình tham số Oracle (ví dụ: db_cache_size, pga_aggregate_target, processes, kích thước PSAPTEMP, và vô hiệu hóa lưu trữ archive) cho system copy dựa trên R3load nên được đặt theo các khuyến nghị từ SAP Note 936441.\nTrong quy trình xuất/nhập di chuyển, một instance EC2 với số lượng CPU cao hơn, RAM, mạng, và dung lượng thông lượng lưu trữ nên được chọn. Ngoài ra, khuyến nghị sử dụng tạm thời các volume EBS io2 với giá trị IOPS được tăng cường để giảm thời gian nhập, sau đó được chuyển đổi lại thành gp3 sau, trong các hoạt động trực tuyến. Kích thước instance được chọn nên có ít nhất số lượng CPU yêu cầu để chạy nhiều quy trình R3load đồng thời và cũng hỗ trợ thông lượng EBS và IOPS đủ để đảm bảo các volume thông lượng cao của bạn không bị giới hạn. Như một quy tắc ngón tay cái, sử dụng gấp ba lần số CPU. Ví dụ, nếu bạn lập kế hoạch chạy 300 quy trình R3load, chọn một instance Amazon EC2 với tối thiểu 100 vCPUs.\nThay đổi kích thước instance và điều chỉnh các tham số trong mỗi lần chạy proof of concept (POC) tiếp theo dựa trên các phát hiện. Lập kế hoạch cho nhiều lần lặp POC trong hệ thống thử nghiệm hoặc sandbox với kích thước cơ sở dữ liệu tương tự sản xuất. Sau vài lần chạy POC, bạn nên có cấu hình tối ưu của CPU, RAM, băng thông mạng, thông lượng EBS, và IOPS yêu cầu để hoàn thành chuyển đổi Unicode trong thời gian ngừng hoạt động kỹ thuật mong muốn. Trước hoạt động xuất và nhập, loại instance được thay đổi để đạt hiệu suất tối ưu với CPU cao hơn, bộ nhớ, hiệu suất mạng, và băng thông tối đa. Ví dụ, EC2 r7i.48xlarge, được cung cấp bởi bộ xử lý Intel Xeon Scalable Thế hệ 4, cung cấp 192 CPU, 1536 GB bộ nhớ, 50 Gbps Băng thông Mạng, 5000 MB/s Thông lượng EBS Tối đa, và 240000 IOPS Tối đa.\nViệc giám sát thực thi di chuyển là cần thiết, và bạn có thể tận dụng Amazon CloudWatch để tạo bảng điều khiển giám sát trong cutover. Điều này sẽ giúp xác định bất kỳ nút thắt cổ chai nào hoặc chỉ ra các cơ hội để tinh chỉnh thêm thời gian ngừng hoạt động chuyển đổi Unicode.\nSử dụng Amazon CloudWatch dashboards, bạn có thể giám sát các EBS metrics liên quan cho thông lượng (VolumeReadBytes, VolumeWriteBytes, hoặc VolumeThroughputPercentage), và IOPS (VolumeReadOps, VolumeWriteOps, hoặc VolumeConsumedReadWriteOps) cho các volume quan trọng chẳng hạn như volume sapdata (dùng cho file sapdata Oracle) và volume sapdump (dùng để lưu trữ dữ liệu xuất/nhập từ hệ thống SAP). Ngoài ra, bạn có thể giám sát sử dụng CPU cùng với các chỉ số khác như thông lượng và IOPS. Nếu các giới hạn không được đạt và SAP migration time analyzer hiển thị một số nhiệm vụ mất nhiều thời gian hơn, bạn nên tăng số lượng quy trình R3load và cho phép các nhiệm vụ chậm hơn đó được xử lý trước trong xuất. Bạn có thể kiểm soát thứ tự xuất/nhập bằng thuộc tính orderBy như được mô tả trong phần 2.6.7 của SAP system copy guide.\nKhuyến nghị giám sát các volume chứa online redo logs Oracle, có thể được sử dụng cho các cơ chế ghi log trong xuất/nhập. Điều này áp dụng cho cả instance cơ sở dữ liệu staging và instance cơ sở dữ liệu cuối cùng. Bằng cách giám sát chặt chẽ các chỉ số này, bạn có thể xác định các nút thắt cổ chai tiềm ẩn và đưa ra quyết định sáng suốt để tối ưu hóa quy trình chuyển đổi Unicode, đảm bảo di chuyển mượt mà và hiệu quả trong thời gian ngừng hoạt động kỹ thuật mong muốn.\nHình 3 minh họa một ví dụ về Amazon CloudWatch Dashboard hiển thị các chỉ số quan trọng.\nHình 3: Bảng điều khiển Amazon CloudWatch với các chỉ số quan trọng\nCác bước sau di chuyển\nTrong giai đoạn này, tất cả các hoạt động hậu chuyển đổi Unicode, hậu di chuyển như được nêu trong hướng dẫn chuyển đổi Unicode SAP như được đề cập trong SAP Note 551344 và SAP system copy guide được thực hiện. Một khi các hoạt động này hoàn thành, bất kỳ tối ưu hóa nào được thực hiện cụ thể cho di chuyển (ví dụ: kích thước instance, IOPS, thông lượng, tham số SAP/cơ sở dữ liệu) được khôi phục về cài đặt gốc.\nTrước khi bàn giao hệ thống cho xác thực người dùng, đảm bảo rằng một bản sao lưu hệ thống ở nơi và hoạt động đầy đủ. Sau khi di chuyển hoàn thành và được xác thực bởi kinh doanh, hệ thống staging được tắt (và sau đó bị chấm dứt) để tránh chi phí không cần thiết.\nViệc tuân theo các bước được quy định một cách chính xác đảm bảo kiểm tra hậu di chuyển thành công và triển khai sản xuất.\nKết luận Trong bài đăng blog này, bạn đã học cách Bell Canada tận dụng cơ sở hạ tầng có khả năng mở rộng của AWS để hoàn thành chuyển đổi kỹ thuật Unicode của hệ thống ERP Sản xuất 11 TB của họ trong vòng dưới 5 giờ và di chuyển thành công sang AWS. Cách tiếp cận này dẫn đến giảm 75% thời gian ngừng hoạt động kỹ thuật so với quy trình chuyển đổi và di chuyển Unicode một bước, mất hơn 24 giờ. Ngoài ra, nó loại bỏ nhu cầu về tài nguyên phần cứng tại chỗ bổ sung.\nBằng cách áp dụng cách tiếp cận này, Bell Canada có thể tối ưu hóa quy trình chuyển đổi Unicode và di chuyển, giảm thiểu gián đoạn kinh doanh và tối đa hóa hiệu quả hoạt động. Khả năng mở rộng và linh hoạt của cơ sở hạ tầng AWS đóng vai trò quan trọng trong việc đạt được thành tựu đáng kể này, cho phép Bell Canada hoàn thành quy trình di chuyển phức tạp trong khung thời gian ngắn hơn đáng kể.\nTrong blog này, chúng tôi đã sử dụng Oracle Data Guard để thiết lập instance staging. Tuy nhiên, có các hạn chế khi thay đổi endianness (Big Endian và Little Endian), chẳng hạn như từ AIX (Big Endian) sang X86_64 (Little Endian), theo tài liệu của Oracle [Data Guard Support for Heterogeneous Primary and Physical Standbys in Same Data Guard Configuration](https://support.oracle.com/knowledge/Oracle Cloud/413484_1.html) (yêu cầu đăng nhập hỗ trợ Oracle). SAP Note 552464 hướng dẫn xác định endianness chính xác cho các kiến trúc và hệ điều hành khác nhau. Trong các tình huống mà khách hàng cần di chuyển hệ thống SAP không phải Unicode trên cơ sở dữ liệu Oracle từ nền tảng big-endian sang little-endian, Oracle Cross-Platform Transportable Tablespaces (XTTS) được sử dụng để di chuyển hệ thống không phải Unicode sang AWS theo blog Reducing downtime with Oracle XTTS method for cross-platform SAP migrations. Một khi hệ thống không phải Unicode có sẵn trên AWS, bạn có thể thực hiện các quy trình xuất và nhập trên AWS theo các bước được nêu trong blog này.\nTham gia thảo luận về SAP trên AWS Ngoài đội ngũ tài khoản khách hàng của bạn và các kênh AWS Support, AWS cung cấp các diễn đàn Câu hỏi \u0026amp; Trả lời công khai trên re:Post Site của chúng tôi. Đội ngũ Kiến trúc Giải pháp SAP trên AWS của chúng tôi thường xuyên theo dõi chủ đề SAP on AWS để thảo luận và câu hỏi có thể được trả lời để hỗ trợ bạn. Nếu câu hỏi của bạn không liên quan đến hỗ trợ, hãy xem xét tham gia thảo luận tại re:Post và thêm vào cơ sở kiến thức cộng đồng.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.7-blog7/",
	"title": "Blog 7",
	"tags": [],
	"description": "",
	"content": "GNOME có một đối tác cung cấp hạ tầng mới: Chào mừng AWS ! Bài đăng này được đóng góp bởi Andrea Veri từ Tổ chức GNOME. Được đăng tải lại từ gnome.org với sự cho phép.\nGNOME trước đây tự quản lý cơ sở hạ tầng của mình tại chỗ . Điều đó đã thay đổi với 1 chương trình tài trợ AWS Open Source Credits , sự tài trợ này đã cho phép đội ngũ 2 kỹ sư SRE của chúng tôi di chuyển phần lớn khối lượng công việc lên Cloud và biến môi trường Openshift hiện tại thành một môi trường có khả năng mở rộng hoàn toàn và chịu lỗi nhờ vào cơ sở hạ tầng được cung cấp bởi AWS . Bằng cách di chuyển lên Cloud, chúng tôi đã giảm đáng kể gánh nặng bảo trì , đạt được độ trễ thấp hơn cho người dùng của chúng tôi và các cộng tác viên và làm tăng tính bảo mật thông qua kiểm soát truy cập tốt hơn.\nCơ sở hạ tầng ban đầu của chúng tôi đã không tính đến sự tăng trưởng theo cấp số nhân mà GNOME đã chứng kiến trong nhiều người đóng góp và cơ sở người dùng trong 4-5 năm qua nhờ vào sự giới thiệu của GNOME Circle . GNOME Circle được hình thành bởi nhiều ứng dụng mà không phải là thành phần của lõi GNOME nhưng được định nghĩa để mở rộng hệ sinh thái mà không bị ràng buộc bởi các chính sách lõi và lịch trình ra mắt nghiêm ngặt . Việc đóng góp trong những dự án này cũng khiến cho những người đóng góp có đủ điều kiện trở thành GNOME Foundation membership và có khả năng cho phép họ nhận quyền truy cập trực tiếp để commit lên Gitlab trong trường hợp các đóng góp của họ diễn ra đều đặn trong một khoảng thời gian dài để nhận được nhiều sự tin tưởng hơn từ cộng đồng . GNOME gần đây cũng đã di chuyển sang GitLab , rời khỏi cgit và Bugzilla.\nTrong bài đăng này , chúng tôi muốn chia sẻ 1 số sự cải tiến mà chúng tôi đã làm như là kết quả của việc di chuyển lên Cloud của chúng tôi.\nLịch sử của những thách thức về mạng và lưu trữ Trong năm 2020 , chúng tôi đã ghi chép lại những thử thách trong kiến trúc chính của chúng tôi.\nCơ sở hạ tầng của chúng tôi đã được xây dựng trên OpenShift trong hệ thống cơ sở hạ tầng siêu hội tụ , sử dụng OpenShift Data Foundations (ODF) , chạy Ceph và Rook ở phía “sau” . Mặt phẳng điều khiển và khối lượng công việc của chúng tôi cũng chạy trên cùng của cùng 1 nút. Bởi vì GNOME trước đây không có mạng L3 và nhìn chung cũng không có kế hoạch nâng cấp thiết bị mạng cơ sở và/hoặc đầu tư thời gian trong việc tái cấu trúc nó , chúng tôi sẽ phải chạy cổng kết nối của mình bằng cách sử dụng máy ảo Linux thông thường với tất cả các hệ quả đi kèm. Chúng tôi cũng đã muốn tận dụng 1 nhóm Cluster bên ngoài với tốc độ lưu trữ chậm hơn , nhưng điều này đã không được hỗ trợ trong ODF và yêu cầu thêm các thành phần kết nối để làm cho nó hoạt động. Không có thay đổi nào được lên kế hoạch trong phía thiết bị mạng để tạo ra kết nối dự phòng . Điều đó có nghĩa là việc nâng cấp mã code trên các thiết bị chuyển mạch sẽ yêu cầu dừng toàn bộ dịch vụ trong 1 khoảng thời gian. Chúng tôi phải làm việc với đội ngũ hỗ trợ của Dell cho mọi linh kiện phần cứng bị hỏng , việc đó thêm phần vất vả. Với cộng đồng người dùng và người đóng góp GNOME luôn tăng , chúng tôi chưa bao giờ có cách nào thật sự hiệu quả để mở rộng quy mô tài nguyên máy tính do hạn chế về ngân sách. Những sự cải tiến khi di chuyển lên Cloud Vào năm 2024 , trong suốt quá trình chu kì làm mới phần cứng , chúng tôi đã bắt đầu đánh giá ý tưởng về việc di chuyển lên Cloud công khai . Chúng tôi đã tham gia chương trình AWS Open Source Credits trong nhiều năm và nhận được sự tài trợ cho 1 bộ của kho lưu trữ Amazon Simple Storage Service (Amazon S3) , cái mà chúng tôi sử dụng rộng rãi thông qua dịch vụ GNOME . Dựa trên kinh nghiệm trước đó của chúng tôi với những chương trình và những người điều hành nó , Chúng tôi quyết định gửi yêu cầu tài trợ từ AWS cho toàn bộ cơ sở hạ tầng và yêu cầu đã được chấp nhận 1 cách thiện chí.\nTôi tin rằng việc then chốt là để hiểu được tại sao AWS lại giải quyết được những thách thức về cơ sở hạ tầng chúng tôi có khi là 1 đội nhỏ SRE ( chỉ có 2 kỹ sư ) . Điều quan trọng nhất là , việc chuyển đổi này đã giảm đáng kể công việc bảo trì vất vả mà chúng tôi đã phải chịu.\nSử dụng các dịch vụ mạng được định nghĩa bằng phần mềm do AWS cung cấp , chúng tôi không còn phải phụ thuộc vào đội ngũ bên ngoài để thay đổi các cấu trúc mạng cơ sở . Điều này cũng giúp cho chúng tôi 1 cách để dùng các cổng kết nối và NAT dự phòng mà không phải làm lộ các nút xử lý ra ngoài Internet. Chúng tôi hiện giờ dùng các phiên bản AWS Elastic Load Balancing (ELB) ( bộ cân bằng tải cổ điển là 1 loại duy nhất được hỗ trợ bởi OpenShift cho tới bây giờ ) như là điểm vào lưu lượng truy cập cho nhóm máy chủ OpenShift của chúng tôi . Điều này giúp giảm độ trễ vì chúng tôi bây giờ đang vận hành trong cùng 1 VPC thay vì phụ thuộc vào nhà cung cấp cân bằng tải bên ngoài . Điều này cũng đi kèm khả năng truy cập vào các API của security group , cái mà giúp chúng ta dùng thêm các IP một cách động . Điều này là thiết yếu khi chúng tôi có những cá nhân hoặc tổ chức lạm dụng hàng ngàn truy vấn mỗi phút cho các dịch vụ GNOME cụ thể. Chúng tôi cũng sử dụng Amazon Elastic Block Store (Amazon EBS ) và Amazon Elastic File System ( Amazon EFS ) thông qua trình điều khiển OpenShift CSI . Việc này cho phép chúng tôi tránh được việc phải quản lý cụm máy chủ Ceph , cái mà là một lợi thế lớn trong vấn đề về mặt bảo trì và vận hành. Với các phiên bản AWS Graviton , giờ chúng tôi đã có quyền truy cập vào các máy chủ ARM64 , cái mà chúng tôi có thể tận dụng tối đa vì chúng thường rẻ hơn so với những máy Intel tương đương. Với mức độ rộng rãi mà chúng tôi sử dụng Amazon S3 trên cơ sở hạ tầng , chúng tôi có thể giảm độ trễ và chi phí nhờ việc sử dụng VPC S3 endpoints nội bộ. Chúng tôi tận dụng AWS Identity và Access Management(IAM) để cung cấp quyền truy cập chi tiết đến các dịch vụ AWS , giúp chúng tôi có khả năng cho phép các nhà đóng góp cá nhân để quản lý các bộ tài nguyên giới hạn mà không cần phải quyền cao hơn. Chúng tôi giờ đã hoàn thành việc trừu tượng hóa việc quản lý phần cứng , cái mà thiết yếu cho một đội chỉ có 2 kỹ sư, những người đang cố gắng tránh bất kì gánh nặng bảo trì phát sinh nào. Cảm ơn bạn, AWS! Tôi muốn cảm ơn AWS vì sự tài trợ dành của họ và cơ hội to lớn mà họ đang trao cho cơ sở hạ tầng GNOME để cung cấp các khối lượng công việc bền bỉ , ổn định và có tính sẵn sàng cao đến những người dùng và người đóng góp của GNOME trên toàn cầu.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.8-blog8/",
	"title": "Blog 8",
	"tags": [],
	"description": "",
	"content": "Tận dụng các Mô hình Ngôn ngữ lớn (LLM) như 1 Sự bổ sung cho Việc điều chỉnh Siêu tham số Truyền thống Khi tìm cách cải thiện hiệu suất mô hình máy học ,việc điều chỉnh siêu tham số thường là khuyến nghị hàng đầu . Tuy nhiên , việc tiếp cận này đối mặt với nhiều hạn chế đáng kể, đặc biệt đối với những mô hình phức tạp yêu cầu thời gian huấn luyện kéo dài . Trong bài viết này , chúng ta sẽ khám phá một cách tiếp cận mới ,kết hợp phân tích độ chuẩn gradient với hướng dẫn từ Mô hình Ngôn Ngữ Lớn (LLM) để thiết kế lại mô hình mạng nơ-ron 1 cách thông minh . Phương pháp này có thể xác định và giải quyết nút thắt hiệu suất mà không có gánh nặng tính toán của việc điều chỉnh siêu tham số truyền thống . Thông qua những ví dụ thực tiễn , chúng tôi sẽ chỉ ra kỹ thuật của mình tận dụng LLM như những cố vấn kiến trúc , cung cấp những khuyến nghị trọng tâm , giải quyết trực tiếp những điểm yếu đã được xác định trong thiết kế mạng .\nBối cảnh Tinh chỉnh siêu tham số truyền thống thường sử dụng Tối ưu hóa Bayesian, xây dựng một mô hình toán học về mối quan hệ giữa tham số và hiệu suất để tìm ra lời giải tối ưu một cách hiệu quả, với số lần đánh giá ít hơn so với các phương pháp như giải thuật di truyền.\nTuy nhiên, tồn tại nhiều hạn chế thực tế đáng kể. Nếu không có điện toán hiệu năng cao , việc thực thi tuần tự sẽ mất rất nhiều thời gian — trong khi các mô hình nhẹ có thể hoàn thành tối ưu hóa trong 24 giờ, thì các bài toán phức tạp như học tăng cường (reinforcement learning) hoặc tập dữ liệu thị giác máy tính lớn thường khiến phương pháp truyền thống trở nên không khả thi trên phần cứng cục bộ. Các giải pháp Cloud như AWS Batch, AWS Parallel Computing Service, hoặc AWS ParallelCluster cho phép song song hóa ở quy mô lớn, có thể mang lại ROI đáng kể cho các mô hình phức tạp dù tốn thêm chi phí.\nViệc tinh chỉnh truyền thống cũng đòi hỏi phải tham số hóa rõ ràng tất cả những gì cần tối ưu. Trong khi các tham số đơn giản như tốc độ học (learning rate) dễ dàng được tích hợp, việc cải tiến toàn bộ cấu trúc kiến trúc đem lại nhiều thách thức lớn khi triển khai. Các phương pháp như Neuroevolution of Augmented Topologies (NEAT) có thể giải quyết việc tối ưu hóa kiến trúc nhưng thường hy sinh hiệu quả mẫu.\nĐây chính là nơi mà các Mô hình ngôn ngữ lớn (LLM) mang đến một lựa chọn hấp dẫn. LLM hoạt động như những chuyên gia tổng hợp, kết hợp tri thức trên toàn bộ phổ phát triển mạng nơ-ron — thực chất là nội suy hàng thập kỷ tri thức của con người trên các lĩnh vực chuyên biệt như thị giác máy tính, NLP, và học tăng cường. Chúng đưa ra khuyến nghị kiến trúc dựa trên trí tuệ tập thể được mã hóa trong tài liệu kỹ thuật, thay vì dựa vào các tìm kiếm thực nghiệm tiêu tốn nhiều tài nguyên.\nPhương pháp của chúng tôi tập trung cụ thể vào việc sử dụng LLM để thiết kế và điều chỉnh kiến trúc mạng nơ-ron dựa trên phân tích độ chuẩn gradient, bổ sung cho các framework như Liu et al. (2022) AgentHPO, vốn cung cấp khả năng tối ưu siêu tham số tổng quát hơn cho nhiều tác vụ ML đa dạng.\nMột quy trình tác nhân cho thiết kế mạng nơ-ron Trong quá trình khảo sát của chúng tôi về sự chỉnh sửa mã dựa trên LLM , chúng tôi đã triển khai 1 quy trình tác nhân để quản lý các quá trình suy luận lặp và thực thi . Hình 1 minh họa mô hình hoàn chỉnh cho hệ thống của chúng tôi , tận dụng LangGraph cho điều phối quy trình và định tuyến quyết định giữa các tác nhân . Việc triển khai của chúng tôi chạy trên các máy ảo EC2 g6.24xlarge được trang bị 4x NVIDIA L4 Tensor Core GPUs để xử lý quá trình huấn luyện mạng nơ-ron . Các tương tác với LLM diễn ra thông qua các lời gọi Python API đến Amazon Bedrock sử dụng Boto3. Chúng tôi sử dụng triệt để các mô hình Claude khác nhau cho các công việc cụ thể : Claude 3.7 Sonnet cho các tác nhân kiểm thử, Claude 3.7 Sonnet với khả năng kích hoạt suy luận cho việc viết mã code , và các mô hình nhỏ hơn/nhanh hơn như Claude 3.0 Haiku cho việc tạo ra báo cáo và kiểm tra tính hợp lệ của mã code .\nHình 1 : Quy trình đa tác nhân cho thiết kế mạng nơ-ron tại chỗ. LLM icon dùng trong Amazon Bedrock API.\nQuy trình của chúng tôi bắt đầu (bước 1) với sự huấn luyện theo lô nhỏ tiêu chuẩn trong khi triển khai cơ chế xử lý lỗi mạnh mẽ - các lỗi trong thời gian chạy được phát hiện và chuyển tiếp tới tác nhân giám sát cho phân tích và sửa mã code .\nTheo chu kỳ cố định ( mỗi 50-100 epoch ) , chúng tôi trích ra (bước 2) các thông tin then chốt trong huấn luyện bao gồm độ chuẩn gradient (sẽ thảo luận trong đoạn sau ) và các chỉ số tiêu chuẩn như độ mất mát (loss) và độ chuẩn xác(accuracy) . Dạng biểu diễn trạng thái này được định dạng thành 1 prompt(bước 3) cho 1 LLM để đánh giá tình trạng , sự ổn định huấn luyện và phát hiện vấn đề .\nLangGraph là 1 framework dùng để tạo ra những quy trình có trạng thái và nhiều bước với các mô hình ngôn ngữ . Định tuyến quyết định (bước 4) dựa trên LangGraph phân tích đánh giá sức khỏe và điều hướng quy trình tới 1 trong 3 con đường : tối ưu hóa siêu tham số , chỉnh sửa cấu trúc mạng nơ-ron , hoặc sự hoàn tất huấn luyện với việc tạo báo cáo . Đối với việc điều chỉnh siêu tham số , LLM cung cấp các khuyến nghị như cấu trúc JSON có thể áp dụng 1 cách trực tiếp vào huấn luyện .\nĐối với những chỉnh sửa về kiến trúc, chúng tôi sử dụng hai LLM cộng tác: một LLM chính tạo ra các module Python mới định nghĩa kiến trúc mạng đã sửa đổi, trong khi LLM thứ hai đóng vai trò kiểm tra/sửa lỗi bằng cách cố gắng thực thi đoạn mã code đã tạo. Thông qua quy trình lặp đi lặp lại giữa người viết mã và người kiểm tra/sửa lỗi mã, các lỗi được phát hiện, phân tích và sửa chữa trước khi lưu lại mã cuối cùng. Sau khi được xác thực thành công với dữ liệu đầu vào giả lập, quá trình huấn luyện sẽ khởi động lại (bước 5) với kiến trúc đã được cải thiện.\nThiết kế mạng nơ-ron thông qua lăng kính của độ chuẩn gradient Trong khi các số liệu truyền thống như hàm mất mát và độ chính xác cung cấp những hiểu biết cơ bản, phân tích chuẩn gradient (gradient norm analysis) tiết lộ sự hiểu biết sâu sắc hơn về hiệu quả của kiến trúc. Chuẩn gradient—độ lớn của các tín hiệu cập nhật trọng số trong quá trình huấn luyện—đóng vai trò là các công cụ chẩn đoán mạnh mẽ, cho thấy liệu một mạng có quá sâu, không đủ rộng, được chuẩn hóa kém hay đang sử dụng các hàm kích hoạt không tối ưu hay không. Chuẩn gradient quá lớn hoặc quá nhỏ thường báo hiệu các vấn đề kiến trúc cụ thể mà các LLM có thể diễn giải dựa trên các mô hình quan sát được trong suốt hàng thập kỷ nghiên cứu về mạng nơ-ron. Để chứng minh khả năng này, chúng tôi sẽ thử nghiệm với một mô hình phân loại thị giác máy tính (được hiển thị bên dưới) được huấn luyện trên tập dữ liệu CIFAR , kết hợp các thiết kế lỗi có chủ ý với tốc độ học cực kì cao (0.1) và thuật toán tối ưu hóa SGD cơ bản mà không có quán tính hoặc các thành phần thích ứng. Bằng cách xem xét cách LLM diễn giải những mô hình chuẩn gradient này trong suốt các epochs huấn luyện, chúng ta sẽ quan sát được khả năng của nó trong việc chẩn đoán các khiếm khuyết kiến trúc cụ thể và đề xuất các sửa đổi phù hợp—tận dụng hiệu quả các tín hiệu dựa trên gradient tương tự mà những người có kinh nghiệm sử dụng để gỡ lỗi các thiết kế mạng.\nimport torch import torch.nn as nn class CNN(nn.Module): \u0026#34;\u0026#34;\u0026#34; An extremely simple CNN with a single convolutional layer followed by a fully connected layer for classification. Uses sigmoid activation instead of ReLU. \u0026#34;\u0026#34;\u0026#34; def __init__(self): super(CNN, self).__init__() # Single convolutional layer self.conv1 = nn.Conv2d(3, 16, kernel_size=15, padding=1) # With no pooling, feature size remains 32x32, so: 32x32x16 = 16384 self.fc = nn.Linear(16384, 10) def forward(self, x): # Single convolutional layer with sigmoid activation x = torch.sigmoid(self.conv1(x)) # No pooling, so dimensions stay the same # Flatten for fully connected layer x = torch.flatten(x, 1) # Classification layer x = self.fc(x) return x Sau khi cho phép quá trình huấn luyện tiến triển trong khoảng 50-100 epochs, chúng tôi đã cho bộ tối ưu hóa đủ thời gian để xác định một thung lũng tối ưu phù hợp vượt ra khỏi sự hỗn loạn ban đầu của việc khởi tạo trọng số. Tại thời điểm kiểm tra này, chúng tôi đã cung cấp lịch sử huấn luyện và chuẩn gradient cho Claude 3.7 thông qua Amazon Bedrock, yêu cầu một bản đánh giá về hiệu suất và tính ổn định của mô hình ( xem dòng 219 ở đây) . LLM đã phản hồi bằng một đề xuất thay đổi kiến trúc mạng nơ-ron , đồng thời đưa ra phân tích sau.\n\u0026#34;Explanation: While the model shows some minimal improvement (validation accuracy from 17.6% to 19.4% over 50 epochs), progress is extremely slow and erratic. The loss isn\u0026#39;t consistently decreasing, and the model appears to be struggling with fundamental architectural issues. The high learning rate (0.1) combined with SGD optimizer is likely causing training instability given the complex architecture. The lack of batch normalization is also problematic.\u0026#34; Bước đánh giá này đóng vai trò như một điểm định tuyến quan trọng trong quy trình LangGraph của chúng tôi. LLM đã xác định rằng cần thiết phải đại tu toàn bộ kiến trúc, tạo ra mã PyTorch mới làm tăng đáng kể độ phức tạp và sửa đổi hàm mất mát. Khối mã tiếp theo hiển thị mô hình mạng nơ-ron đã được sửa đổi hoàn toàn này, mô hình này đã được LLM thứ cấp xác thực và kiểm tra lỗi trước khi triển khai.\nclass ConvBlock(nn.Module): \u0026#34;\u0026#34;\u0026#34; A convolutional block with batch normalization and residual connection to improve gradient flow and training stability \u0026#34;\u0026#34;\u0026#34; def __init__(self, in_channels, out_channels, kernel_size=3, stride=1): super(ConvBlock, self).__init__() self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=kernel_size//2, bias=False) self.bn = nn.BatchNorm2d(out_channels) # FIX: More explicit handling of skip connection to ensure dimension matching if in_channels == out_channels and stride == 1: # Identity shortcut when dimensions match self.residual = nn.Identity() else: # 1x1 conv to match both channel dimensions and spatial dimensions (if stride \u0026gt; 1) self.residual = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False) def forward(self, x): identity = x # Main branch out = self.conv(x) out = self.bn(out) out = F.relu(out) # Add residual connection out = out + self.residual(identity) # FIX: Added ReLU after addition (standard in ResNet blocks) out = F.relu(out) return out class CNN(nn.Module): \u0026#34;\u0026#34;\u0026#34; Improved CNN architecture that addresses gradient flow issues: 1. Replaces large kernel sizes (15x15) with smaller, more efficient 3x3 kernels 2. Adds batch normalization to stabilize gradients 3. Uses multiple smaller convolutional layers with residual connections 4. Balances FC layers to prevent bottlenecks 5. Implements proper pooling strategy to reduce parameter count 6. Uses ReLU activations instead of sigmoid for better gradient flow 7. Adds dropout for regularization \u0026#34;\u0026#34;\u0026#34; def __init__(self, num_classes=10): super(CNN, self).__init__() # Initial convolution with moderate number of filters self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1, bias=False) self.bn1 = nn.BatchNorm2d(32) # Convolutional blocks with gradually increasing filters # Input: 16x16x32, Output: 16x16x64 self.block1 = ConvBlock(32, 64) # Input: 8x8x64, Output: 8x8x128 self.block2 = ConvBlock(64, 128) # Input: 4x4x128, Output: 4x4x256 self.block3 = ConvBlock(128, 256) # Pooling layers to reduce spatial dimensions self.pool = nn.MaxPool2d(2, 2) # More balanced FC layer architecture # After 3 pooling operations (32 -\u0026gt; 16 -\u0026gt; 8 -\u0026gt; 4), feature map is 4x4x256 = 4096 self.fc1 = nn.Linear(4096, 512) self.fc2 = nn.Linear(512, 128) self.fc3 = nn.Linear(128, num_classes) # Dropout for regularization self.dropout = nn.Dropout(0.3) # Reduced from 0.5 to prevent too much regularization # Proper weight initialization for better gradient flow self._initialize_weights() def _initialize_weights(self): \u0026#34;\u0026#34;\u0026#34;Initialize weights using Kaiming initialization for ReLU activations\u0026#34;\u0026#34;\u0026#34; for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode=\u0026#39;fan_out\u0026#39;, nonlinearity=\u0026#39;relu\u0026#39;) elif isinstance(m, nn.BatchNorm2d): nn.init.constant_(m.weight, 1) nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.kaiming_normal_(m.weight, mode=\u0026#39;fan_out\u0026#39;, nonlinearity=\u0026#39;relu\u0026#39;) if m.bias is not None: nn.init.constant_(m.bias, 0) def forward(self, x): \u0026#34;\u0026#34;\u0026#34; Forward pass with explicit shape tracking comments Input shape: [batch_size, 3, 32, 32] \u0026#34;\u0026#34;\u0026#34; # Initial convolution: [batch_size, 3, 32, 32] -\u0026gt; [batch_size, 32, 32, 32] x = self.conv1(x) x = self.bn1(x) x = F.relu(x) # First pooling: [batch_size, 32, 32, 32] -\u0026gt; [batch_size, 32, 16, 16] x = self.pool(x) # Block 1: [batch_size, 32, 16, 16] -\u0026gt; [batch_size, 64, 16, 16] x = self.block1(x) # Second pooling: [batch_size, 64, 16, 16] -\u0026gt; [batch_size, 64, 8, 8] x = self.pool(x) # Block 2: [batch_size, 64, 8, 8] -\u0026gt; [batch_size, 128, 8, 8] x = self.block2(x) # Third pooling: [batch_size, 128, 8, 8] -\u0026gt; [batch_size, 128, 4, 4] x = self.pool(x) # Block 3: [batch_size, 128, 4, 4] -\u0026gt; [batch_size, 256, 4, 4] x = self.block3(x) # Flatten: [batch_size, 256, 4, 4] -\u0026gt; [batch_size, 4096] x = torch.flatten(x, 1) # FC layers with dropout x = F.relu(self.fc1(x)) # [batch_size, 4096] -\u0026gt; [batch_size, 512] x = self.dropout(x) x = F.relu(self.fc2(x)) # [batch_size, 512] -\u0026gt; [batch_size, 128] x = self.dropout(x) # Output: [batch_size, 128] -\u0026gt; [batch_size, num_classes] x = self.fc3(x) return x def loss_function(self, outputs, targets): \u0026#34;\u0026#34;\u0026#34; Custom loss function that helps with gradient scaling. Uses label smoothing to prevent overconfidence and improve gradient flow. \u0026#34;\u0026#34;\u0026#34; return nn.CrossEntropyLoss(label_smoothing=0.1)(outputs, targets) Thật thú vị là, khi quy trình làm việc chủ động (một quy trình tự động, tự định hướng, nơi hệ thống AI đưa ra các quyết định độc lập mà không cần sự can thiệp của con người) bắt đầu quá trình huấn luyện với mô hình đã được sửa đổi của nó, chúng ta quan sát thấy hàm mất mát (loss) tăng vọt ngay lập tức, làm trì trệ tiến trình. LLM phát hiện ra sự mất ổn định này và tự động thực hiện các sửa đổi quan trọng đối với chiến lược tối ưu hóa, bao gồm điều chỉnh tốc độ học (learning rate) và chuyển sang bộ tối ưu hóa Adam. Từ thời điểm này trở đi, LLM liên tục (cứ sau mỗi 50 – 100 epoch) giám sát động lực học của quá trình huấn luyện, thực hiện các điều chỉnh lặp đi lặp lại đối với các tham số tối ưu hóa hoặc kiến trúc mạng nơ-ron cho đến khi nó xác định rằng quá trình huấn luyện đã đủ ổn định để việc triển khai LangGraph hoàn thành quy trình mà không cần sự can thiệp thêm của LLM.\nHình 2 trình bày một phân tích toàn diện về hiệu suất của mô hình cơ sở trên 600 vòng huấn luyện (epochs). Phần trên bên trái của hình cho thấy sai số huấn luyện giảm mạnh trong 25 vòng huấn luyện đầu tiên, từ khoảng 10² xuống 10¹, sau đó hoàn toàn đi ngang quanh mức 10⁰, cho thấy mô hình đã ngừng học một cách có ý nghĩa mặc dù tiếp tục được huấn luyện. Sự hội tụ sớm này còn được thể hiện rõ hơn ở phần trên bên phải của hình, nơi độ chính xác huấn luyện (màu xanh lam) dao động mạnh giữa 7-14%, trong khi độ chính xác kiểm định (màu cam) vẫn cố định ở mức xấp xỉ 10% trong suốt quá trình huấn luyện, xác nhận rằng không có sự học hỏi thực sự nào đang diễn ra.\nCác đồ thị phía dưới cung cấp thông tin chi tiết về hành vi của gradient (độ dốc). Chuẩn gradient tổng (phía dưới bên trái) ban đầu tăng vọt lên trên 10² trước khi giảm nhanh chóng và ổn định xung quanh 10⁻¹ trong thời gian còn lại của quá trình huấn luyện. Chuẩn gradient riêng cho từng lớp (phía dưới bên phải) cũng ổn định tương tự sau các epoch (lượt) huấn luyện ban đầu, với gradient của các lớp khác nhau ổn định ở các độ lớn khác nhau trong khoảng từ 10⁻³ đến 10⁻¹. Mặc dù các mô hình gradient này có vẻ ổn định về mặt số học, nhưng chúng không thể thúc đẩy các cập nhật tham số có ý nghĩa để cải thiện hiệu suất của mô hình, cho thấy các vấn đề tối ưu hóa vượt ra ngoài sự bất ổn gradient đơn thuần.\nHình 2 : Kết quả khi sử dụng CNN cơ bản mà không điều chỉnh LLM\nNgược lại, Hình 3 cho thấy hiệu suất vượt trội đáng kể của mạng neural được thiết kế bởi LLM với các siêu tham số tối ưu hóa được lựa chọn cẩn thận. Sau khoảng 4 lần lặp thiết kế bởi LLM, mô hình này đạt được độ chính xác xác thực (validation accuracy) khoảng 83%, thể hiện một sự cải thiện đáng kể so với mô hình cơ sở. Mặc dù đây là một tiến bộ đáng kể, nhưng cần lưu ý rằng các mô hình hiện đại (state-of-the-art) để phân loại CIFAR hiện đang đạt được độ chính xác trên 99% (EfficientNet-L2) , cho thấy vẫn còn dư địa để tối ưu hóa hơn nữa. Khoảng cách giữa kết quả của chúng tôi và khả năng tinh chỉnh thủ công tiên tiến nhất có thể xuất phát từ các kỹ thuật tiên tiến mà LLM của chúng tôi có thể chưa kết hợp hoặc chưa biết đến. Ví dụ, các phương pháp tối ưu hóa như Sharpness Aware Minimization (SAM) đã đẩy EfficientNet-L2 đạt độ chính xác kỷ lục bằng cách cải thiện khả năng khái quát hóa thông qua tối ưu hóa cực tiểu phẳng. Các kỹ thuật chuyên biệt như vậy có thể nằm ngoài dữ liệu huấn luyện của LLM hoặc không được xem xét trong các ràng buộc thử nghiệm của chúng tôi. Điều này cho thấy phương pháp của chúng tôi có thể được hưởng lợi đáng kể từ việc bổ sung hệ thống RAG kết hợp các tiến bộ học thuật gần đây, cho phép LLM tận dụng các nghiên cứu tiên tiến có thể đã xuất hiện sau thời điểm cắt kiến thức của nó. Tuy nhiên, sự khác biệt về hiệu suất nhấn mạnh tính hiệu quả của việc cho phép LLM điều chỉnh linh hoạt thiết kế mạng nơ-ron và các tham số huấn luyện để đáp ứng với các động lực huấn luyện được quan sát.\nHình 3 : Kết quả khi sử dụng thiết kế CNN do LLM và các tham số tối ưu hóa được chọn bởi LLM .\nKết luận Các LLM cung cấp một giải pháp thay thế mạnh mẽ cho việc điều chỉnh siêu tham số truyền thống, tận dụng kiến thức tổng hợp để cải thiện mạng nơ-ron mà không cần tìm kiếm tham số một cách triệt để. Kiến trúc được thiết kế bởi LLM trong thử nghiệm của chúng tôi đã đạt được độ chính xác xác thực là 83% trên CIFAR, vượt trội đáng kể so với mô hình cơ sở. Cách tiếp cận này đặc biệt có giá trị cho những người thực hành có nguồn lực tính toán hạn chế hoặc những người làm việc với các mô hình đòi hỏi chu kỳ huấn luyện dài.\nMột chiến lược mang tính bổ trợ có thể kết hợp việc sử dụng các mô hình ngôn ngữ lớn (LLMs) cho các quyết định kiến trúc quan trọng với việc điều chỉnh siêu tham số truyền thống tập trung cho việc tinh chỉnh cuối cùng, có khả năng mang lại những ưu điểm tốt nhất của cả hai. Toàn bộ mã nguồn cho dự án này, bao gồm cả việc triển khai quy trình làm việc LangGraph đa tác nhân và tất cả các mô hình mạng nơ-ron, đều có sẵn trong AWS Samples repository trên GitHub.\nChúng tôi khuyến khích các nhà nghiên cứu và những người thực hành khám phá và xây dựng dựa trên những phát hiện này.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.9-blog9/",
	"title": "Blog 9",
	"tags": [],
	"description": "",
	"content": "Góc nhìn thống nhất của bạn về du khách và khách hàng từ Amazon Connect Customer Profiles Trong lịch sử , những công ty ngành du lịch và khách sạn thường dựa vào các chương trình khách hàng thân thiết để làm chính xác điều đó - xây dựng lòng trung thành . Tuy nhiên 1 báo cáo McKinsey \u0026amp; Company cho thấy rằng mức độ trung thành đang giảm . Cùng 1 nghiên cứu từ MCKinsey cũng đưa ra khuyến nghị rằng các công ty ngành du lịch và khách sạn có thể giành được lòng trung thành bằng cách “cung cấp những trải nghiệm độc đáo thoả mãn“ thông qua nhiều sự tương tác được cá nhân hoá hơn .\nMấu chốt để làm hài lòng khách hàng và cung cấp những trải nghiệm liền mạch mà họ muốn bắt đầu bằng dữ liệu khách hàng chính xác . Hôm nay , chúng tôi rất hứng thú để thông báo Amazon Connect Customer Profile cho ngành du lịch và khách sạn , 1 tính năng cụ thể cho ngành công nghiệp nằm trong Amazon Connect , nó giúp cho các công ty ngành du lịch và khách sạn cung cấp những trải nghiệm cá nhân hoá thông qua mỗi điểm chạm của khách hàng.\nTrong bài viết này , chúng ta sẽ khám phá cách các công ty ngành du lịch và khách sạn hiện giờ có thể dùng Amazon Connect Customer Profiles để tạo những hồ sơ của du khách và khách hàng thống nhất , cải thiện hợp tác dữ liệu cho các chiến dịch truyền thông ,các đối tác và đo lường và sử dụng các AI tạo sinh để mang đến nhiều sự tương tác và dịch vụ cá nhân hoá hơn .\nThống nhất dữ liệu khách hàng là thử thách Trong khi những tổ chức đều khao khát để có góc nhìn duy nhất của khách hàng , những công ty du lịch và khách sạn biết rõ điều này thử thách như thế nào . Các công ty du lịch và khách sạn có rất nhiều dữ liệu khách hàng của riêng họ. Tuy nhiên, những dữ liệu này lại bị tách rời. Chúng có thể nằm trong các công cụ đặt phòng, hệ thống quản lý cơ sở lưu trú, hệ thống khách hàng thân thiết, trung tâm liên hệ và nhiều nơi khác. Dữ liệu có thể nằm trên đám mây hoặc tại chỗ. Nó có thể ở dạng có cấu trúc hoặc không có cấu trúc. Dữ liệu này có thể được dùng để cải thiện hành trình của khách du lịch và khách lưu trú ở mỗi bước, nhưng chỉ khi nó được gộp lại thành một cái nhìn thống nhất về khách hàng. Sự chia nhỏ này khiến việc mang đến trải nghiệm cá nhân hóa và nhất quán trên nhiều kênh và điểm chạm trở nên khó khăn.\nAmazon Connect Customer Profiles hiện nay giải quyết những thách thức này bằng cách cung cấp một ánh xạ được xây dựng riêng cho các ứng dụng phổ biến trong ngành du lịch và khách sạn. Dịch vụ này đi kèm với các mô hình dữ liệu được cấu hình sẵn, được thiết kế đặc biệt cho các trường hợp sử dụng trong lĩnh vực du lịch và khách sạn, giúp các công ty có thể nhanh chóng triển khai một cái nhìn thống nhất về khách hàng, đồng thời hiểu được những nhu cầu riêng biệt của họ. Dịch vụ này kết hợp dữ liệu khách hàng từ hơn 75 nguồn khác nhau, bao gồm các nền tảng dữ liệu khách hàng hàng đầu (CDP), các nền tảng tương tác, và những ứng dụng chuyên biệt cho du lịch và khách sạn, thông qua quy trình tự động thu thập và hợp nhất dữ liệu.\nLàm giàu dữ liệu khách hàng Quy trình hợp nhất hồ sơ theo thời gian thực sử dụng phương pháp loại bỏ trùng lặp dựa trên quy tắc để đảm bảo các hồ sơ khách hàng chính xác và thống nhất. Điều này giúp các công ty có được cái nhìn tổng thể về từng khách hàng tại mọi thời điểm. Amazon Connect Customer Profiles luôn được cập nhật theo thời gian thực thông qua các kết nối trực tiếp với nguồn dữ liệu, giúp bạn luôn nắm bắt được những thông tin mới nhất về khách hàng của mình.\nAmazon Connect Customer Profiles được xây dựng để xử lý quy mô cấp doanh nghiệp, hỗ trợ dung lượng dữ liệu lên đến hàng terabyte với hiệu năng dưới 50 mili-giây, đáp ứng nhu cầu của các tổ chức lớn nhất thế giới. Ngoài ra, dịch vụ này hiện có sẵn tại 10 khu vực toàn cầu, tích hợp sẵn các tiêu chuẩn tuân thủ như GDPR, PCI, HIPAA và CCPA, giúp các công ty có thể sử dụng dịch vụ trong khi vẫn đáp ứng các yêu cầu về quy định khác nhau.\nKích hoạt trong Amazon Connect và hơn thế nữa Với Amazon Connect Customer Profiles thống nhất, các tổ chức có thể kích hoạt dữ liệu khách hàng trên nhiều kênh và tại nhiều điểm tương tác khác nhau. Khách hàng sử dụng Amazon Connect sẽ có trải nghiệm tự phục vụ hiệu quả hơn, thông qua việc định tuyến tối ưu hơn hoặc phản hồi trong trò chuyện được cá nhân hóa hơn. Các nhân viên sử dụng Amazon Connect có thể truy cập toàn bộ ngữ cảnh của khách hàng, giúp họ tương tác cá nhân hóa hơn trong những tình huống cần đến phán đoán của con người.\nAmazon Connect Customer Profiles còn được nâng cấp với các khả năng AI tạo sinh ,bao gồm trợ lý AI hỗ trợ tạo các nhóm khách hàng có thể hành động hoặc các thuộc tính được tính toán để dự đoán hành vi khách hàng tốt hơn. Những tính năng này cho phép các công ty không chỉ hiểu khách hàng của mình rõ hơn mà còn có thể dự đoán trước nhu cầu và sở thích của họ.\nTrình khám phá mới của Amazon Connect Customer Profiles thay đổi cách mà các doanh nghiệp trong lĩnh vực du lịch và khách sạn hiểu và tương tác với khách hàng của họ. Giao diện trực quan này hợp nhất dữ liệu khách hàng bị phân mảnh thành một cái nhìn toàn diện kiểu “customer-360”, giúp các doanh nghiệp chuyển đổi dữ liệu khách hàng thành những thông tin chi tiết có thể hành động, thúc đẩy lòng trung thành và doanh thu.\n*Tìm khách hàng ngay lập tức bằng cách sử dụng nhiều thông tin nhận dạng cùng lúc (email, số điện thoại, mã đặt chỗ, …) với kết quả tìm kiếm theo thời gian thực.\n*Tùy chỉnh giao diện hiển thị để ưu tiên những thông tin liên quan nhất cho nhu cầu kinh doanh cụ thể.\n*Truy cập toàn bộ ngữ cảnh khách hàng bao gồm dữ liệu nhân khẩu học, lịch sử liên lạc, hành vi tương tác và nhóm khách hàng mà họ thuộc về.\n*Tận dụng các thông tin chi tiết được hỗ trợ bởi AI với phần tóm tắt khách hàng làm nổi bật các mẫu hành vi chính và các suy luận cá nhân hóa về hành vi của khách hàng.\nBắt đầu Amazon Connect Customer Profiles dành cho ngành du lịch và khách sạn hiện đã có sẵn, với mô hình giá linh hoạt “trả theo mức sử dụng” dựa trên số lượng hồ sơ được dùng. Cách tính này giúp các công ty chỉ phải trả tiền cho những gì họ thực sự sử dụng, khiến dịch vụ trở nên phù hợp cho các tổ chức ở mọi quy mô.\nĐể tìm hiểu thêm về cách Customer Profiles dành cho du lịch và khách sạn có thể thay đổi chiến lược trải nghiệm khách hàng của bạn, hãy truy cập trang sản phẩm của chúng tôi hoặc liên hệ với nhóm tài khoản AWS của bạn. Với những khả năng mạnh mẽ mới này, tương lai của các trải nghiệm du lịch và khách sạn được cá nhân hóa đã ở đây — được vận hành bởi AWS.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-infra-terraform/5.3.1-provider/",
	"title": "Cấu hình Provider",
	"tags": [],
	"description": "",
	"content": "Cấu hình Provier.tf Đầu tiên, chúng ta cần cấu hình Terraform provider và backend. File provider.tf định nghĩa AWS provider và các yêu cầu về version:\nterraform { required_version = \u0026#34;\u0026gt;= 1.5.0\u0026#34; required_providers { aws = { source = \u0026#34;hashicorp/aws\u0026#34; version = \u0026#34;~\u0026gt; 5.0\u0026#34; } } } provider \u0026#34;aws\u0026#34; { region = var.aws_region } File provider.tf định nghĩa: Terraform version requirement (\u0026gt;= 1.5.0) AWS provider version (~\u0026gt; 5.0) AWS region được sử dụng (từ variable aws_region) "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Kick-off AWS FCJ Workforce - OJT FALL 2025 Mục tiêu sự kiện Chúc mừng các sinh viên được chọn tham gia Chương trình AWS First Cloud Journey – On-the-Job Training (OJT FALL 2025). Phát triển thế hệ AWS Builders có kỹ năng cao tại Việt Nam. Cung cấp kinh nghiệm thực hành về Cloud Computing, DevOps, AI/ML, Security và Data \u0026amp; Analytics. Kết nối kiến thức học thuật, công nghệ tiên tiến và cơ hội nghề nghiệp thực tế, giúp học viên phát triển trong bối cảnh công nghệ hiện đại. Diễn giả Tên Vai trò Tổ chức Thầy Nguyễn Trần Phước Bảo Trưởng phòng Quan hệ Doanh nghiệp (QHDN) Trường Đại học Nguyễn Gia Hưng Trưởng bộ phận Solutions Architect AWS Việt Nam Đỗ Huy Thắng DevOps Lead VNG Danh Hoàng Hiếu Nghị GenAI Engineer Renova Bùi Hồ Linh Nhi AI Engineer SoftwareOne Phạm Nguyễn Hải Anh Cloud Engineer G-Asia Pacific Nguyễn Đông Thanh Hiệp Principal Cloud Engineer G-Asia Pacific Điểm nổi bật Lễ khai mạc \u0026amp; Phát biểu chào mừng\nPhát biểu chào mừng từ đại diện Trường Đại học.\nTầm nhìn tương lai\nĐộng lực từ các chuyên gia hàng đầu và mở rộng kết nối chuyên nghiệp trong lĩnh vực Cloud, AI và DevOps.\nKhám phá nghề nghiệp DevOps\nNắm vững các kỹ năng thực tế trong Cloud, DevOps, AI/ML, Security và Data \u0026amp; Analytics.\nCâu chuyện \u0026amp; Chia sẻ từ Cựu học viên\nTừ học viên First Cloud Journey đến GenAI Engineer chuyên nghiệp. Hành trình truyền cảm hứng \u0026ldquo;She in Tech\u0026rdquo;. Cái nhìn thực tế về \u0026ldquo;Một ngày trong cuộc sống của Cloud Engineer\u0026rdquo;.\nKết quả chính Tiếp cận Công nghệ: Tiếp cận công nghệ điện toán đám mây tiên tiến nhất. Định hướng Nghề nghiệp: Được truyền cảm hứng, kết nối với chuyên gia và mở rộng cơ hội nghề nghiệp trong Cloud Computing, AI và DevOps. Kỹ năng Tổng quát: Được trang bị kỹ năng thực hành (Cloud, DevOps, AI/ML, Security, Data \u0026amp; Analytics). Tư duy Phát triển: Khởi đầu hành trình học tập và xây dựng liên tục để thúc đẩy hệ sinh thái điện toán đám mây Việt Nam phát triển. Hình ảnh Sự kiện "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về ứng dụng WebChat Ứng dụng WebChat là một hệ thống nhắn tin real-time cho phép người dùng giao tiếp với nhau thông qua giao diện web hiện đại. Hệ thống hỗ trợ các tính năng cơ bản như gửi và nhận tin nhắn văn bản, chia sẻ file, gửi tin nhắn thoại, tạo nhóm chat, phân quyền thành viên trong nhóm.\nBackend của ứng dụng được xây dựng bằng framework NestJS, một framework Node.js mạnh mẽ sử dụng TypeScript, cung cấp kiến trúc modular và dễ mở rộng. Tính năng real-time messaging được triển khai thông qua Socket.io, cho phép giao tiếp hai chiều giữa client và server một cách hiệu quả mà không cần polling liên tục.\nPhía frontend được phát triển bằng VueJS với công cụ build Vite. Pinia được sử dụng để quản lý state, trong khi Socket.io-client đảm bảo kết nối WebSocket ổn định với backend.\nXác thực người dùng được thực hiện thông qua JWT (JSON Web Tokens), cho phép quản lý phiên đăng nhập một cách an toàn và không trạng thái (stateless).\nTổng quan về workshop Trong workshop này, chúng ta sẽ xây dựng một ứng dụng WebChat hoàn chỉnh từ đầu đến cuối, sử dụng các dịch vụ AWS và công nghệ hiện đại. Workshop được chia thành các phần chính như sau:\nThiết lập hạ tầng với Terraform: Sử dụng Terraform để định nghĩa và triển khai toàn bộ hạ tầng AWS theo nguyên tắc Infrastructure as Code (IaC). Điều này bao gồm việc tạo S3 bucket cho file storage, ECR repository cho Docker images, ECS cluster và service, Application Load Balancer (ALB) để phân phối lưu lượng, cùng với các IAM roles và CloudWatch log groups cần thiết.\nPhát triển Backend Application: Xây dựng backend API sử dụng NestJS, bao gồm các module chính như authentication (JWT), chat với WebSocket support, file upload tích hợp với S3, và các module quản lý users, groups, messages, authentication, chat. Backend sẽ được containerized bằng Docker và deploy lên Amazon ECS Fargate, một dịch vụ container orchestration không cần quản lý server, tự động scale và quản lý containers.\nTriển khai Backend lên AWS: Sau khi build Docker image, chúng ta sẽ push image lên Amazon ECR (Elastic Container Registry) và cấu hình ECS service để chạy containers. Application Load Balancer (ALB) sẽ được sử dụng để phân phối lưu lượng HTTP/WebSocket đến các ECS tasks, đảm bảo tính khả dụng và khả năng mở rộng của ứng dụng.\nPhát triển Frontend Application: Xây dựng giao diện người dùng với VueJS, tích hợp Socket.io-client để kết nối real-time với backend, và sử dụng Pinia để quản lý state. Frontend sẽ bao gồm các component như chat interface, message list, file upload, và các trang authentication.\nTriển khai Frontend: Triển khai Frontend với Amplify , cấu hình Route53 để trỏ Domain về HostedZone ,cấu hình Domain Frontend và kết nối đến Domain Backend.\nMonitoring và Logging: Sau khi triển khai toàn bộ Backend và Frontend lên nền tàng AWS. Chúng ta cấu hình Amazon CloudWatch Logs để thu thập và theo dõi logs từ ECS tasks, tạo CloudWatch dashboards để giám sát metrics như request count, error rates, và response times. AWS Budgets sẽ được thiết lập để theo dõi và cảnh báo về chi phí sử dụng các dịch vụ AWS.\nDatabase: Hệ thống sử dụng MongoDB Atlas làm database chính để lưu trữ dữ liệu người dùng, cuộc trò chuyện và tin nhắn.\nBổ sung Diagram kiến trúc tổng quát "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/",
	"title": "Nhật ký hàng tuần",
	"tags": [],
	"description": "",
	"content": "Tuần 1: Tham gia chương trình, bảo mật tài khoản AWS và nắm vững hạ tầng cốt lõi\nTuần 2: Kiểm soát ngân sách và xây dựng kết nối VPC + EC2 end-to-end\nTuần 3: Củng cố lab VPN/IAM và triển khai Node.js trên Linux \u0026amp; Windows\nTuần 4: EC2 Auto Scaling và triển khai website tĩnh trên Amazon S3\nTuần 5: Vận hành RDS, ứng dụng Lightsail, container và giám sát CloudWatch\nTuần 6: Cấu hình Route 53, thành thạo AWS CLI + DynamoDB và khởi chạy Redis\nTuần 7: Hoàn thành workshop mạng, CloudFront + Lambda@Edge và WordPress\nTuần 8: Lập kế hoạch stack chat real-time và đồng bộ quy trình nhóm với GitHub Pages\nTuần 9: Xây dựng ứng dụng chat monorepo dùng Docker với Vue, Nest và MongoDB\nTuần 10: Hoàn thiện UI, hoàn tất API và tài liệu kiến trúc triển khai AWS\nTuần 11: Triển khai toàn bộ stack lên AWS, giám sát bằng CloudWatch và kiểm thử live\nTuần 12: Phân tích chi phí, tối ưu tài nguyên, ôn tập toàn bộ kiến thức AWS và hoàn thành báo cáo cuối kỳ FCJ\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.5-deployfe/5.5.1-deploy-frontend/",
	"title": "Triển khai Frontend với Amplify",
	"tags": [],
	"description": "",
	"content": "Chuẩn bị Github Repository Chúng ta sẽ chuẩn bị 1 Repository Github , Project này có dạng Monoporo , trong project có chứa thư mục frontend và thư mục backend . Ở đây chúng ta sẽ triển khai ở thư mục frontend lên Amplify.\nBắt đầu triển khai với Amazon Amplify Trong AWS Console , truy cập AWS Amplify rồi chọn Deploy an app. Tiếp tục chọn nền tảng quản lý mã nguồn của bạn, ở đây mình sử dụng Github nên sẽ chọn Github, sau đó nhấn Next. Amplify sẽ hiện 1 cửa sổ mới , với nội dung yêu cầu cấp quyền GitHub để xác thực cho AWS Amplify. Tiếp tục chọn organizations chứa repository mà bạn cần deploy. Ở đây mình chỉ cài đặt cho 1 repository nhất định nên sẽ chọn “Only select repositories” và tiến hành chọn repo mà mình cần deploy , sau đó nhấn “Install \u0026amp; Authorize”. Tại màn hình dưới , bạn sẽ chọn repository của mình (1) và chọn nhánh (2) . Tùy vào cấu trúc thư mục của bạn , nếu thư mục gốc repository của bạn là thư mục chứa mã nguồn chính cần deploy thì bạn sẽ không cần phải tích vào “My app is monorepo” , nhưng đối với repository của mình ,thì mã nguồn chính cần deploy nằm trong thư mục frontend trong thư mục gốc , nên mình sẽ tích chọn (3) và nhập thư mục frontend (4) để giúp Amplify xác định thư mục cần tập trung. Sau đó nhấn Next. Hầu hết trong phần này Amplify sẽ tự động chọn cho bạn. Bạn tiến hành nhập tên App và có thể kiểm tra trước khi Next. Bạn có thể bấm vào Advanced Settings để xem và tinh chỉnh môi trường build Frontend của bạn cho phù hợp với dự án . Bạn chỉ cần kiểm tra lại và nhấn Next. Kiểm tra lại các thông tin quan trọng và nhấn Save and deploy. Đợi vài phút để Amplify tiến hành deploy. Sau khi Deploy thành công ,Amplify sẽ cung cấp cho chúng ta 1 Domain ngẫu nhiên , tùy theo nhu cầu chúng ta sẽ sử dụng Domain này hoặc có thể thêm 1 Custom Domain theo ý muốn của mình. Chúng ta sẽ tiến hành copy Domain đó và paste ra trình duyệt để xem kết quả. Như vậy là bạn đã triển khai Frontend lên Amazon Amplify thành công và có thể truy cập bằng domain do Amplify cung cấp. Từ giờ, mỗi lần bạn cập nhật code trên GitHub (nhánh frontend), Amplify sẽ tự động build và deploy lại sau vài phút.\nVậy bước tiếp theo là: kết nối Frontend với Backend đang chạy trên ECS qua ALB. Hiện tại ALB trả về endpoint HTTP, trong khi Amplify phục vụ Frontend qua HTTPS. Điều này gây ra lỗi mixed content và trình duyệt sẽ chặn request.\nỞ phần tiếp theo, chúng ta sẽ thiết lập HTTPS cho ALB để Frontend và Backend giao tiếp an toàn và đúng chuẩn.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Đọc và nắm quy trình và nội quy của chương trình thực tập First Cloud. Kết nối, làm quen với các thành viên trong chương trình thực tập. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Note 2 - Xem video YouTube hướng dẫn cài đặt và triển khai Workshop template với Hugo server.\n- Nắm bắt các tài liệu học. 08/09/2025 08/09/2025 https://gohugo.io/host-and-deploy/host-on-github-pages/ Làm quen với môi trường workshop 3 - Tạo tài khoản AWS.\n- Thiết lập MFA cho tài khoản AWS. 09/09/2025 09/09/2025 https://000001.awsstudygroup.com/ Bảo mật tài khoản root 4 - Xem các video YouTube Module 01 và ghi chép các khái niệm về Data Center, Region, AZ, Edge Location.\n- Tạo Admin Group và Admin User.\n- Khám phá AWS Management Console. 10/09/2025 10/09/2025 https://www.youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i Ghi chú khái niệm cơ bản 5 - Biết về AWS Command Line Interface (CLI).\n- Xem cách yêu cầu hỗ trợ từ AWS Support. 11/09/2025 11/09/2025 https://000009.awsstudygroup.com/ Thực hành lệnh cơ bản 6 - Thực hành bài Lab 000001 Thiết lập MFA, tạo Admin Group và User, khám phá yêu cầu hỗ trợ, điều hướng AWS Console, và bắt đầu với AWS CLI.) 12/09/2025 12/09/2025 https://000001.awsstudygroup.com/ Hoàn thành Lab đầu tiên Kết quả đạt được tuần 1: Hoàn thành việc đọc và nắm vững quy trình, nội quy chương trình thực tập First Cloud. Kết nối và làm quen thành công với các thành viên trong nhóm thực tập. Thiết lập môi trường làm việc: Cài đặt và chạy thử Workshop template với Hugo server. Tạo tài khoản AWS và kích hoạt MFA. Tạo Admin Group, Admin User với quyền phù hợp. Nắm vững các khái niệm cơ bản về hạ tầng AWS: Data Center, Region, Availability Zone (AZ), Edge Location. Làm quen với công cụ quản trị AWS: Sử dụng AWS Management Console. Biết cách dùng AWS CLI cơ bản. Hiểu quy trình yêu cầu hỗ trợ từ AWS Support. Hoàn thành bài Lab 000001 thành công. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 2: Ôn lại bài Lab 000001 và nâng cao hiểu biết về quản lý chi phí AWS. Nắm vững các khái niệm mạng VPC và xây dựng kiến trúc mạng an toàn. Thực hành kết nối EC2, kiểm tra bảo mật và phân tích khả năng kết nối. Làm quen với các phương thức truy cập an toàn vào EC2. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Ghi chú 2 - Ôn lại Lab 000001.\n- Thực hành Lab 000007: Quản lý chi phí với AWS Budgets – tạo ngân sách theo template cho Cost, Usage, Savings Plans.\n- Dọn dẹp (cleanup) toàn bộ tài nguyên đã tạo.\n- (Nhận 20$ thưởng khi tạo Budget thành công) 15/09/2025 15/09/2025 https://000007.awsstudygroup.com/ Kiểm soát chi phí \u0026amp; dọn dẹp 3 - Xem video Module 02 và ghi chép các khái niệm cốt lõi:\n• VPC\n• Subnet (Public \u0026amp; Private)\n• Route Table\n• Interface/Gateway Endpoints\n• Internet Gateway / NAT Gateway 16/09/2025 16/09/2025 https://www.youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i (Module 02) Cơ bản về mạng 4 - Thực hành Lab 000003.3:\n• Tạo VPC\n• Tạo Public Subnet và Private Subnet\n• Gắn Internet Gateway\n• Cấu hình Route Table\n• Tạo Security Groups 17/09/2025 17/09/2025 https://000003.awsstudygroup.com/vi/ Thiết lập nền tảng mạng 5 - Tiếp tục Lab 000003 (phần còn lại):\n• Khởi chạy EC2 trong Public và Private Subnet\n• SSH từ Public EC2 → Private EC2\n• Kiểm tra kết nối Internet từ cả hai instance\n• Dùng Reachability Analyzer để kiểm tra đường đi giữa 2 EC2 18/09/2025 18/09/2025 https://000003.awsstudygroup.com/ Kết nối \u0026amp; kiểm tra mạng EC2 6 - Thực hành và so sánh 3 cách kết nối EC2:\n1. Bastion Host (Jump Server)\n2. VPC Interface Endpoint + EC2 Instance Connect\n3. AWS Systems Manager – Session Manager\n- Ghi chú ưu/nhược điểm và mức độ bảo mật 19/09/2025 19/09/2025 https://000003.awsstudygroup.com/ Truy cập EC2 an toàn Kết quả đạt được tuần 2: Ôn tập thành công Lab 000001 và áp dụng tốt các thực hành quản lý tài nguyên. Nắm vững AWS Budgets: Tạo ngân sách Cost, Usage, Savings Plans theo template. Thực hiện dọn dẹp tài nguyên triệt để để kiểm soát chi phí. Nhận thưởng 20$ từ nhiệm vụ tạo Budget. Nắm chắc kiến thức mạng VPC AWS: Phân biệt rõ Public vs Private Subnet, Route Table, Internet/NAT Gateway, Endpoint. Xây dựng thành công kiến trúc VPC đa tầng hoạt động ổn định. Thực hành được EC2 trong môi trường cách ly: Khởi chạy và cấu hình EC2 ở cả public và private subnet. Kiểm chứng SSH nối tiếp và hành vi kết nối Internet. Sử dụng Reachability Analyzer để chẩn đoán và xác nhận đường mạng. Tiếp thu các phương thức truy cập EC2 an toàn: Triển khai và so sánh: Bastion Host (SSH truyền thống qua jump server) EC2 Instance Connect Endpoint (truy cập riêng tư) Session Manager (không cần agent, kiểm soát bằng IAM, hỗ trợ audit) Hiểu rõ ưu nhược về bảo mật, tiện lợi, khả năng kiểm tra. Hoàn thành Lab 000007 và Lab 000003 với đầy đủ yêu cầu. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 3: Củng cố kiến thức VPC, EC2, IAM thông qua thực hành lặp lại và dọn dẹp tài nguyên. Hiểu sâu cơ chế kết nối mạng: Internet Gateway → EC2 Public, NAT Gateway → EC2 Private. Nắm các phương thức truy cập EC2 an toàn: Bastion Host, Connect Endpoint, Session Manager. Nắm vững Site-to-Site VPN và IAM qua thực hành Lab. Làm quen với EC2, AMI tùy chỉnh, Snapshot, khôi phục keypair, và triển khai Node.js trên cả Linux \u0026amp; Windows. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Ghi chú 2 - Xóa toàn bộ tài nguyên từ tuần trước.\n- Thực hành lại từ đầu Lab 000003 (toàn bộ):\n• Tạo VPC, Subnet, IGW, NATGW, Route Table, SG\n• Khởi chạy EC2 Public \u0026amp; Private\n• SSH qua Bastion Host, Connect Endpoint, Session Manager\n• Kiểm tra kết nối Internet:\n– EC2 Public → qua Internet Gateway\n– EC2 Private → qua NAT Gateway\n• Tìm hiểu tại sao cấu hình như vậy 22/09/2025 22/09/2025 https://000003.awsstudygroup.com/ Củng cố kiến trúc mạng 3 - Xem Module 02 (phần nâng cao).\n- Thực hành Lab 000003 – Site-to-Site VPN:\n• Tạo Customer Gateway, Virtual Private Gateway\n• Cấu hình VPN Connection\n• Kiểm tra kết nối\n• Dọn dẹp tài nguyên 23/09/2025 23/09/2025 https://www.youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i (Module 02)\nAWS VPN Docs Mạng kết nối hybrid 4 - Xem và nắm vững AWS IAM (Users, Groups, Roles, Policies, MFA).\n- Thực hành Lab 000002:\n• Tạo IAM User, Group, Role\n• Gắn Policy (inline \u0026amp; managed)\n• Kích hoạt MFA\n• Kiểm thử quyền truy cập\n• Dọn dẹp 24/09/2025 24/09/2025 https://000002.awsstudygroup.com/ Quản trị truy cập 3 - Xem Module 02 (phần nâng cao).\n- Thực hành Lab 000003 – Site-to-Site VPN:\n• Tạo Customer Gateway, Virtual Private Gateway\n• Cấu hình VPN Connection\n• Kiểm tra kết nối\n• Dọn dẹp tài nguyên 23/09/2025 23/09/2025 https://www.youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i (Module 02)\nAWS VPN Docs Mạng kết nối hybrid 4 - Xem và nắm vững AWS IAM (Users, Groups, Roles, Policies, MFA).\n- Thực hành Lab 000002:\n• Tạo IAM User, Group, Role\n• Gắn Policy (inline \u0026amp; managed)\n• Kích hoạt MFA\n• Kiểm thử quyền truy cập\n• Dọn dẹp 24/09/2025 24/09/2025 https://000002.awsstudygroup.com/vi/\nAWS IAM Console Quản trị truy cập 5 - Dịch Blog cá nhân (Bản dịch + bản tiếng Anh). 25/09/2025 25/09/2025 AWS Blogs\nVí dụ: Secure VPC Design 6.1 - Xem Module 03.\n- Thực hành Lab 000004 (phần 1):\n• Tạo VPC + Security Group chuẩn bị cho Linux \u0026amp; Windows\n• Khởi chạy EC2 Windows Instance\n• Khởi chạy EC2 Linux Instance\n• Dọn dẹp tài nguyên 26/09/2025 26/09/2025 https://000004.awsstudygroup.com/ 6.2 - Hoàn thành Lab 000004 (phần 2):\n• Thay đổi instance type\n• Tạo Snapshot → Custom AMI\n• Mất keypair → khôi phục bằng Systems Manager\n• Triển khai Node.js app trên:\n– EC2 Linux (User Data + PM2)\n– EC2 Windows (IIS hoặc Node trực tiếp)\n• Dọn dẹp toàn bộ 26/09/2025 26/09/2025 https://000004.awsstudygroup.com/ Kết quả đạt được tuần 3: Nắm kiến thức về kiến trúc VPC đa tầng: Hiểu rõ lý do dùng IGW cho Public, NATGW cho Private. Thực hành thành công 3 phương thức kết nối EC2: Bastion Host → truyền thống, cần mở port 22 Connect Endpoint → private-only, không cần public IP Session Manager → không cần SSH key, audit log, IAM control Thành công thiết lập Site-to-Site VPN: Cấu hình kết nối on-premise ↔ AWS VPC. Kiểm tra ping, traceroute qua tunnel. Nắm vững AWS IAM: Tạo và quản lý User, Group, Role, Policy. Áp dụng MFA, Least Privilege, Policy Conditions. Nắm kiến thức về EC2 nâng cao: So sánh Linux vs Windows EC2 (RDP vs SSH). Tạo Custom AMI từ Snapshot. Khôi phục truy cập khi mất keypair bằng Session Manager. Triển khai thành công ứng dụng Node.js trên cả Linux (systemd/PM2) và Windows (NSSM/IIS). Hoàn thành Lab 000002, 000003 (VPN), 000004 với đầy đủ yêu cầu. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 4: Nắm cơ chế Auto Scaling với EC2: Launch Template, Auto Scaling Group, Load Balancer. Hiểu cách quản lý truy cập S3 bằng IAM User + Access Key. Tìm hiểu, khám phá về Amazon S3 như một nền tảng lưu trữ và triển khai website tĩnh. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Ghi chú 2 - Thực hành lại Lab 000004 để ôn kiến thức EC2.\n- Tiếp tục Lab 000006: Tạo Launch Template, Auto Scaling Group, cấu hình Load Balancer để đảm bảo khả năng mở rộng linh hoạt. 29/09/2025 29/09/2025 https://000006.awsstudygroup.com/ Auto Scaling \u0026amp; High Availability 3 - Thực hành Lab 000048: Tạo IAM User với Access Key / Secret Access Key.\n- Upload file lên S3 bucket bằng AWS CLI hoặc SDK.\n- Dọn dẹp tài nguyên (xóa user, bucket). 30/09/2025 30/09/2025 https://000048.awsstudygroup.com/ Quản lý truy cập S3 4 - Xem YouTube Module 04 về Amazon S3 (các khái niệm: bucket, object, versioning, lifecycle, static website). 01/10/2025 01/10/2025 https://www.youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i (Module 04) Kiến thức nền S3 5 - Thực hành Lab 000057:\n• Chuẩn bị file website (HTML, CSS, JS).\n• Tạo S3 bucket, bật Static Website Hosting.\n• Cấu hình bucket policy cho phép public read.\n• Upload file và truy cập qua URL S3. 02/10/2025 02/10/2025 https://000057.awsstudygroup.com/ Triển khai website tĩnh 6 - Ôn lại toàn bộ các Lab tuần 4 và dọn dẹp tất cả tài nguyên để tránh phí. 03/10/2025 03/10/2025 Kiểm soát chi phí Kết quả đạt được tuần 4: Thành công thiết lập EC2 Auto Scaling: Tạo và cấu hình Launch Template. Thiết lập Auto Scaling Group với min/max/desired capacity. Kết hợp Elastic Load Balancer (ALB/NLB) để phân tải tự động. Thành công thiết lập truy cập S3 bằng IAM: Tạo IAM User với Access Key / Secret Key. Upload file thành công qua CLI/SDK. Dọn dẹp sạch user và bucket. Triển khai website tĩnh trên S3: Hiểu rõ S3 bucket, static website hosting, bucket policy. Hoàn thành Lab 000057 – website truy cập được qua URL public. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 5: Nắm vững cơ sở dữ liệu quan hệ với Amazon RDS. Làm chủ Amazon Lightsail: khởi tạo VPS, triển khai ứng dụng, và container. Giám sát hệ thống hiệu quả bằng Amazon CloudWatch. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Ghi chú 2 - Học về Amazon RDS (MySQL/PostgreSQL).\n- Thực hành Lab 000005: Tạo RDS instance, cấu hình Security Group, kết nối database, sao lưu snapshot. 06/10/2025 06/10/2025 https://000005.awsstudygroup.com/ Cơ sở dữ liệu quan hệ 3 - Khám phá Amazon Lightsail.\n- Thực hành Lab 000045: Khởi tạo VPS, triển khai ứng dụng cơ bản (WordPress, LAMP, Node.js). 07/10/2025 07/10/2025 https://000045.awsstudygroup.com/ VPS đơn giản \u0026amp; ứng dụng 4 - Tiếp tục với Lightsail Containers.\n- Thực hành Lab 000046: Tạo container service, deploy Docker image (ví dụ: Nginx, custom app). 08/10/2025 08/10/2025 https://000046.awsstudygroup.com/ Triển khai container 5 - Học về Amazon CloudWatch.\n- Thực hành Lab 000008: Tạo dashboard, thiết lập alarm (CPU, memory), thu thập và xem log từ EC2 hoặc Lightsail. 09/10/2025 09/10/2025 https://000008.awsstudygroup.com/ Giám sát \u0026amp; cảnh báo 6 - Ôn lại toàn bộ các Lab tuần 5.\n- Dọn dẹp tài nguyên: xóa RDS, Lightsail instances, containers, alarms để tránh phí. 10/10/2025 10/10/2025 Kiểm soát chi phí Kết quả đạt được tuần 5: Nắm kiến thức về Amazon RDS: Tạo và cấu hình RDS instance (MySQL/PostgreSQL). Kết nối từ ứng dụng/local, thực hiện query. Sao lưu tự động và khôi phục từ snapshot. Làm chủ Amazon Lightsail: Khởi tạo VPS thành công, cài đặt WordPress, LAMP, Node.js. Triển khai ứng dụng chạy ổn định với public IP. Triển khai container trên Lightsail: Tạo container service, push Docker image. Truy cập ứng dụng qua URL công khai. Giám sát hệ thống với CloudWatch: Xây dựng dashboard theo dõi CPU, memory, network. Thiết lập alarm gửi thông báo qua email/SNS. Thu thập và phân tích log từ instance. Hoàn thành Lab 000005, 000045, 000046, 000008. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 6: Nắm kiến thức về DNS với Amazon Route 53: hosted zone, record, routing policy. Thành thạo AWS CLI: cài đặt, cấu hình, thực hành lệnh cơ bản. Quản lý DynamoDB qua CLI: tạo bảng, thao tác CRUD. Triển khai và sử dụng ElastiCache Redis: khởi tạo cluster, lệnh SET/GET. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Ghi chú 2 - Thực hành Lab 000010: Tạo public hosted zone trên Route 53.\n- Thêm các bản ghi (A, CNAME, MX).\n- Cấu hình routing policy (Simple, Weighted, Latency). 13/10/2025 13/10/2025 https://000010.awsstudygroup.com/ DNS quản lý 3 - Thực hành Lab 000011: Cài đặt AWS CLI.\n- Cấu hình profile (Access Key, Secret Key, Region).\n- Thực hành lệnh cơ bản: aws ec2 describe-instances, aws s3 ls, aws iam list-users, aws rds describe-db-instances. 14/10/2025 14/10/2025 https://000011.awsstudygroup.com/ Tự động hóa quản trị 4 - Thực hành Lab 000060: Tạo bảng DynamoDB qua CLI (aws dynamodb create-table).\n- Thực hiện CRUD: put-item, get-item, update-item, delete-item.\n- Query và Scan dữ liệu. 15/10/2025 15/10/2025 https://000060.awsstudygroup.com/ NoSQL qua CLI 5 - Thực hành Lab 000061: Khởi tạo Redis cluster trên ElastiCache.\n- Kết nối bằng redis-cli hoặc ứng dụng.\n- Thực hành lệnh SET key value và GET key. 16/10/2025 16/10/2025 https://000061.awsstudygroup.com/ In-memory cache 6 - (Dự phòng) Ôn lại toàn bộ Lab tuần 6.\n- Dọn dẹp tài nguyên: xóa hosted zone, bảng DynamoDB, Redis cluster, xóa CLI profile nếu cần. 17/10/2025 17/10/2025 Kiểm soát chi phí Kết quả đạt được tuần 6: Nắm kiến thức về Route 53: Tạo và quản lý public hosted zone. Cấu hình bản ghi và chính sách định tuyến linh hoạt. Nắm kiến thức về AWS CLI: Cài đặt, cấu hình profile thành công. Thực hiện lệnh quản lý EC2, S3, IAM, RDS mượt mà. Quản lý DynamoDB qua CLI: Tạo bảng với primary key. Thực hiện đầy đủ thao tác CRUD, Query, Scan. Triển khai ElastiCache Redis: Khởi tạo cluster, kết nối ổn định. Sử dụng lệnh SET/GET để lưu và lấy dữ liệu trong bộ nhớ. Hoàn thành Lab 000010, 000011, 000060, 000061. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 7: Hoàn thiện kiến thức mạng AWS qua workshop thực hành. Triển khai CloudFront + Lambda@Edge để tối ưu phân phối nội dung. Triển khai WordPress trên hạ tầng AWS Cloud. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Ghi chú 2 - Hoàn thành Lab 000092: Workshop về mạng AWS.\n20/10/2025 20/10/2025 https://000092.awsstudygroup.com/ 3 - Thực hành Lab 000094: Tạo CloudFront distribution cho S3 static website.\n21/10/2025 21/10/2025 https://000094.awsstudygroup.com/ CDN cơ bản 4 - Thực hành Lab 000130: Áp dụng Lambda@Edge.\n- Tạo Lambda function (Viewer Request/Response, Origin Request).\n22/10/2025 22/10/2025 https://000130.awsstudygroup.com/vi/ Edge computing 5 - Thực hành Lab 000101: Triển khai WordPress trên AWS.\n- Tạo EC2 (Linux), cài MySQL, cấu hình Apache/Nginx, upload WordPress.\n23/10/2025 23/10/2025 https://000130.awsstudygroup.com/vi/ CMS trên Cloud 6 - Ôn lại toàn bộ Lab tuần 7.\n- Dọn dẹp tài nguyên: xóa CloudFront distribution, Lambda@Edge, EC2 WordPress, RDS, S3 bucket. 24/10/2025 24/10/2025 Kết quả đạt được tuần 7: Hoàn thành workshop mạng (Lab 000092): Xây dựng kiến trúc VPC đa tầng, phân biệt public/private subnet. Cấu hình route table, gateway, security group chính xác. Triển khai CloudFront thành công (Lab 000094): Phân phối nội dung tĩnh từ S3 qua CDN toàn cầu. Tối ưu tốc độ tải, giảm latency. Áp dụng Lambda@Edge (Lab 000130): Tùy chỉnh request/response tại edge location. Triển khai WordPress trên AWS (Lab 000101): Cài đặt và chạy WordPress ổn định trên EC2. Kết nối database (RDS hoặc local MySQL), cấu hình domain. Hoàn thành Lab 000092, 000094, 000130, 000101. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 8: Lên kế hoạch và khởi động dự án web chat nhóm. Tìm hiểu công nghệ: MongoDB, Vue.js, Nest.js, Socket.IO, Docker. Thiết lập repository Git và GitHub Pages cho workshop. Điều chỉnh worklog theo tiến độ chung của nhóm. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Ghi chú 2 - Lên kế hoạch dự án web chat: xác định yêu cầu.\n- Tạo collection MongoDB (users, rooms, messages, \u0026hellip;).\n- Lựa chọn stack: MongoDB + Vue.js + Nest.js + Socket.IO + Docker. 27/10/2025 27/10/2025 Internal Project Docs\nMongoDB University 3 - Tìm hiểu MongoDB: cài đặt local, thực hành CRUD, aggregation, indexing.\n- Tìm hiểu Vue.js: component, Vue Router, Pinia (state management). 28/10/2025 28/10/2025 - https://www.mongodb.com/docs/\n- https://doc.vueframework.com/ 4 - Tìm hiểu Nest.js: module, controller, service, DTO, JWT auth.\n- Tìm hiểu Socket.IO: WebSocket, rooms, events, real-time messaging. 29/10/2025 29/10/2025 - https://docs.nestjs.com/\n- https://socket.io/docs/v4 Backend \u0026amp; real-time 5 - Tìm hiểu Docker: Dockerfile, docker-compose, multi-container app.\n- Bàn dự án nhóm: phân chia công việc (frontend, backend, DevOps).\n- Điều chỉnh worklog theo tiến độ nhóm. 30/10/2025 30/10/2025 - https://docs.docker.com/\nTeam Meeting 6 - Tạo repository Git (GitHub/GitLab).\n31/10/2025 31/10/2025 GitHub Kết quả đạt được tuần 8: Hoàn thành kế hoạch dự án web chat: Xác định đầy đủ yêu cầu chức năng và phi chức năng. Thiết kế schema MongoDB (users, chat rooms, messages). Quyết định công nghệ stack chính thức. Nắm các công nghệ chính : MongoDB: thực hành CRUD, aggregation pipeline. Vue.js: xây dựng component, routing, state management. Nest.js: cấu trúc module, API REST, authentication. Socket.IO: implement real-time chat events. Docker: viết Dockerfile, docker-compose.yml. Phân chia công việc nhóm rõ ràng: Frontend: Vue.js + UI/UX. Backend: Nest.js + Socket.IO + MongoDB. DevOps: Docker + CI/CD + AWS deployment. Thiết lập hệ thống quản lý mã nguồn: Tạo repository Git với branch strategy. Triển khai GitHub Pages để lưu tài liệu workshop. Điều chỉnh worklog nhóm đồng bộ, đảm bảo tiến độ chung. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 9: Thiết lập môi trường phát triển local hoàn chỉnh. Xây dựng cấu trúc dự án monorepo với Vue.js (frontend) và Nest.js (backend). Phát triển giao diện chat cơ bản và kết nối real-time. Xây dựng backend WebSocket, quản lý tin nhắn và người dùng. Thiết kế schema MongoDB và Docker hóa toàn bộ ứng dụng. Chạy thử nghiệm local với Docker Compose, đảm bảo real-time chat hoạt động. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Ghi chú 2 - Setup môi trường phát triển local: Node.js, MongoDB, Docker, VS Code.\n- Khởi tạo monorepo với 2 apps: frontend (Vue.js), backend (Nest.js). 03/11/2025 03/11/2025 - https://doc.vueframework.com/ - https://docs.nestjs.com/ 3 - Phát triển frontend Vue.js: giao diện chat cơ bản (login, room list, chat box).\n- Tích hợp Socket.IO client để nhận/gửi tin nhắn real-time. 04/11/2025 04/11/2025 https://socket.io/docs/v4 4 - Phát triển backend Nest.js: WebSocket gateway, message service, user controller,\u0026hellip; - Xử lý kết nối người dùng, broadcast tin nhắn theo room. 05/11/2025 05/11/2025 5 - Thiết kế schema MongoDB: collections users, rooms, messages, .. - Kết nối Mongoose trong Nest.js, thực hiện CRUD tin nhắn. 06/11/2025 06/11/2025 Database modeling 6 - Docker hóa ứng dụng: Dockerfile cho frontend, backend, mongo.\n- Viết docker-compose.yml để chạy toàn bộ stack local.\n- Test real-time chat giữa nhiều tab/user. 07/11/2025 07/11/2025 Containerization \u0026amp; local run Kết quả đạt được tuần 9: Hoàn thiện môi trường phát triển local: Monorepo chạy mượt với frontend Vue.js và backend Nest.js. IDE, Git, Docker sẵn sàng. Giao diện chat cơ bản hoạt động: Login, chọn phòng, gửi/nhận tin nhắn real-time. UI responsive, state management với Pinia. Backend Nest.js xử lý WebSocket ổn định: Quản lý kết nối người dùng, phòng chat. Broadcast tin nhắn chính xác, không mất dữ liệu. MongoDB schema hợp lý: Lưu trữ user, room, message với index tối ưu. CRUD tin nhắn qua API và WebSocket. Docker hóa thành công: 3 container: vue-frontend, nest-backend, mongo-db. docker-compose up chạy toàn bộ hệ thống local. Real-time chat hoạt động giữa nhiều người dùng: Test với 3-5 tab/browser, tin nhắn đồng bộ tức thì. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Ứng dụng trò chuyện thời gian thực 1. Tóm tắt điều hành Serverless Web Chat Platform được phát triển nhằm cung cấp một giải pháp giao tiếp nội bộ nhanh chóng, bảo mật và dễ vận hành. Ứng dụng hỗ trợ nhắn tin thời gian thực giữa các thành viên thông qua giao diện web nhẹ, có kha năng mở rộng linh hoạt trong tương lai. Nền tảng tận dụng các dịch vụ AWS Serverless như API Gateway AWS Lambda, DynamoDB và Amazon Cognito để đảm bảo vận hành ổn định, chi phí thấp và không yêu cầu quản lý máy chủ. Quyền truy cập được giới hạn cho các thành viên phòng lab, đảm bảo bảo mật và tính riêng tư trong quá trình trao đổi thông tin.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nNhóm đang phát triển một ứng dụng chat phục vụ mục đích học tập và nghiên cứu về cách xây dựng hệ thống web thời gian thực. Nếu triển khai theo mô hình truyền thống (tự dựng máy chủ, tự quản lý cơ sở dữ liệu và duy trì kết nối WebSocket), nhóm sẽ phải đối mặt với nhiều khó khăn như: thiết lập hạ tầng phức tạp, xử lý mở rộng khi có nhiều kết nối đồng thời, đảm bảo tính ổn định và bảo mật, cũng như theo dõi và ghi log đầy đủ cho hệ thống. Việc không tận dụng các dịch vụ AWS khiến nhóm khó mô phỏng các mô hình hạ tầng hiện đại, đồng thời tốn thời gian cho các tác vụ vận hành thay vì tập trung vào phần ứng dụng và các bài học kỹ thuật cốt lõi.\nGiải pháp\nỨng dụng Web Chat được triển khai dựa trên các dịch vụ Serverless của AWS, nhằm mô phỏng kiến trúc ứng dụng hiện đại, có khả năng mở rộng tối đa.Giải pháp tập trung vào việc loại bỏ nhu cầu quản lý máy chủ, tối đa hóa khả năng mở rộng tức thì và giảm chi phí vận hành. Bằng cách sử dụng WebSocket API qua CloudFront và Lambda, giải pháp đảm bảo giao tiếp WSS tốc độ cao, đồng thời áp dụng DynamoDB để xử lý hiệu quả các thao tác đọc/ghi lớn cho dữ liệu chat. Cognito cung cấp lớp xác thực mạnh mẽ, bảo vệ toàn bộ ứng dụng từ lớp truy cập (frontend) đến lớp API.\nLợi ích và hoàn vốn đầu tư (ROI)\nGiải pháp giúp nhóm thực hành xây dựng ứng dụng chat hoàn chỉnh từ frontend đến backend, kết hợp với các dịch vụ cloud thường dùng trong môi trường doanh nghiệp. Nhờ tận dụng Free Tier và các tài nguyên test, chi phí triển khai thấp nhưng vẫn đảm bảo đủ tính thực tiễn để nhóm hiểu rõ về quản lý hạ tầng, giám sát, mở rộng và bảo mật. Việc triển khai trên AWS giúp giảm thời gian cấu hình thủ công, đồng thời tạo nền tảng vững chắc cho các nghiên cứu nâng cao như chatbot, xử lý dữ liệu hoạt động người dùng hoặc tích hợp hệ thống AI. Thời gian hoàn vốn gần như tức thời do không yêu cầu chi phí phần cứng và giảm đáng kể nỗ lực vận hành.\n3. Kiến trúc giải pháp Ứng dụng Web Chat được triển khai theo kiến trúc container hóa trên AWS, sử dụng Amazon ECS Fargate làm nền tảng chạy backend NestJS, trong khi frontend VueJS được lưu trữ trên Amazon Amplify. Kiến trúc này đảm bảo tính tách biệt giữa frontend – backend, dễ mở rộng, an toàn và giảm thiểu các tác vụ vận hành máy chủ.\nLuồng truy cập tổng quan Người dùng truy cập ứng dụng thông qua tên miền được quản lý bởi Amazon Route 53. Các request đến frontend sẽ được phân phối tới **Amazon Amplify Hosting, trong khi các request backend theo đường dẫn api.webchat.mom sẽ được chuyển đến **Application Load Balancer (ALB), nơi điều phối traffic đến các container Fargate trong từng subnet khác nhau để đảm bảo tính sẵn sàng cao.\nThành phần chính trong kiến trúc Amazon Route 53: Quản lý DNS, phân giải tên miền tùy chỉnh webchat.mom và api.webchat.mom. Route 53 điều hướng request frontend vào Amplify và request backend vào Application Load Balancer.\nAmazon Amplify Hosting (Frontend): Deploy và phân phối ứng dụng VueJS. Amplify cũng tích hợp với Amazon Certificate Manager (ACM) để cung cấp HTTPS cho giao diện web. Ngoài ra, Amplify sử dụng Rewrite \u0026amp; Redirect rule để điều hướng người dùng vào đúng domain API khi truy cập frontend.\nAmazon Certificate Manager (ACM): Cung cấp chứng chỉ SSL/TLS cho cả Amplify và Application Load Balancer nhằm bảo đảm toàn bộ giao tiếp giữa người dùng và hệ thống đều được mã hóa.\nApplication Load Balancer (ALB): Đóng vai trò điều phối traffic backend. ALB nhận request từ api.webchat.mom và định tuyến đến các ECS Fargate tasks nằm trong các public subnet, đảm bảo khả năng scale-out khi có số lượng request tăng cao.\nAmazon ECS Fargate (Backend): Chạy các container NestJS backend mà không cần quản lý EC2. Các tasks nằm trong nhiều subnet khác nhau để tăng tính sẵn sàng. Ứng dụng backend giao tiếp trực tiếp với MongoDB và SMTP server thông qua Internet Gateway hoặc VPC routing.\nAmazon ECR: Lưu trữ Docker Image của backend NestJS. Mỗi lần CI/CD cập nhật backend, Fargate sẽ pull image trực tiếp từ ECR.\nAmazon S3: Dùng để lưu trữ tệp tĩnh như hình ảnh, file đính kèm hoặc nội dung được chia sẻ trong chat.\nMongoDB Atlas / MongoDB Server: Lưu trữ toàn bộ thông tin người dùng, tin nhắn và dữ liệu ứng dụng. Backend Fargate kết nối tới MongoDB thông qua Internet Gateway.\nSMTP Server: Được backend sử dụng để gửi email thông báo (nếu có).\nAmazon CloudWatch (Shared Service): Thu thập log từ ECS Fargate và ALB, hỗ trợ việc giám sát, cảnh báo và theo dõi hiệu suất hệ thống.\nAmazon IAM: Quản lý quyền truy cập giữa các dịch vụ như Fargate → ECR, ALB → CloudWatch, Amplify → S3, và cấp quyền tối thiểu cần thiết theo mô hình Least Privilege.\nTổng quan hoạt động User truy cập webchat.mom → Route 53 → Amplify Web. Giao diện frontend tải về từ Amplify. Các request backend từ frontend được gửi đến domain api.webchat.mom. Route 53 điều hướng request backend đến ALB. ALB định tuyến đến các container NestJS chạy trên ECS Fargate. Container Fargate kết nối với: MongoDB để xử lý dữ liệu chat S3 để lưu file SMTP để gửi mail Tất cả log được đẩy vào CloudWatch. Quyền truy cập được kiểm soát bởi IAM và toàn bộ traffic được mã hóa thông qua chứng chỉ từ ACM. Lợi ích kiến trúc Không cần quản lý máy chủ (Serverless Container – Fargate). Tự động mở rộng khi số lượng người dùng tăng. Tách biệt frontend – backend dễ phát triển độc lập. Hỗ trợ CI/CD qua Amplify và ECR → Fargate. Dễ giám sát, chuẩn mô hình Cloud Native thực tế trong doanh nghiệp. Bảo mật toàn diện từ DNS đến backend. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án Web Chat gồm 2 phần chính — xây dựng backend , frontend cho web và triển khai lên Cloud AWS - trải qua 5 giai đoạn:\nXây dựng Prototype: Tìm hiểu VueJS, NestJS và lên kế hoạch xây dựng Web chat chạy trên mạng LAN (1 tháng trước kỳ thực tập). Nghiên cứu và vẽ kiến trúc: Tìm hiểu các dịch vụ AWS và vẽ kiến trúc phù hợp với dự án WebChat (Tháng 1). Tính toán chi phí và kiểm tra tính khả thi: Sử dụng AWS Pricing Calculator để ước tính chi phí cho ECS Fargate, Application Load Balancer (ALB), DynamoDB, Amplify, CloudFront và CloudWatch; đồng thời đánh giá mức sử dụng tài nguyên container để dự báo chi phí chính xác. (Tháng 2). Điều chỉnh kiến trúc để tối ưu chi phí/giải pháp: Tối ưu cấu hình ECS Service (CPU/memory), số task chạy tối thiểu/tự động scale; tinh chỉnh thiết kế WebSocket trên Fargate qua ALB; tối ưu DynamoDB (PK/SK, GSI) và thiết lập cache frontend với CloudFront để giảm tải lên backend. (Tháng 3). Phát triển, kiểm thử, triển khai: Xây dựng backend (NestJS) chạy trong container ECS Fargate; phát triển frontend VueJS; triển khai toàn bộ hạ tầng (ECS Fargate, ALB, DynamoDB, Amplify + CloudFront, Route53, Cognito). Thực hiện kiểm thử hệ thống (functional, integration, load test) và đưa vào vận hành. (Tháng 3–4). Yêu cầu kỹ thuật\nBackend: Chạy ứng dụng NestJS trong container ECS Fargate, xử lý API và WebSocket thời gian thực thông qua Application Load Balancer (ALB). Dữ liệu chat và người dùng lưu trữ trên DynamoDB; log và giám sát bằng CloudWatch; tích hợp domain bằng Route53. Frontend: Phát triển bằng VueJS; triển khai qua Amplify và phân phối qua CloudFront để tối ưu tốc độ tải và hiệu suất giao diện chat realtime. Realtime \u0026amp; hiệu năng: Kết nối WebSocket thông qua ALB tới backend chạy trên Fargate để đảm bảo độ trễ thấp và kết nối ổn định. CloudFront cache frontend nhằm giảm tải lên backend và tăng tốc độ phản hồi. Bảo mật \u0026amp; quản lý người dùng: Sử dụng AWS Cognito để xác thực người dùng, quản lý phiên đăng nhập và phân quyền truy cập dữ liệu chat. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng khảo sát yêu cầu, phân tích phạm vi, lựa chọn công nghệ (VueJS, NestJS, ECS Fargate, ALB, Amplify, DynamoDB, CloudFront, Route53, CloudWatch) và lập kế hoạch kiến trúc tổng thể. Thực tập (Tháng 1–3): Tháng 1: Học và làm quen với AWS (EC2, ECS, DynamoDB, Amplify, CloudFront, Route53, CloudWatch). Thiết lập môi trường phát triển, tạo prototype backend NestJS và frontend VueJS. Tháng 2: Thiết kế và điều chỉnh kiến trúc hệ thống, xây dựng tính năng chính (chat realtime, lưu tin nhắn, giao diện cơ bản). Thiết lập hạ tầng: ECS service, ALB listener, DynamoDB tables, Amplify cho frontend, CloudFront CDN, Route53 cho domain. Tháng 3: Triển khai chính thức, kiểm thử , tối ưu hiệu năng, cấu hình giám sát CloudWatch và đưa vào sử dụng. Sau triển khai: Tiếp tục nghiên cứu và mở rộng tính năng trong vòng 1 năm (chatbot, phân tích dữ liệu, cải thiện UI/UX, tối ưu bảo mật và chi phí). 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nChi phí hạ tầng\nECS Fargate: 9,50 USD/tháng (1 task 0.25 vCPU + 0.5GB RAM chạy 720 giờ) Application Load Balancer: 16,00 USD/tháng (listener + LCU + traffic thấp) DynamoDB: 0,50 USD/tháng (~50.000 Read/Write on-demand) Amplify: 0,20 USD/tháng CloudFront: 0,70 USD/tháng (Data Transfer Out ~8GB) CloudWatch: 0,10 USD/tháng (50MB log) Route53: 0,50 USD/tháng Tổng: 27,50 USD/tháng, 330 USD/12 tháng\n7. Đánh giá rủi ro Ma trận rủi ro\nMất mạng / sự cố internet: Ảnh hưởng trung bình, xác suất trung bình. Lỗi dữ liệu / DynamoDB: Ảnh hưởng cao, xác suất thấp. Vượt ngân sách AWS: Ảnh hưởng trung bình, xác suất thấp. Lỗi frontend / CloudFront: Ảnh hưởng thấp, xác suất trung bình. Lỗi backend / ECS Fargate hoặc ALB: Ảnh hưởng cao, xác suất thấp. Chiến lược giảm thiểu\nMất mạng / Internet: Dùng CloudFront để cache frontend; lưu tạm tin nhắn cục bộ (localStorage/IndexedDB). Lỗi dữ liệu / DynamoDB: Bật Point-In-Time Recovery, kiểm tra schema, theo dõi bằng CloudWatch Logs và Metrics. Vượt ngân sách AWS: Thiết lập CloudWatch billing alarm, giới hạn log retention, tối ưu task Fargate (CPU/RAM). Frontend / CloudFront lỗi: Dùng versioned deployment để rollback nhanh. Backend / ECS Fargate lỗi: Triển khai nhiều task khi cần, dùng health check của ALB để tự động thay thế task lỗi. Kế hoạch dự phòng\nSử dụng Infrastructure as Code (CloudFormation / Terraform) để tái tạo nhanh toàn bộ ECS Service, ALB, DynamoDB, Amplify, CloudFront. Khi AWS gặp sự cố kéo dài, có thể chạy phiên bản local (VueJS + NestJS) để duy trì trao đổi nội bộ. Theo dõi định kỳ CloudWatch Dashboard, ALB health checks và ECS task status để phát hiện sớm sự cố. 8. Kết quả kỳ vọng Cải tiến kỹ thuật\nỨng dụng chat realtime chạy ổn định trên kiến trúc container (ECS Fargate + ALB), thay thế việc trao đổi bằng email hoặc ghi chú thủ công. Lưu trữ tin nhắn và dữ liệu người dùng tập trung qua DynamoDB, dễ quản lý và truy xuất. Kiến trúc mô-đun với backend NestJS (chạy Fargate), frontend VueJS (Amplify + CloudFront) và hạ tầng AWS (ECS, ALB, DynamoDB, CloudFront, Amplify, Route53, CloudWatch) có thể mở rộng lên 50–100 người dùng. Giá trị dài hạn\nHệ thống có thể lưu trữ dữ liệu chat và log trong 1 năm để phục vụ nghiên cứu, đánh giá người dùng hoặc tích hợp AI/ML (chatbot, phân tích hành vi). Kiến trúc và codebase có thể tái sử dụng lại cho các dự án nội bộ, microservice khác hoặc làm nền tảng học DevOps/Cloud. Giúp nhóm thành thạo cách triển khai, tối ưu và giám sát hệ thống cloud-native chạy container trên AWS. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.10-blog10/",
	"title": "Blog 10",
	"tags": [],
	"description": "",
	"content": "Tăng tốc phát triển Microservices với DAPR và Amazon EKS Các Microservices và container đang cách mạng hóa cách xây dựng ứng dụng hiện đại, triển khai, và quản lý trên nền tảng đám mây. Tuy nhiên, việc phát triển và vận hành microsevices có thể làm tăng đáng kể mức độ phức tạp, thường xuyên yêu cầu các nhà phát triển phải dành ra nhiều thời gian quý báu cho những mối quan tâm chung như khám phá dịch vụ, quản lý trạng thái, và khả năng quan sát.\nDapr ( Distributed Application Runtime ) là một runtime mã nguồn mở được thiết kế để xây dựng microservices trên nền tảng đám mây và biên ( edge ), Nó cung cấp các khối xây dựng độc lập với nền tảng như khám phá dịch vụ, quản lý trạng thái, nhắn tin pub/sub, và khả năng quan sát, tất cả đều được tích hợp sẵn. Dapr đã tốt nghiệp Cloud Native Computing Foundation ( CNCF ) vào ngày 30 tháng 10 năm 2024, đánh dấu một cột mốc quan trọng trong hành trình phát triển dự án.\nKhi được kết hợp với Amazon Elastic Kubernetes Service ( Amazon EKS ), một dịch vụ Kubernetes được quản lý do AWS cung cấp, Dapr có thể tăng tốc việc áp dụng microservices và containers, các nhà phát triển có thể tập trung vào việc viết các logic nghiệp vụ mà không cần bận tâm về hạ tầng phức tạp bên dưới. Amazon EKS giúp việc quản lý các cụm Kubernetes trở nên dễ dàng, đồng thời cho phép mở rộng quy mô linh hoạt khi khối lượng công việc thay đổi. Trong bài viết này, chúng ta sẽ khám phá cách mà Dapr đơn giản hóa việc phát triển microservices trên AWS EKS và minh họa nhanh cách triển khai một ứng dụng mẫu trên EKS bằng Dapr.\nSức mạnh của Dapr và Amazon EKS Sự kết hợp giữa Dapr và Amazon EKS mang đến một nền tảng mạnh mẽ để xây dựng các microservices có tính ổn định cao và khả năng mở rộng vượt trội. Một số lợi ích bao gồm :\nTăng tính di động : Với Dapr và Amazon EKS, microservices có thể được triển khai thành bất cứ cụm Kubernetes tiêu chuẩn nào, giúp tăng khả năng di chuyển giữa các môi trường khác nhau. Cải thiện khả năng phục hồi : Các cơ chế đảm bảo độ tin cậy của Dapr như thử lại, ngắt mạch tạm thời, kết hợp với tính năng tự động khởi động lại container của Amazon EKS, giúp nâng cao tính sẵn sàng và thời gian hoạt động của toàn bộ dịch vụ. Khả năng quan sát liền mạch : các tích hợp giám sát của Dapr kết hợp với giám sát gốc qua Amazon CloudWatch trong EKS cung cấp khả năng quan sát toàn diện đối với các microservices. Tăng tốc đổi mới : Dapr đẩy nhanh sự phát triển của microservice, trong khi Amazon EKS đơn giản hóa việc vận hành cụm, cho phép các nhà phát triển tập trung vào cái logic nghiệp vụ thay vì hạ tầng Phân tách các mối quan tâm : Dapr xử lý các mối quan tâm chung như khám phá dịch vụ và nhắn tin pub/sub, giúp phân tách rõ ràng các tầng chức năng trong kiến trúc microservices. Tích hợp dịch vụ của AWS : Các khối xây dựng Dapr được tích hợp với nhiều dịch vụ AWS mang đến hệ sinh thái phong phú để xây dựng các microservice mạnh mẽ trên Amazon EKS. Một số ví dụ là Amazon Dynamo DB, AWS Secrets Manager, AWS Parameter Store, Amazon SNS, Amazon SQS, Amazon Kinesis và Amazon S3. Gọi dịch vụ và quản lý trạng thái với Dapr Chúng ta sẽ bắt đầu đi sâu vào hai khối chức năng thiết yếu trong Dapr : gọi dịch vụ và quản lý trạng thái.\nGọi dịch vụ ( Service Invocation ) : Việc giao tiếp liền mạch và đáng tin cậy giữa các microservices là rất quan trọng. Tuy nhiên, các nhà phát triển thường xuyên gặp khó khăn với những nhiệm vụ phức tạp như khám phá dịch vụ, chuẩn hóa APIs, bảo mật kênh giao tiếp, xử lý lỗi một cách linh hoạt, và triển khai khả năng quan sát. Các dịch vụ của bạn có thể giao tiếp dễ dàng với nhau thông qua các giao thức tiêu chuẩn trong ngành như gRPC và HTTP/HTTPS. Gọi dịch vụ đảm nhiệm toàn bộ phần phức tạp, từ đăng ký và khám phá dịch vụ đến thử lại yêu cầu, mã hóa, kiểm soát truy cập và theo dõi phân tán.\nQuản lý trạng thái ( State Management ) : Khối xây dựng quản lý trạng thái của Dapr đơn giản hóa cách mà các nhà phát triển làm việc với trạng thái trong ứng dụng của họ. Nó cung cấp một API nhất quán cho việc lưu trữ và truy xuất dữ liệu trạng thái, bất kể kho lưu trữ trạng thái bên dưới là gì ( Ví dụ : ElastiCache, AWS DynamoDB, Azure Cosmos DB ). Lớp trừu tượng này cho phép các nhà phát triển xây dựng ứng dụng có trạng thái mà không cần lo lắng về sự phức tạp của việc quản lý và mở rộng các kho lưu trữ trạng thái.\nKiến trúc ứng dụng Dựa vào sơ đồ, chúng ta có hai microservices : một ứng dụng Python và một ứng dụng Node.js. Ứng dụng Python tạo ra dữ liệu đơn hàng và gọi đến endpoint /neworder được cung cấp bởi ứng dụng Node.js. Ứng dụng Node.js ghi dữ liệu đơn hàng đến vào kho lưu trữ trạng thái ( Trong trường hợp này, Amazon ElastiCache ) và trả về mã đơn hàng cho ứng dụng Python như một phản hồi.\nBằng cách tận dụng dịch vụ khối xây dựng gọi dịch vụ của Dapr, ứng dụng Python có thể giao tiếp liền mạch với ứng dụng Node.js mà không cần lo lắng về khám phá dịch vụ, chuẩn hóa API, bảo mật kênh giao tiếp, xử lý lỗi, hay khả năng quan sát. Vận dụng mTLS để đảm bảo an toàn giao tiếp giữa các dịch vụ. Dapr xử lý các mối quan tâm chung, cho phép các nhà phát triển tập trung vào viết các logic nghiệp vụ cốt lõi.\nNgoài ra, khối xây dựng quản lý trạng thái của Dapr đơn giản hóa việc tương tác của ứng dụng Node.js với kho lưu trữ trạng thái ( Amazon ElastiCache ). Dapr cung cấp một API nhất quán cho việc lưu trữ và truy xuất dữ liệu trạng thái, trừu tượng hóa toàn bộ sự phức tạp của việc quản lý và mở rộng kho lưu trữ và trạng thái bên dưới. Lớp trừu tượng này cho phép các nhà phát triển xây dựng ứng dụng có trạng thái mà không cần lo lắng về các chi tiết phức tạp trong việc quản lý kho lưu trữ trạng thái.\nCụm Amazon EKS chứa một namespace được gọi là dapr-system, nơi lưu trữ các thành phần của mặt điều khiển của Dapr. Thành phần dapr-sidecar-injector tự động chèn một runtime của Dapr vào các pod của những microservice được kích hoạt Dapr.\nỨng dụng và lời gọi dịch vụ Sơ đồ kiến trúc ứng dụng thể hiện các bước thực hiện lời gọi dịch vụ.\nDịch vụ tạo đơn hàng ( ứng dụng Python ) gọi đến phương thức /neworder của ứng dụng Node. Yêu cầu này được gửi đến Dapr sidecar cục bộ, vốn chạy chung trong cùng một pod với ứng dụng Python. Dapr xác định ứng dụng đích bằng cách sử dụng nhà cung cấp DNS của cụm Amazon EKS và gửi yêu cầu đến sidecar của ứng dụng Node.js Sidecar của ứng dụng Node.js sau đó gửi yêu cầu đến microservice của ứng dụng Node. Ứng dụng Node sau đó viết mã đơn hàng đã nhận từ ứng dụng Python vào Amazon ElastiCache. Ứng dụng Node gửi phản hồi đến Dapr sidecar cục bộ của nó. Sidecar của ứng dụng Node chuyển tiếp phản hồi cho Dapr sidecar của ứng dụng Python. Sidecar của ứng dụng Python trả về phản hồi cho ứng dụng Python, ứng dụng này là bên khởi tạo cái yêu cầu đến phương thức /neworder của ứng dụng Node. Kết nối ứng dụng với Dapr trên Amazon EKS Yêu cầu chuẩn bị : Để triển khai một ứng dụng mẫu trên Amazon EKS sử dụng Dapr, hãy theo dõi theo bài viết này. Bạn sẽ cần chuẩn bị những điều kiện sau :\nMột tài khoản AWS. Nếu bạn chưa có tài khoản, bạn có thể đăng kí ở đây https://signin.aws.amazon.com/signup?request_type=register Người dùng AWS Identity and Access Management ( IAM ) có quyền thích hợp - Thực thể bảo mật IAM mà bạn đang dùng nên có những quyền hạn để làm việc với Amazon EKS IAM, service linked roles, AWS CloudFormation, một VPC, và những tài nguyên liên quan. Thêm nhiều thông tin hơn, hãy xem Actions, resources, and condition keys for Amazon Elastic Container Service for Kubernetes và create a service-linked role trong hướng dẫn người dùng IAM. Để hiểu cách làm việc của Dapr trên Amazon EKS, hãy chuẩn bị một cụm Amazon EKS và triển khai một ứng dụng mẫu. Sau đó chúng ta sẽ cài đặt Dapr runtime và áp dụng cấu hình Dapr cho các microservice mẫu. Chúng ta sẽ kiểm thử ứng dụng mẫu và trực quan hóa các thành phần Dapr trên bảng điều khiển Dapr.\n1. Chuẩn bị cụm Amazon EKS Cài đặt awscli, kubectl và eksctl, đây là những công cụ cần thiết để thực thi các lệnh trong terminal của bạn.\nTạo một cụm Amazon EKS tên là eksworkshop-dapr sử dụng ví dụ cluster-config.yaml\napiVersion: eksctl.io/v1alpha5\rkind: ClusterConfig\rmetadata:\rname: eksworkshop-dapr\rregion: us-east-2\rversion: \u0026#34;1.31\u0026#34;\rtags:\rkarpenter.sh/discovery: eksworkshop-dapr\riam:\rwithOIDC: true\rmanagedNodeGroups:\r- name: default\rdesiredCapacity: 3\rminSize: 3\rmaxSize: 5\rinstanceType: m7i.large\rprivateNetworking: true\raddons:\r- name: vpc-cni attachPolicyARNs:\r- arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy\r- name: coredns\rversion: latest - name: kube-proxy\rversion: latest\r- name: aws-ebs-csi-driver\rwellKnownPolicies: ebsCSIController: true Chạy lệnh này để áp dụng yaml và tạo cụm Amazon EKS của bạn\neksctl create cluster -f cluster-config.yaml Trước khi tiến hành với việc phát triển ứng dụng của bạn, bạn sẽ cần cấu hình các thiết lập bảo mật để cho phép việc giao tiếp đúng cách giữa các Dapr sidecar. Sử dụng các lệnh tiếp theo để cập nhật quyền bảo mật để cho phép cụm Amazon EKS của bạn có thể giao tiếp với Dapr sidecar\naws ec2 authorize-security-group-ingress --region [your_aws_region] \\\r--group-id [your_security_group] \\\r--protocol tcp \\\r--port 4000 \\\r--source-group [your_security_group] Tiếp theo, bạn sẽ thêm vào một storage class mặc định, là phần cần thiết cho Dapr scheduler hoạt động đúng cách\nkubectl patch storageclass gp2 -p \u0026#39;{\u0026#34;metadata\u0026#34;: {\u0026#34;annotations\u0026#34;:{\u0026#34;storageclass.kubernetes.io/is-default-class\u0026#34;:\u0026#34;true\u0026#34;}}}\u0026#39; Tiếp theo là chạy lệnh này để xác nhận rằng các node của Amazon EKS đang hoạt động\nkubectl get nodes Bạn sẽ nhận được kết quả như thế này\nip-192-168-117-234.us-east-2.compute.internal Ready \u0026lt;none\u0026gt; 7m46s v1.31.7-eks-473151a\rip-192-168-141-0.us-east-2.compute.internal Ready \u0026lt;none\u0026gt; 7m47s v1.31.7-eks-473151a\rip-192-168-179-109.us-east-2.compute.internal Ready \u0026lt;none\u0026gt; 7m47s v1.31.7-eks-473151a Ứng dụng mẫu tận dụng AWS Load Balancer Controller, một thành phần điều phối AWS Load Balancer Controller bên trong cụm Kubernetes của bạn. Để bắt đầu, cài đặt AWS Load Balancer Controller bằng cách theo dõi các bước sau here\n2. Cài đặt DAPR trên cụm Amazon EKS của bạn Ở bước này, bạn sẽ cài đặt Dapr CLI và sử dụng nó như một công cụ cho các tác vụ liên quan đến Dapr như cài đặt Dapr và liệt kê các thành phần của Dapr.\nChạy lệnh này để cài đặt Dapr CLI mới nhất cho Linux vào /usr/local/bin\nwget -q https://raw.githubusercontent.com/dapr/cli/master/install/install.sh -O - | /bin/bash Bạn cần xác thực việc cài đặt Dapr CLI bằng cách chạy dòng lệnh này.\ndapr -h Tiếp theo, cài đặt Dapr bằng cách sử dụng lệnh này trong bối cảnh cụm của bạn.\ndapr init -k Bạn có thể xác thực việc cài đặt Dapr bằng cách chạy lệnh này.\ndapr status -k Bạn sẽ nhận được kết quả như thế này.\ndapr-placement-server dapr-system True Running 1 1.15.4 1m 2025-05-12 17:38.08 dapr-dashboard dapr-system True Running 1 0.15.0 1m 2025-05-12 17:38.10 dapr-sentry dapr-system True Running 1 1.15.4 1m 2025-05-12 17:38.08 dapr-operator dapr-system True Running 1 1.15.4 1m 2025-05-12 17:38.08 dapr-sidecar-injector dapr-system True Running 1 1.15.4 1m 2025-05-12 17:38.08 dapr-scheduler-server dapr-system True Running 3 1.15.4 1m 2025-05-12 17:38.08 3. Thiết lập Amazon ElastiCache làm khi lưu trữ trạng thái Ở bước này, bạn sẽ tạo một kho lưu trữ trạng thái cho ứng dụng mẫu của mình sử dụng Amazon ElastiCache Serverless. Dịch vụ được quản lý này tự động mở rộng để đáp ứng lưu lượng truy cập của ứng dụng của bạn mà không yêu cầu về việc quản lý máy chủ.\nĐể làm cho nó đơn giản hơn, hãy tạo một phiên bản Amazon ElastiCache serverless trong cùng một VPC với cụm Amazon EKS của bạn. Cấu hình security group để cho phép những kết nối đến từ cụm Amazon EKS của bạn. Ghi lại endpoint của cache, bạn sẽ cần chúng ở bước thứ 5 trong khi áp dụng các cấu hình Dapr.\n4. Ứng dụng mẫu Trong bước này, bạn cần sao chép một ứng dụng mẫu từ Dapr Quickstarts. Dapr Quickstarts có những ứng dụng mẫu để giúp bạn bắt đầu nhanh chóng với Dapr. Đối với hướng dẫn này, chúng ta sẽ sử dụng các ứng dụng mẫu là ứng dụng Node và ứng dụng Python, nằm trong thư mục hello-kubernetes.\ngit clone https://github.com/dapr/quickstarts.git 5. Cấu hình thành phần kho lưu trữ trạng thái của Dapr Trong bước này, bạn sẽ tạo và cấu hình thành phần kho lưu trữ trạng thái Dapr để giao tiếp với Amazon ElastiCache.\nTạo một file đặt tên là redis-state.yaml với cấu hình kho lưu trữ trạng thái như sau. Hãy thay thế giá trị redisHost bằng endpoint Amazon ElastiCache của bạn từ bước thứ 3.\nCẬP NHẬT apiVersion: dapr.io/v1alpha1 kind: Component metadata: name: statestore namespace: default spec: type: state.redis version: v1 metadata:\nname: redisHost value: redisdaprd-7rr1vd.serv3rless.use1.cache.amazonaws.com:6379 name: enableTLS value: true Áp dụng cấu hình vào cụm của bạn.\nkubectl apply -f redis-state.yaml 6. Triển khai Microservices với Dapr Sidecars Ở bước này, bạn sẽ triển khai hai microservice : một ứng dụng Node với quy trình đặt hàng và ứng dụng Python chứa những logic nghiệp vụ để tạo ra đơn hàng mới. Bạn đã lấy các ứng dụng này ở bước thứ 4 từ Dapr Quickstart.\nĐể triển khai ứng dụng microservice Node, hãy truy cập vào /quickstarts/tutorials/hello-kubernetes/deploy/node.yaml file. Hãy chú ý đến các chú thích Dapr quan trọng.\nChú thích này chỉ thị cho control plane của Dapr chèn một sidecar và gán một tên cho ứng dụng Dapr.\nannotations:\rdapr.io/enabled: \u0026#34;true\u0026#34;\rdapr.io/app-id: \u0026#34;nodeapp\u0026#34;\rdapr.io/app-port: \u0026#34;3000 Thêm chú thích AWS Load Balancer để tạo một internet-facing AWS Load Balancer.\nkind: Service\rapiVersion: v1\rmetadata:\rname: nodeapp\rannotations:\rservice.beta.kubernetes.io/aws-load-balancer-scheme: \u0026#34;internet-facing\u0026#34;\rlabels:\rapp: node\rspec:\rselector:\rapp: node\rports:\r- protocol: TCP\rport: 80\rtargetPort: 3000\rtype: LoadBalancer Kế tiếp, triển khai ứng dụng Node sử dụng kubectl. Điều hướng để thư mục /quickstarts/tutorials/hello-kubernetes/deploy và thực thi lệnh này.\nkubectl apply -f node.yaml Tiếp theo, lấy endpoint của load balancer. Nó xuất hiện dưới mục External IP trong kết quả của lệnh sau đây.\nkubectl get svc nodeapp\rhttp://k8s-default-nodeapp-3a173exxxx-f7b14bedf0c4dd8.elb.us-east-2.amazonaws.com Bây giờ thi dịch vụ của bạn đã được triển khai, hãy xác thực để làm nó hoạt động chính xác hơn, Bạn sẽ kiểm thử chức năng gửi đơn hàng, sử dụng một mẫu tải trọng JSON.\nĐiều hướng đến thư mục /quickstarts/tutorials/hello-kubernetes chỗ có tệp sample.json để thực hiện bước này.\ncurl --request POST --data \u0026#34;@sample.json\u0026#34; --header Content-Type:application/json http://k8s-default-nodeapp-3a173exxxx-f14bedff0c4dd8.elb.us-east-2.amazonaws.com/neworder Bạn có thể xác thực kết quả bằng cách truy cập endpoint /order sử dụng load balancer trên trình duyệt.\nhttp://k8s-default-nodeapp-3a173exxxx-f7b14bedff0c4dd8.elb.us-east-2.amazonaws.com/order\nBạn sẽ nhận được kết quả tương tự như {“OrderId”:“42”}\nĐể hoàn thành phần chuẩn bị microservices của bạn, bạn sẽ cần triển khai ứng dụng Python bây giờ, phần có logic nghiệp vụ để tạo ra mã đơn hàng mới trong mỗi giây. Nó gọi tự động endpoint /neworder của ứng dụng Node.\nĐiều hướng đến thư mục quickstarts/tutorials/hello-kubernetes/deploy và thi hành lệnh này.\nkubectl apply -f python.yaml 7. Xác minh các Microservice đã được kích hoạt Dapr Hãy xác thực kiến trúc microservices của bạn hoạt động chính xác bằng cách kiểm tra nhật ký và endpoints.\nTheo dõi logs của sidecar Dapr thuộc dịch vụ ứng dụng Python để xác thực nó đã tạo ra và gửi đơn hàng. Hãy chạy những dòng lệnh sau đây và bạn sẽ nhận được các lệnh gọi API HTTP xuất hiện liên tục với phương thức là POST /neworder\nkubectl logs --selector=app=python -c daprd --tail=-1\rtime=\u0026#34;2024-03-07T12:43:11.556356346Z\u0026#34; level=info msg=\u0026#34;HTTP API Called\u0026#34; app_id=pythonapp instance=pythonapp-974db9877-dljtw method=\u0026#34;POST /neworder\u0026#34; scope=dapr.runtime.http-info type=log useragent=python-requests/2.31.0 ver=1.12.5\rtime=\u0026#34;2024-03-07T12:43:12.563193147Z\u0026#34; level=info msg=\u0026#34;HTTP API Called\u0026#34; app_id=pythonapp instance=pythonapp-974db9877-dljtw method=\u0026#34;POST /neworder\u0026#34; scope=dapr.runtime.http-info type=log useragent=python-requests/2.31.0 ver=1.12.5 Tiếp theo, kiểm tra log của ứng dụng Node để xác nhận tiến trình đơn hàng và lưu trữ trạng thái. Hãy chạy lệnh sau và bạn sẽ nhận được thông báo xác thực đã xử lý đơn hàng.\nkubectl logs —selector=app=node -c node —tail=-1\rGot a new order! Order ID: 367\rSuccessfully persisted state for Order ID: 367\rGot a new order! Order ID: 368\rSuccessfully persisted state for Order ID: 368\rGot a new order! Order ID: 369\rSuccessfully persisted state for Order ID: 369 Bạn cũng có thể xác thực xem các đơn hàng đang lưu trữ trạng thái đúng cách trên Amazon ElastiCache. Bạn có thể thêm /order vào load balancer của ứng dụng. Nó trả về mã đơn hàng gần nhất mà đã được tạo ra bởi ứng dụng Python.\nhttp://k8s-default-nodeapp-3a173exxxx-f7b14beff0c4dd8.elb.us-east-2.amazonaws.com/order\nBạn sẽ nhận được kết quả của nhiều đơn hàng gần đây như {“OrderId”:“370”}\n8. Trực quan hóa các thành phần Dapr bằng bảng điều khiển ( Dashboard ) Dapr cung cấp một bảng điều khiển mạnh mẽ mà nó có thể giúp cho bạn theo dõi ứng dụng, cấu hình, cách thành thành phần và log của bạn. Bạn có thể thiết lập quyền truy cập bên ngoài thông qua Elastic Load Balancing (ELB).\nTrong phần này, bạn sẽ tạo một tệp yaml cho bảng điều khiển và áp dụng nó vào cụm Amazon EKS của bạn.\nTạo một tệp yaml được gọi là dashboard.yaml với những chú thích.\nkind: Service\rapiVersion: v1\rmetadata:\rname: dapr-mydashboard\rannotations:\rservice.beta.kubernetes.io/aws-load-balancer-scheme: \u0026#34;internet-facing\u0026#34;\rnamespace: dapr-system labels:\rapp: dapr-dashboard\rspec:\rselector:\rapp: dapr-dashboard\rports:\r- protocol: TCP\rport: 80\rtargetPort: 8080\rtype: LoadBalancer Điều hướng đến thư mục chứa dashbroad.yaml và thực hiện lệnh này để tạo dịch vụ.\nkubectl apply -f dashboard.yaml Tiếp theo, hãy lấy endpoint ELB từ dapr-mydashboard bằng cách thực lệnh sau. Chúng ta sẽ sử dụng endpoint này để truy cập đến bảng điều khiển.\nkubectl get svc dapr-mydashboard -n dapr-system Truy cập đến bảng điều khiển Dapr bằng endpoint ELB mà chúng ta đã lấy được, Đây là ví dụ của endpoint URL và ảnh chụp màn hình.\nhttp://k8s-daprsyst-daprdash-ca3914xxxx-b507661502aa8eb.elb.us-east-2.amazonaws.com/overview\nBảng điều khiển Dapr cung cấp cái nhìn chi tiết về ứng dụng Dapr, các thành phần và cấu hình chạy Amazon EKS từ một vùng duy nhất.\nDọn dẹp Chạy lệnh sau để xóa các triển khai của ứng dụng Node và ứng dụng Python có kho lưu trữ trạng thái.\nĐiều hướng đến thư mục /quickstarts/tutorials/hello-kubernetes/deploy để thực hiện các lệnh sau đây.\nkubectl delete -f node.yaml\rkubectl delete -f python.yaml Bạn có thể xóa cụm Amazon EKS của mình bằng lệnh eksctl và xóa Amazon ElasticCache.\nĐiều hướng đến thư mục chứa tệp cluster.yaml để tạo cụm ở bước đầu tiên.\neksctl delete cluster -f cluster-config.yaml Tóm tắt Trong bài viết này, bạn đã được nhìn thấy được cách kết hợp giữa Dapr và Amazon EKS đơn giản hóa việc phát triển và triển khai microservices.\nGiải pháp này mang lại một số lợi ích chính :\nDapr trừu tượng hóa các mô hình hệ thống phân tán phức tạp. Amazon EKS đảm nhiệm phần việc phức tạp trong quản lý Kubernetes. Các nhà phát triển có thể hoàn toàn tập trung vào logic nghiệp vụ. Hỗ trợ tích hợp sẵn các khả năng quan trọng như quản lý trạng thái và giao tiếp giữa các dịch vụ. Hướng đi tiếp theo :\nKhám phá khả năng theo dõi phân tán của Dapr. Tìm hiểu các khối xây dựng bổ sung của Dapr cho những tính năng như pub/sub và quản lý bảo mật. Mở rộng kiến trúc microservice của bạn với khả năng điều phối mạnh mẽ của Amazon EKS. Bằng cách tận dụng Dapr trên Amazon EKS, bạn có thể nhanh chóng phát triển microservices của bạn trong khi vẫn duy trì độ tin cậy và khả năng mở rộng cấp doanh nghiệp. Sự kết hợp cung cấp một nền tảng sẵn sàng cho các ứng dụng hiện đại, chạy trên nền tảng đám mây.\nTìm hiểu thêm ở Dapr documentation và Amazon EKS documentation.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.11-blog11/",
	"title": "Blog 11",
	"tags": [],
	"description": "",
	"content": "Theo dõi, phân tích, và quản lý cách sử dụng công suất từ một giao diện duy nhất với Amazon EC2 Capacity Manager Hôm nay, tôi rất vui khi giới thiệu về Amazon EC2 Capacity Manager, một giải pháp tập trung vào theo dõi, phân tích, và quản lý cách sử dụng công suất trên mọi tài khoản và AWS Regions từ một giao diện duy nhất. Dịch vụ này tổng hợp thông tin về công suất với tốc độ làm mới hàng giờ và cung cấp những lựa chọn tối ưu hóa được ưu tiên, đơn giản hóa quy trình quản lý công suất mà trước đây cần đến tự động hóa tùy chỉnh và thu thập dữ liệu thủ công từ nhiều dịch vụ AWS.\nCác tổ chức sử dụng Amazon Elastic Compute Cloud (Amazon EC2) ở quy mô lớn vận hành hàng trăm loại phiên bản trên nhiều Availability Zone và nhiều tài khoản, sử dụng On-Demand Instances, Spot Instances, và Capacity Reservations. Sự phức tạp này có nghĩa rằng những khách hàng hiện nay phải truy cập dữ liệu công suất thông qua nhiều dịch vụ AWS bao gồm AWS Management Console, Cost and Usage Reports, Amazon CloudWatch và EC2 describe APIs. Cách tiếp cận phân tán này có thể làm tăng khối lượng công việc vận hành do phải thu thập dữ liệu thủ công, chuyển đổi ngữ cảnh giữa các công cụ, và xây dựng các quy trình tự động tùy chỉnh để tổng hợp thông tin phục vụ cho việc phân tích tối ưu hóa công suất.\nEC2 Capacity Manager giúp bạn vượt qua những phức tạp trong vận hành bằng cách hợp nhất mọi công suất dữ liệu vào trong một bảng điều khiển thống nhất. Bạn bây giờ có thể xem số liệu công suất của cross-account và cross-Region cho các phiên bản On-Demand Instances, Spot Instances, và Capacity Reservations trên tất cả AWS Regions thương mại từ một vị trí duy nhất, loại bỏ nhu cầu phải xây dựng các công cụ thu thập dữ liệu tùy chỉnh hoặc điều hướng giữa nhiều dịch vụ AWS.\nKhả năng hiển thị hợp nhất có thể giúp bạn khám phá cách tiết kiệm chi phí bằng cách làm nổi bật những Capacity Reservations chưa được sử dụng hiệu quả, phân tích các mẫu sử dụng giữa các loại phiên bản, và cung cấp thông tin chuyên sâu về mô hình gián đoạn Spot Instance. Bằng cách truy cập vào dữ liệu công suất toàn diện trên một vùng, bạn có thể đưa ra quyết định sáng suốt hơn về việc tối ưu kích thước hạ tầng và tối ưu hóa chi tiêu EC2.\nĐể tôi giới thiệu chi tiết về khả năng của EC2 Capacity Manager.\nBắt đầu với EC2 Capacity Manager Trên giao diện AWS Management Console, ta điều hướng đến Amazon EC2 và chọn Capacity Manager từ ngăn điều hướng. Ta kích hoạt EC2 Capacity Manager thông qua các cài đặt dịch vụ. Dịch vụ tổng hợp dữ liệu lịch sử từ 14 ngày trước đó trong quá trình thiết lập ban đầu.\nTrên bảng điều khiển chính hiển thị mức độ sử dụng công suất trên tất cả các loại phiên bản thông qua phần tổng quan toàn diện, nơi trình bày các chỉ số chính một cách trực quan. Các thẻ tổng quan công suất cho Reservations, Usage và Spot hiển thị xu hướng các chỉ số và sự thay đổi phần trăm để giúp bạn nhận dạng các mẫu công suất nhanh chóng. Bạn có thể áp dụng bộ lọc thông qua điều khiển bộ lọc theo ngày, bao gồm lựa chọn phạm vi ngày, cấu hình múi giờ, và thiết lập khoảng thời gian.\nBạn có thể chọn những đơn vị khác để phân tích dữ liệu theo vCPUS, số lượng phiên bản, hay ước lượng chi phí để hiểu hơn về các mẫu tiêu thụ tài nguyên. Ước lượng chi phí dựa vào mức giá On-Demand đã công bố và không bao gồm Savings Plans hay những phiếu giảm giá khác. Dựa vào mức giá này giúp bạn so sánh tác động tương đối của công suất chưa được tận dụng hết trên các loại phiên bản khác nhau - Ví dụ, 100 giờ vCPU của đặt trước p5 không sử dụng thể hiện tác động chi phí lớn hơn so với 100 giờ vCPU của đặt trước t3 không sử dụng.\nBảng điều khiển bao gồm chi tiết về Usage metrics với cả trực quan hóa tổng thể mức sử dụng và biểu đồ mức sử dụng theo thời gian. Phần tổng thể mức sử dụng thể hiện sự phân tích chi tiết giữa mức sử dụng đã đặt trước, mức sử dụng chưa được đặt trước và Spot usage. Phần biểu đồ mức sử dụng theo thời gian cung cấp thể hiện hình ảnh trực quan hóa xu hướng công suất theo thời gian, giúp bạn nhận diện các mô hình sử dụng và những giai đoạn có nhu cầu cao điểm.\nTrong mục Reservation metrics, Reserved capacity trends trực quan hóa mức sử dụng và không sử dụng công suất đã được đặt trước dựa vào thời gian đã đưa ra, thể hiện tỉ lệ số giờ vCPU đã được đặt trước vẫn chưa được sử dụng so với lượng thời gian sử dụng thực tế, giúp bạn theo dõi các mẫu về hiệu quả sử dụng gói đặt trước và xác định các giai đoạn có mức sử dụng thấp kéo dài. Khả năng hiển thị này giúp bạn giảm bớt chi phí bằng cách xác định mức sử dụng tài nguyên đặt trước chưa sử dụng hiệu quả và giúp cho bạn đưa ra các quyết định hợp lý về điều chỉnh công suất.\nPhần Unused capacity liệt kê công suất đã được đặt trước mà chưa được sử dụng hiệu quả theo từng tổ hợp loại phiên bản và kết hợp Availability Zone ( AZ ), hiển thị cụ thể phần trăm khả năng và loại phiên bản trên những AZ khác. Danh sách được ưu tiên này giúp bạn nhận ra những khả năng tiết kiệm bằng cách hiển thị trực tiếp trên chi phí công suất chưa chưa được sử dụng.\nMục Usage cung cấp xu hướng lịch sử và thống kê sử dụng chi tiết trên mọi AWS Regions cho Spot Instances, On-Demand Instance, và Capacity Reservation. Mức sử dụng Dedicated Hosts không được bao gồm. Dimension filter giúp bạn nhóm và lọc dữ liệu công suất bằng Account ID ( Mã tài khoản ), Region ( Vùng ), Instance Family ( Họ phiên bản ), AZ, và Instance Type ( Loại phiên bản ), tạo chế độ xem tùy chỉnh giúp làm rõ mẫu sử dụng trên các tài khoản của bạn và AWS Organizations. Điều này giúp bạn phân tích cấu hình cụ thể và so sánh hiệu suất trên các tài khoản hoặc các vùng ( Regions ).\nPhần Aggregations cung cấp một bảng sử dụng toàn diện trên EC2 và Spot Instances. Bạn có thể chọn các đơn vị phân tích dữ liệu khác nhau như vCPUS, số lượng phiên bản, hay chi phí ước tính để hiểu hơn về mẫu tiêu thụ tài nguyên. Bảng hiển thị phân tích chi tiết theo họ phiên bản với thống kê sử dụng tổng, số giờ sử dụng đặt trước, số giờ sử dụng không đặt trước, và dữ liệu sử dụng Spot. Mỗi hàng bao gồm một hành động View breakdown để phân tích chi tiết.\nMục Capacity usage or estimated cost trends trực quan hóa các xu hướng sử dụng, mức sử dụng đặt trước, mức sử dụng không đặt trước, và mức sử dụng Spot. Bạn có thể lọc dữ liệu hiển thị và đơn vị đo lường để xem mẫu lịch sử. Những công cụ lọc và phân tích giúp bạn xác định mức sử dụng xu hướng, so sánh chi phí giữa các chiều dữ liệu khác nhau, và đưa ra những quyết định sáng suốt cho việc lập kế hoạch và tối ưu hóa công suất.\nKhi bạn chọn View breakdown từ bảng Aggregations, bạn truy cập chi tiết Usage breakdown dựa vào các bộ lọc theo chiều dữ liệu mà bạn đã chọn. Chế độ xem chi tiết này hiển thị các mẫu mức sử dụng cho từng loại phiên bản riêng lẻ trong phạm vi họ phiên bản và kết hợp AZ đã chọn.\nThẻ Reservations hiển thị mức tận dụng của công suất đã được đặt trước với phân tích tự động khả năng mà tạo ra danh sách ưu tiên về các lựa chọn được tối ưu hóa. Tương tự như thẻ Usage, bạn có thể áp dụng bộ lọc theo chiều dữ liệu về Account ID ( Mã tài khoản ), Region ( Vùng ), Instance Family ( Họ phiên bản ), AZ, và Instance Type ( Loại phiên bản ) cùng với các lựa chọn bổ sung liên quan đến chi tiết của các gói được đặt trước. Trên mỗi thẻ, bạn có thể đi sâu vào để xem dữ liệu cho từng mục riêng lẻ. Cụ thể đối với các gói đặt trước, bạn có thể xem các gói đặt trước cụ thể và truy cập vào thông tin chi tiết về On-Demand Capacity Reservations ( ODCRs ), bao gồm lịch sử sử dụng, thông số cấu hình, và trạng thái hiện tại. Khi ODCR tồn tại trong cùng một tài khoản với Capacity Manager, bạn có thể thay đổi trực tiếp thông số gói được đặt trước trên giao diện này, loại bỏ nhu cầu điều hướng đến các phần riêng biệt trên bảng điều khiển EC2 để quản lý việc đặt trước.\nPhần Statistics cung cấp bảng số liệu tóm tắt, bao gồm tổng số lượng gói đặt trước, phần trăm tận dụng tổng thể, tổng mức công suất được đặt trước, số lượng mức công suất đã dùng và chưa dùng, số lượng đặt trước theo lịch trình trung bình, và số lượng tài khoản, họ phiên bản, và Regions ( Vùng ) mà có gói đặt trước.\nGóc nhìn tổng thể này giúp bạn hiểu cách phân bổ gói đặt trước và các mẫu tận dụng trên cơ sở hạ tầng của bạn. Ví dụ, bạn có thể phát hiện các tài khoản phát triển của mình liên tục cho thấy mức tận dụng gói đặt trước là 30% trong khi các tài khoản production vượt quá 95%, chỉ ra lựa chọn để phân bổ lại hoặc sửa đổi gói đặt trước. Tương tự, bạn cũng có thể xác định các họ phiên bản cụ thể ở một số Region ( Vùng ) nhất định có tỉ lệ tận dụng thấp kéo dài, gợi ý những đối tượng cho việc điều chỉnh gói đặt trước hay tối ưu hóa khối lượng công việc. Những thông tin chuyên sâu này giúp bạn đưa ra các quyết định dựa trên dữ liệu về việc mua, sửa đổi, hoặc hủy bỏ các gói đặt trước để điều chỉnh mức công suất được đặt trước của bạn phù hợp hơn với các mẫu mức sử dụng thực tế.\nThẻ Spot tập trung vào mức sử dụng Spot Instance và hiển thị lượng thời gian mà Spot Instance của bạn chạy trước khi bị gián đoạn. Việc phân tích mẫu mức sử dụng Spot Instance giúp bạn xác định được những cái lựa chọn tối ưu cho khối lượng công việc. Bạn có thể sử dụng các đề xuất về điểm xếp hạng Spot để cải thiện sự linh hoạt của khối lượng công việc.\nĐối với các tổ chức yêu cầu khả năng xuất dữ liệu, Capacity Manager bao gồm tính năng xuất dữ liệu ra các bucket Amazon Simple Storage Service (Amazon S3) để phân tích công suất. Bạn có thể xem và quản lý tác vụ xuất dữ liệu của mình thông qua thẻ Data exports, giúp bạn tạo mới các tác vụ xuất, giám sát trạng thái vận chuyển, và cấu hình lịch trình xuất để phân tích dữ liệu công suất bền ngoài AWS Management Console.\nViệc truy xuất dữ liệu mở rộng khả năng phân tích của bạn bằng cách lưu trữ dữ liệu công suất vượt quá thời gian lưu trữ 90 ngày có sẵn thông qua bảng điều khiển và APIs. Việc lưu trữ kéo dài này cho phép phân tích xu hướng dài hạn và lập kế hoạch mức công suất dựa trên dữ liệu lịch sử. Bạn cũng có thể tích hợp xuất dữ liệu với quy trình làm việc phân tích hiện có, các công cụ kinh doanh thông minh, hay hệ thống báo cáo cá tùy chỉnh để đưa ra số liệu công suất EC2 vào các quá trình phân tích cơ sở hạ tầng và ra quyết định ở phạm vi rộng hơn.\nPhần Settings cung cấp các lựa chọn cấu hình cho việc tích hợp AWS Organizations, cho phép quản lý công suất tập trung trên nhiều tài khoản. Quản trị viên của tổ chức có thể bật khả năng hiển thị công suất trên toàn doanh nghiệp hoặc ủy quyền truy cập cho những tài khoản cụ thể trong khi vẫn duy trì các quyền và kiểm soát truy cập phù hợp.\nKhả dụng hiện tại EC2 Capacity Manager loại bỏ gánh nặng vận hàng của việc thu thập và phân tích dữ liệu công suất từ nhiều nguồn khác nhau. Dịch vụ cung cấp những lựa chọn tối ưu hóa tự động, khả năng hiển thị tập trung trên nhiều tài khoản, và quyền truy cập trực tiếp tới công cụ quản lý công suất. Bạn có thể giảm thời gian phân tích thủ công đồng thời cải thiện việc tận dụng công suất và tối ưu hóa chi phí trên cơ sở hạ tầng EC2.\nAmazon EC2 Capacity Manager được cung cấp mà không cần chi phí bổ sung. Để bắt đầu sử dụng Amazon EC2 Capacity Manager, truy cập tới Amazon EC2 console hoặc trên APIs của dịch vụ. EC2 Capacity Manager khả dụng với tất cả AWS Regions enabled by default thuộc về thương mại.\nTìm hiểu thêm tại EC2 Capacity Manager documentation.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.12-blog12/",
	"title": "Blog 12",
	"tags": [],
	"description": "",
	"content": "Giới thiệu Amazon EBS Volume Clones: Tạo các bản sao tức thì cho EBS volumes của bạn Với tư cách là người đã làm việc tại Sun Microsystems, nơi mà ZFS được phát minh, tôi luôn yêu thích làm việc với các hệ thống lưu trữ có khả năng tạo bản sao volume tức thì cho nhu cầu phát triển và kiểm thử của mình.\nHôm nay, tôi rất vui khi chia sẻ rằng AWS đang mang điều có khả năng tương tự cho Amazon Elastic Block Store (Amazon EBS) với việc ra mắt Amazon EBS Volume Clones, một tính năng mới cho phép bạn tạo các bản sao tức thì ở một thời điểm cụ thể cho các EBS volume của mình bên trong cùng một Availability Zone.\nNhiều khách hàng cần tạo nhiều bản sao về dữ liệu production của họ để hỗ trợ các hoạt động phát triển và kiểm thử trong một môi trường phi production riêng biệt. Cho đến nay, quy trình này đã yêu cầu tạo một EBS snapshot ( được lưu trữ trong Amazon Simple Storage Service (Amazon S3) ) và sau đó tạo mới một volume từ snapshot đó. Mặc dù cách tiếp cận này vẫn hoạt động, quy trình này tạo ra gánh nặng vận hành do có nhiều bước.\nVới Amazon EBS Volume Clones, bây giờ bạn có thể tạo ra các bản sao EBS volume của bạn với một lệnh gọi API hoặc chọn trên giao diện. Các volume được sao chép luôn sẵn sàng trong vài giây và cung cấp truy cập đến dữ liệu của bạn ngay lập tức với độ trễ một chữ số mili giây. Điều này làm cho tính năng Volume Clones đặc biệt hữu ích cho việc cài đặt tùy chỉnh nhanh chóng ở môi trường kiểm thử với dữ liệu production hoặc tạo ra những bản sao tạm thời của cơ sở dữ liệu cho mục đích phát triển.\nĐể tôi giới thiệu cho bạn cách mà Volume Clones hoạt động. Ở bài viết này, tôi đã tạo ra một ví dụ nho nhỏ về Amazon Elastic Compute Cloud (Amazon EC2), với một volume được đính kèm. Tôi đã tạo một tệp ở hệ thống tệp gốc với dòng lệnh echo \u0026quot;Hello CopyVolumes\u0026quot; \u0026gt; hello.txt .\nĐể bắt đầu việc sao chép, tôi mở AWS Management Console ở trên trình duyệt và tôi điều hướng đến EC2, Elastic Block Store, Volumes. Tôi chọn volume mà tôi muốn sao chép.\nLưu ý rằng, tại thời điểm công bố bài viết này, chỉ có các volume đã được mã hóa mới được sao chép.\nTrong mục lục Actions, tôi chọn tùy chọn Copy Volume.\nKế tiếp, tôi chọn chi tiết của volume đích. Tôi có thể thay đổi Volume type và điều chỉnh thông số Size, IOPS, và Throughput. Tôi chọn Copy volume để bắt đầu hoạt động Volume Clone.\nVolume được sao chép sẽ chuyển sang trạng thái Creating và sẵn sàng để sử dụng trong vòng vài giây. Sau đó, tôi có thể đính kèm nó vào trong một phiên bản EC2 và bắt đầu sử dụng nó ngay lập tức.\nKhối dữ liệu đã được sao chép từ volume nguồn và được viết vào volume bản sao ở chế độ nền. Volume sẽ duy trì ở trạng thái Initializing cho đến khi quá trình này hoàn thành. Tôi có thể theo dõi tiến trình của nó với describe-volume-status API. Hoạt động khởi tạo này không ảnh hướng đến hiệu suất của volume nguồn. Tôi có thể tiếp tục sử dụng nó bình thường trong suốt quá trình sao chép.\nTôi rất thích volume được sao chép có thể sử dụng được ngay lập tức. Tôi không cần phải chờ đợi nó khởi tạo hoàn tất. Trong suốt giai đoạn khởi tạo, volume đã được sao chép của tôi sẽ cung cấp hiệu năng dựa trên mức thấp nhất sau : mức cơ bản là 3,000 IOPS và 125 MiB/s, hiệu năng đã cấu hình của volume nguồn, hoặc hiệu năng đã cấu hình của volume bản sao.\nSau quá trình khởi tạo hoàn thành, volume bản sao trở thành bản độc lập đầy đủ của volume nguồn và cung cấp đầy đủ hiệu năng đã cấu hình.\nNgoài ra, tôi có thể sử dụng AWS Command Line Interface (AWS CLI) để bắt đầu việc sao chép :\naws ec2 copy-volumes \\\r--source-volume-id vol-1234567890abcdef0 \\\r--size 500 \\\r--volume-type gp3 Sau khi volume bàn được đã được tạo, tôi đính kèm nó vào trong phiên bản EC2 của mình và mount nó. Tôi có thể kiểm tra tệp mà tôi đã tạo lúc đầu có tồn tại không.\nĐầu tiên, tôi đính kèm volume từ laptop của mình, sử dụng lệnh attach-volume :\naws ec2 attach-volume \\\r--volume-id \u0026#39;vol-09b700e3a23a9b4ad\u0026#39; \\\r--instance-id \u0026#39;i-079e6504ad25b029e\u0026#39; \\\r--device \u0026#39;/dev/sdb\u0026#39; Sau đó, tôi kết nối đến phiên bản, và tôi đánh các lệnh sau :\n$ sudo lsblk -f\rNAME FSTYPE FSVER LABEL UUID FSAVAIL FSUSE% MOUNTPOINTS\rnvme0n1 ├─nvme0n1p1 xfs / 49e26d9d-0a9d-4667-b93e-a23d1de8eacd 6.2G 22% /\r└─nvme0n1p128 vfat FAT16 3105-2F44 8.6M 14% /boot/efi\rnvme1n1 ├─nvme1n1p1 xfs / 49e26d9d-0a9d-4667-b93e-a23d1de8eacd └─nvme1n1p128 vfat FAT16 3105-2F44 $ sudo mount -t xfs /dev/nvme1n1p1 /data\r$ df -h\rFilesystem Size Used Avail Use% Mounted on\rdevtmpfs 4.0M 0 4.0M 0% /dev\rtmpfs 924M 0 924M 0% /dev/shm\rtmpfs 370M 476K 369M 1% /run\r/dev/nvme0n1p1 8.0G 1.8G 6.2G 22% /\rtmpfs 924M 0 924M 0% /tmp\r/dev/nvme0n1p128 10M 1.4M 8.7M 14% /boot/efi\rtmpfs 185M 0 185M 0% /run/user/1000\r/dev/nvme1n1p1 8.0G 1.8G 6.2G 22% /data\r$ cat /data/home/ec2-user/hello.txt Hello CopyVolumes Những điều cần biết Volume Clones tạo ra bản sao ở trên cùng một AZ với volume nguồn của bạn. Bạn chỉ có thể tạo những bản sao từ volumes được mã hóa, và kích thước của bản sao cần phải bằng hoặc lớn hơn volume nguồn.\nVolume Clones tạo ra các bản sao nhất quán tại thời điểm xảy ra sự cố cho các volume của bạn. giống hệt như snapshot. Để đạt được tính nhất quán ở cấp độ ứng dụng, bạn cần phải tạm dừng hoạt động I/O của ứng dụng trước khi tạo ra bản sao. Ví dụ, với cơ sở dữ liệu Postgre SQL, bạn có thể sử dụng các hàm pg_start_backup() và pg_stop_backup() để tạm dừng viết và tạo bản sao nhất quán. Ở cấp độ điều hành trên Linux với XFS, bạn có thể sử dụng lệnh xfs_freeze để đình chỉ tạm thời và khôi phục quyền truy cập đến hệ thống tệp và đảm bảo mọi thứ đã được lưu vào bộ nhớ đệm được viết vào ổ đĩa.\nMặc dù Volume Clones tạo ra bản sao ngay tại thời điểm cụ thể, nó mang tính bổ sung chứ không thay thế EBS snapshot cho mục đích sao lưu. EBS snapshots vẫn là giải pháp được khuyến nghị dành cho việc sao lưu dữ liệu và bảo vệ chống lại các sự cố ở cấp độ AZ và cấp độ volume. Snapshot cung cấp các bản sao lưu gia tăng lên Amazon S3 với độ bền 11 số 9, so với Volume Clones vốn duy trì độ bền của EBS volume ( 99.999% cho io2, 99,9% cho kiểu volume khác ). Hãy cân nhắc sử dụng tính năng Volume Clones cụ thể dành cho các kịch bản môi trường kiểm thử và phát triển nơi mà bạn cần truy cập tức thì để vào volume bản sao.\nCác volume bản sao tồn tại độc lập với các volume nguồn và tiếp tục phát sinh chi phí EBS volume tiêu chuẩn cho đến khi bạn xóa chúng đi. Để quản lý hiệu quả chi phí, thực hiện quyền quản trị để xác định và xóa các volume được sao chép mà không còn cần thiết cho các hoạt động phát triển hay kiếm thử của bạn nữa.\nGiá cả và tính khả dụng Volume Clones hỗ trợ mọi loại EBS volume và làm việc với volume trên cùng một tài khoản AWS và AZ. Tình năng mới này đã có sẵn ở mọi Regions thuộc về thương mại của AWS, Local Zones được chọn, và trong AWS GovCloud (US).\nVề giá cả, bạn sẽ bị tính chi phí một lần cho mỗi GiB dữ liệu ở volume nguồn tại thời điểm khởi tạo, cùng với mức giá EBS tiêu chuẩn cho volume mới.\nTôi thấy tính năng Volume Clones đặc biệt có giá trị cho các khối lượng công việc liên quan đến cơ sở dữ liệu và các kịch bản tích hợp liên tục (CI). Ví dụ, bạn có thể nhanh chóng tạo một bản sao của cơ sở dữ liệu production để kiểm thử các tính năng mới hoặc khắc phục sự cố mà không làm ảnh hưởng đến môi trường production của bạn hoặc phải chờ dữ liệu được nạp đầy đủ từ Amazon S3.\nĐể bắt đầu với Amazon EBS Volume Clones, truy cập Amazon EBS section on the console hoặc xem EBS documentation. Tôi rất mong được nghe về cách bạn sử dụng tính năng này để cải thiện các quy trình phát triển của mình.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Thiết lập IAM Permission cần thiết { \u0026#34;Version\u0026#34;: \u0026#34;2025-12-05\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;ProjectTaskPermission\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:DescribeLogStreams\u0026#34;, \u0026#34;ecr:GetAuthorizationToken\u0026#34;, \u0026#34;ecr:BatchCheckLayerAvailability\u0026#34;, \u0026#34;ecr:GetDownloadUrlForLayer\u0026#34;, \u0026#34;ecr:BatchGetImage\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;cloudwatch:PutMetricData\u0026#34;, \u0026#34;cloudwatch:GetMetricStatistics\u0026#34;, \u0026#34;cloudwatch:ListMetrics\u0026#34;, \u0026#34;cloudfront:CreateInvalidation\u0026#34;, \u0026#34;cloudfront:GetDistribution\u0026#34;, \u0026#34;cloudfront:ListDistributions\u0026#34;, \u0026#34;cloudfront:GetInvalidation\u0026#34;, \u0026#34;cloudfront:ListInvalidations\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListResourceRecordSets\u0026#34;, \u0026#34;route53:GetChange\u0026#34;, \u0026#34;route53:ChangeResourceRecordSets\u0026#34;, \u0026#34;amplify:GetApp\u0026#34;, \u0026#34;amplify:ListApps\u0026#34;, \u0026#34;amplify:GetBranch\u0026#34;, \u0026#34;amplify:ListBranches\u0026#34;, \u0026#34;amplify:StartDeployment\u0026#34;, \u0026#34;amplify:GetJob\u0026#34;, \u0026#34;amplify:ListJobs\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Thiết lập môi trường làm việc Trong workshop này, chúng ta sẽ sử dụng AWS region ap-southeast-2 (Sydney) làm mặc định.\nĐể chuẩn bị cho môi trường làm workshop, bạn cần thiết lập các công cụ và tài nguyên sau:\nTài khoản AWS và cấu hình AWS CLI Đăng nhập vào AWS Console và đảm bảo bạn có quyền truy cập đầy đủ để tạo các tài nguyên sau:\nECS (clusters, services, task definitions). ECR (repositories, images). ALB (load balancers, target groups, listeners). S3 (buckets, objects). CloudWatch (log groups, metrics). IAM (roles, policies). VPC và Networking. Cài đặt AWS CLI vào thiết bị của mình nếu chưa có:\n# Windows (PowerShell) msiexec.exe /i https://awscli.amazonaws.com/AWSCLIV2.msi Cấu hình AWS CLI với Credentials của bạn:\naws configure Nhập các thông tin sau khi được yêu cầu:\nAWS Access Key ID AWS Secret Access Key Default region name: ap-southeast-2 Default output format: json Kiểm tra cấu hình đã thành công:\naws sts get-caller-identity Kết quả sẽ hiển thị Account ID, User ARN và User ID của bạn:\n2. Cài đặt Terraform Tải Terraform từ HashiCorp-Terraform\nGiải nén và thêm vào PATH (hoặc sử dụng package manager):\nchoco install terraform Kiểm tra cài đặt:\nterraform version Kết quả sẽ hiển thị phiên bản Terraform đã cài đặt (ví dụ: Terraform v1.14.0):\n3. Cài đặt các công cụ khác Cài đặt các công cụ khác như Docker, MongoDB, Git, \u0026hellip;\nCách thiết lập MongoDB Atlas (Cloud):\nĐăng ký tài khoản miễn phí tại mongodb.com/cloud/atlas Tạo một cluster miễn phí (M0 Free Tier) Lấy connection string từ MongoDB Atlas dashboard: Click vào \u0026ldquo;Connect\u0026rdquo; trên cluster Chọn \u0026ldquo;Connect your application\u0026rdquo; Copy connection string (ví dụ: mongodb+srv://username:password@cluster.mongodb.net/) Lưu connection string này để sử dụng trong file terraform/dev.tfvars sau này. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.5-deployfe/5.5.2-connect-be-fe/",
	"title": "Cấu hình để kết nối giữa Frontend và Backend",
	"tags": [],
	"description": "",
	"content": "Cấu hình ALB để chấp nhận traffic từ HTTPS. Truy cập EC2, chọn Load Balancer. Chọn ALB của Backend. Chọn Add listener để cấu hình ALB lắng nghe HTTPS 443. Chọn HTTS và nhập Port là 443 Tích chọn Forward to target groups , chọn group của Backend của bạn. Ở phần Certificate Source, chọn From ACM và chọn Certificate bạn đã tạo trước đó. Và nhấn Add listener. Tiếp theo là cấu hình Security Group của ALB để cho phép traffic từ HTTPS 443. Truy cập vào Securiry Group của EC2. Chọn Security Group của ALB. Chọn Edit inbound rules. Thêm HTTPS. Rồi nhấn Save rules. Chúng ta đã thiết lập HTTPS cho domain và cấu hình ALB chấp nhận traffic HTTPS (bao gồm từ Amplify) để chuyển tiếp đến ECS.\nCấu hình Rewrites and redirect cho Amplify Bước tiếp theo, chúng ta quay lại Amplify để cấu hình Frontend sao cho khi gửi request API, ứng dụng Frontend sẽ gọi đến Backend qua endpoint HTTPS của ALB: https://api.webchat.mom.\nChúng ta sẽ vào lại Amplify , chọn Hosting -\u0026gt; Rewrites and redirects. Đây là các Rewrite and directs ban đầu. Trong phần Rewrites and redirects hiện tại thì nếu bạn gọi bất kì đường dẫn nào thì nó sẽ trả về 1 trang index.html. Chúng ta có thể thấy rằng khi Frontend gọi đến đường dẫn /api/auth/login, Amplify áp dụng rule trong mục Rewrites and Redirects và rewrite request đó về file index.html. Vì vậy response trả về chính là trang index.html, như minh họa bên dưới. Chúng ta sẽ quay lại mục Rewrites and Redirects của Amplify để cấu hình sao cho các request API được chuyển tiếp đến domain của ALB, thay vì bị rewrite về trang index.html như hiện tại.\nTrong Rewrites and redirects , ta chọn Manage redirects. Chúng ta sẽ xóa hết các dòng cũ và thêm vào dòng mới như hình dưới .Rồi nhấn Save. Theo hình dưới, ý nghĩa của từng rule như sau:\nDòng 1: Khi Frontend gửi request tới đường dẫn /api/*, Amplify sẽ rewrite request đó sang https://api.webchat.mom/api/*.\nDòng 2: Khi Frontend truy cập bất kỳ đường dẫn nào khác (/*), Amplify sẽ trả về file gốc / (tức là index.html) của ứng dụng.” Truy cập vào lại trang web và nhập các trường và tiến hành đăng nhập. Ở hình dưới, trong tab Network, chúng ta có thể thấy response của request login đã trả về một JSON từ Backend thay vì một trang HTML như trước. Vậy là chúng ta đã thực hiện xong các bước cần thiết để Frontend và Backend có thể kết nối với nhau. Tiếp theo chúng ta sẽ tinh chỉnh tên miền để người dùng có thể dễ tìm kiếm.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-infra-terraform/5.3.2-variables/",
	"title": "Cấu hình Variables",
	"tags": [],
	"description": "",
	"content": "Định nghĩa các biến trong Varaible.tf File variables.tf định nghĩa tất cả các biến được sử dụng trong Terraform configuration:\nvariable \u0026#34;project_name\u0026#34; { description = \u0026#34;Tên dự án, dùng để prefix tài nguyên.\u0026#34; type = string default = \u0026#34;webchat-app\u0026#34; } variable \u0026#34;aws_region\u0026#34; { description = \u0026#34;AWS region để deploy.\u0026#34; type = string default = \u0026#34;ap-southeast-2\u0026#34; } variable \u0026#34;uploads_bucket_name\u0026#34; { description = \u0026#34;Tên S3 bucket dùng để lưu uploads.\u0026#34; type = string } variable \u0026#34;backend_image_tag\u0026#34; { description = \u0026#34;Tag của Docker image backend trên ECR.\u0026#34; type = string default = \u0026#34;latest\u0026#34; } variable \u0026#34;node_env\u0026#34; { description = \u0026#34;Giá trị NODE_ENV cho backend.\u0026#34; type = string default = \u0026#34;production\u0026#34; } variable \u0026#34;jwt_secret\u0026#34; { description = \u0026#34;JWT secret nếu bạn vẫn dùng JWT tự ký trong backend.\u0026#34; type = string sensitive = true } variable \u0026#34;jwt_expires_in\u0026#34; { description = \u0026#34;Thời gian hết hạn access token JWT.\u0026#34; type = string default = \u0026#34;7d\u0026#34; } variable \u0026#34;jwt_refresh_expires_in\u0026#34; { description = \u0026#34;Thời gian hết hạn refresh token JWT.\u0026#34; type = string default = \u0026#34;30d\u0026#34; } variable \u0026#34;cognito_callback_urls\u0026#34; { description = \u0026#34;Danh sách callback URL cho Cognito Hosted UI (VD: URL frontend).\u0026#34; type = list(string) default = [] } variable \u0026#34;cognito_logout_urls\u0026#34; { description = \u0026#34;Danh sách logout URL cho Cognito Hosted UI.\u0026#34; type = list(string) default = [] } variable \u0026#34;default_tags\u0026#34; { description = \u0026#34;Tags chung áp dụng cho tất cả tài nguyên.\u0026#34; type = map(string) default = { managed-by = \u0026#34;terraform\u0026#34; } } variable \u0026#34;mongodb_uri\u0026#34; { description = \u0026#34;URI của MongoDB cho backend.\u0026#34; type = string } # Danh sách email nhận cảnh báo AWS Budgets (vượt ngưỡng chi phí) variable \u0026#34;budget_alert_emails\u0026#34; { description = \u0026#34;Danh sách email sẽ nhận alert khi chi phí AWS vượt ngưỡng budget.\u0026#34; type = list(string) default = [\u0026#34;nguyenngocthanhdai2003@gmail.com\u0026#34;] } #mail smtp: variable \u0026#34;email_host\u0026#34; { description = \u0026#34;Host của SMTP server.\u0026#34; type = string } variable \u0026#34;email_port\u0026#34; { description = \u0026#34;Port của SMTP server.\u0026#34; type = number } variable \u0026#34;email_secure\u0026#34; { description = \u0026#34;Có sử dụng SSL không.\u0026#34; type = bool } variable \u0026#34;email_user\u0026#34; { description = \u0026#34;Tài khoản email.\u0026#34; type = string } variable \u0026#34;email_pass\u0026#34; { description = \u0026#34;Mật khẩu email.\u0026#34; type = string sensitive = true } "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 10: Kiểm thử, hoàn thiện UI và chuẩn bị deploy. Bổ sung tính năng backend, kiểm thử toàn diện API \u0026amp; real-time. Hoàn thiện frontend UI, xử lý lỗi kết nối và trạng thái. Thiết kế kiến trúc AWS. Chuẩn bị tài liệu API và sơ đồ hệ thống. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Ghi chú 2 - Kiểm thử backend: API (REST), WebSocket (real-time).\n10/11/2025 10/11/2025 https://www.postman.com/ 3 - Hoàn thiện frontend UI. - Xử lý lỗi. 11/11/2025 11/11/2025 4 - Thiết kế kiến trúc AWS:\n• Frontend: S3 + CloudFront\n• Backend: Serverless(AWS Lambda, Amazon API Gateway)\n• Database: DynamoDB\n• Real-time: WebSocket 12/11/2025 12/11/2025 AWS Architecture Icons\nDraw.io / Lucidchart 5 - Chuẩn bị tài liệu:\n• API docs (Swagger)\n• Deployment guide 13/11/2025 13/11/2025 Swagger UI\nC4-PlantUML 6 - Team review: duyệt tài liệu, sơ đồ, demo local.\n- Sửa lỗi, tối ưu hệ thống.\n- Chuẩn bị deploy script (Docker + AWS CLI). 14/11/2025 14/11/2025 Kết quả đạt được tuần 10: Backend ổn định và đầy đủ tính năng: API REST hoạt động 100%, WebSocket không mất kết nối. Typing, online status, message seen hoạt động real-time. Frontend hoàn thiện: UI đẹp, hỗ trợ emoji, responsive. Kiến trúc AWS rõ ràng: Sơ đồ hệ thống chi tiết. Lựa chọn dịch vụ tối ưu chi phí \u0026amp; hiệu năng. Tài liệu đầy đủ: API docs tự động từ Swagger. Hướng dẫn deploy từng bước. Toàn bộ code đã review, test local đa user thành công. Sẵn sàng deploy lên AWS. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 11: Xây dựng workshop và hoàn thiện proposal trên Hugo. Triển khai dự án lên AWS Cloud: mạng, database, backend, frontend. Giám sát hệ thống bằng CloudWatch, kiểm tra live, theo dõi chi phí. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Ghi chú 2 - Xây dựng workshop.\n- Hoàn thiện proposal trên Hugo: viết nội dung, thêm sơ đồ, deploy site. 17/11/2025 17/11/2025 3 - Cấu hình mạng AWS: tạo VPC, public subnet, Internet Gateway, Route Table.\n- Thiết lập Security Group cho backend/frontend. 18/11/2025 18/11/2025 4 - Triển khai database trên DyanmoDB tạo cluster, user, connection string.\n- Kết nối backend Nest.js với DyanmoDB 19/11/2025 19/11/2025 5 - Đưa backend lên AWS Lambda, Amazon API Gateway\n- Đưa frontend lên S3 + CloudFront: build Vue.js, upload S3, tạo distribution. 20/11/2025 20/11/2025 6 - Thiết lập CloudWatch: log groups, dashboard (CPU, memory, connections), alarms (high latency).\n- Kiểm tra live: test chat real-time với 5+ users, fix issues.\n- Theo dõi chi phí AWS (Cost Explorer), dọn dẹp nếu cần. 21/11/2025 21/11/2025 Kết quả đạt được tuần 11: Hoàn thiện proposal với sơ đồ hệ thống. Triển khai thành công lên AWS: Mạng VPC ổn định, public subnet cho frontend/backend. Kết nối tốt DynamoDB với Backend. Backend chạy trên EC2 Docker, frontend truy cập qua CloudFront. Giám sát hệ thống: CloudWatch dashboard theo dõi real-time metrics/logs. Alarms gửi alert cho high load, low health. Kiểm tra live toàn diện: Chat hoạt động không lỗi với multiple users, real-time sync. Latency \u0026lt; 200ms, no dropped messages. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 12: Tổng kết toàn bộ dự án web chat thực tập. Hoàn thiện báo cáo cuối kỳ, workshop và proposal. Dọn dẹp toàn bộ tài nguyên AWS, phân tích chi phí. Đánh giá kết quả học tập và rút kinh nghiệm. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Ghi chú 2 - Tổng hợp báo cáo cuối kỳ: mô tả hệ thống, kiến trúc AWS, kết quả triển khai.\n24/11/2025 24/11/2025 3 - Thực hiện workshop demo: trình bày proposal, chạy live hệ thống web chat (frontend, backend, real-time).\n25/11/2025 25/11/2025 4 - Phân tích chi phí AWS: tổng hợp Cost Explorer, xác định dịch vụ tốn nhiều nhất (EC2, CloudFront, MongoDB).\n- Dọn dẹp toàn bộ tài nguyên. 26/11/2025 26/11/2025 5 - Cập nhật Hugo site: thêm báo cáo cuối kỳ, link demo, ảnh chụp hệ thống.\n- Backup toàn bộ code, tài liệu vào GitHub. 27/11/2025 27/11/2025 6 - Nộp báo cáo Hugo workshop. 28/11/2025 28/11/2025 Kết quả đạt được tuần 12: Báo cáo cuối kỳ hoàn chỉnh: Mô tả chi tiết đầy đủ trong 11 tuần, proposal hoàn chỉnh, workshop hoàn thiện. Kết quả live: chat real-time hoạt động mượt, hỗ trợ đa người dùng, latency thấp. Workshop thành công: Trình bày rõ ràng, demo live ổn định. Hugo site hoàn thiện: Đầy đủ worklog tuần 1–12, proposal, sơ đồ, ảnh demo. Kết thúc chương trình thực tập First Cloud Journey. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Bộ nhớ đệm ngoại tuyến với AWS Amplify, TanStack, AppSync và MongoDB Atlas Bài viết trình bày cách xây dựng ứng dụng offline-first với giao diện người dùng lạc quan (optimistic UI) sử dụng AWS Amplify, AWS AppSync, TanStack Query và MongoDB Atlas. Ứng dụng mẫu to-do minh họa cách hiển thị tức thì kết quả CRUD trên giao diện trước khi hoàn tất yêu cầu tới server, cải thiện trải nghiệm người dùng. TanStack Query quản lý bộ nhớ đệm cục bộ, đảm bảo dữ liệu khả dụng khi offline, trong khi AWS Amplify và AppSync cung cấp framework full-stack và API GraphQL. MongoDB Atlas đảm nhận lưu trữ dữ liệu, kết hợp với AWS Lambda và Cognito cho tính năng serverless và quản lý người dùng. Ứng dụng triển khai dễ dàng qua Amplify Gen 2, hỗ trợ đồng bộ hóa dữ liệu và xử lý xung đột đơn giản theo cơ chế \u0026ldquo;first-come, first-served\u0026rdquo;, phù hợp với các ứng dụng có ít xung đột cập nhật.\nBlog 2 - Giới thiệu chuỗi họp cộng đồng AWS CDK AWS công bố chuỗi họp cộng đồng mới cho AWS Cloud Development Kit (CDK), nhằm tạo cơ hội cho các nhà phát triển, từ người mới đến chuyên gia, học hỏi, đặt câu hỏi và chia sẻ phản hồi trực tiếp với đội ngũ CDK. Các buổi họp diễn ra hai lần mỗi quý, được tổ chức trực tuyến để đảm bảo tính bao quát và dễ tiếp cận, với nội dung bao gồm cập nhật lộ trình, demo tính năng, đánh giá đề xuất, và Q\u0026amp;A mở. Buổi họp đầu tiên dự kiến vào ngày 24/6/2025, với hai khung giờ (8h-9h và 17h-18h PDT) để hỗ trợ cộng đồng toàn cầu. Thông tin chi tiết, tài liệu và bản ghi sẽ được đăng trên GitHub và YouTube. Cộng đồng có thể tham gia qua Slack, đề xuất chủ đề trên GitHub, và đóng góp ý kiến qua khảo sát để định hình tương lai của CDK.\nBlog 3 - Bảo mật API ứng dụng Express trong 5 phút với Cedar Bài viết giới thiệu gói authorization-for-expressjs của dự án mã nguồn mở Cedar, cho phép tích hợp kiểm tra phân quyền dựa trên chính sách vào ứng dụng Express trên Node.js chỉ trong vài phút, giảm 90% mã so với cách tích hợp thủ công. Sử dụng mẫu ứng dụng PetStore, Cedar tách biệt logic phân quyền khỏi mã ứng dụng, cho phép định nghĩa chính sách chi tiết thông qua ngôn ngữ Cedar, ví dụ: chỉ nhân viên được phép thực hiện các thao tác ghi (POST /pets, POST /pets/{petId}/sale), trong khi khách hàng chỉ được đọc (GET /pets, GET /pets/{petId}). Gói này tự động tạo lược đồ Cedar từ đặc tả OpenAPI, sinh chính sách mẫu và tích hợp middleware để kiểm tra phân quyền mà không cần gọi dịch vụ từ xa. Ứng dụng được bảo mật thông qua JWT và OIDC, với khả năng kiểm tra chính sách dễ dàng bằng lệnh curl, nâng cao hiệu suất phát triển và đơn giản hóa kiểm tra quyền truy cập.\nBlog 4 - Kiến Trúc Cơ Sở Amazon Bedrock Trong Một Vùng Hạ Tầng AWS Bài viết mô tả một kiến trúc tham chiếu để quản lý và bảo mật quyền truy cập vào các khả năng của Amazon Bedrock trong môi trường AWS đa tài khoản, hay còn gọi là AWS landing zone. Kiến trúc tập trung này bao gồm ba loại tài khoản chính: tài khoản mạng dịch vụ, tài khoản Generative AI và các tài khoản khối lượng công việc. Giải pháp tận dụng Amazon VPC Lattice để đơn giản hóa việc kết nối, bảo mật và giám sát giao tiếp giữa các dịch vụ. Cách tiếp cận này cung cấp một chiến lược bảo vệ đa lớp, thực thi kiểm soát truy cập chi tiết thông qua các chính sách bảo mật cấp mạng và chính sách xác thực của VPC Lattice, đồng thời nhấn mạnh tầm quan trọng của việc giám sát sử dụng và tuân thủ bằng các công cụ như Amazon CloudWatch và AWS CloudTrail.\nBlog 5 - Hiện đại hóa Quy trình Mua sắm SAP với Amazon Appflow, SAP BTP Integration Suite và Amazon Bedrock Bài viết trình bày một giải pháp hiện đại hóa quy trình mua sắm của SAP bằng cách tích hợp các dịch vụ AWS như Amazon AppFlow và Amazon Bedrock với SAP BTP Integration Suite. Kiến trúc này tự động hóa và cải tiến quy trình làm việc mua sắm, đặc biệt tập trung vào một trường hợp sử dụng cho Trợ lý Tìm nguồn cung ứng Bền vững. Hệ thống sử dụng giao diện chatbot và AI tạo sinh để phân tích báo giá dựa trên cả chỉ số về giá cả và tính bền vững. Bằng cách tận dụng Amazon Bedrock để xử lý ngôn ngữ tự nhiên và tích hợp với các hệ thống SAP, giải pháp cung cấp một phương pháp tiếp cận linh hoạt, không máy chủ để chuyển đổi các quy trình mua sắm, giúp chúng hiệu quả hơn và phù hợp với các mục tiêu bền vững.\nBlog 6 - Tối Ưu Hóa Thời Gian Ngừng Hoạt Động Chuyển Đổi Unicode Cho Hệ Thống SAP Trên Oracle Sang AWS Bài viết thảo luận về một phương pháp nhằm giảm thiểu thời gian ngừng hoạt động trong quá trình chuyển đổi Unicode của các hệ thống SAP trên cơ sở dữ liệu Oracle khi di chuyển sang AWS. Bài viết nêu bật một nghiên cứu điển hình của Bell Canada, công ty đã di chuyển thành công hệ thống SAP ERP không phải Unicode 11 TB sang AWS trong vòng chưa đầy 5 giờ, giảm 75% thời gian ngừng hoạt động kỹ thuật so với quy trình chuyển đổi và di chuyển một bước truyền thống. Cách tiếp cận này bao gồm việc thiết lập một hệ thống SAP không phải Unicode tạm thời trên Amazon EC2 và sao chép dữ liệu từ hệ thống tại chỗ bằng Oracle Data Guard. Trong thời gian ngừng hoạt động theo kế hoạch, phiên bản tạm thời này sẽ trở thành nguồn cho việc chuyển đổi Unicode, với các quy trình xuất và nhập chạy song song trên các phiên bản EC2 khác nhau. Phương pháp này, kết hợp với các phương pháp hay nhất như kiểm tra trước và đảm bảo độ tin cậy của mạng, tận dụng cơ sở hạ tầng có thể mở rộng của AWS để giảm thiểu sự gián đoạn kinh doanh và tối ưu hóa hiệu quả hoạt động.\nBlog 7 - GNOME có một đối tác cung cấp hạ tầng mới: Chào mừng AWS ! GNOME đã hợp tác với AWS thông qua chương trình tài trợ Tín dụng Mã nguồn Mở để di chuyển cơ sở hạ tầng lên đám mây, giải quyết các hạn chế kỹ thuật nghiêm trọng của hệ thống cũ vốn không còn đáp ứng được tốc độ tăng trưởng nhanh chóng. Bằng cách tận dụng hạ tầng linh hoạt của AWS, đội ngũ SRE nhỏ gọn của GNOME đã khắc phục hoàn toàn các vấn đề về mạng và lưu trữ, đồng thời giảm thiểu gánh nặng bảo trì, tăng cường bảo mật và tối ưu hóa chi phí nhờ sử dụng chip Graviton. Sự chuyển đổi này giúp GNOME cung cấp một nền tảng ổn định, hiệu suất cao và sẵn sàng mở rộng để phục vụ cộng đồng người dùng toàn cầu.\nBlog 8 - Tận dụng các Mô hình Ngôn ngữ lớn (LLM) như 1 Sự bổ sung cho Việc điều chỉnh Siêu tham số Truyền thống Bài viết giới thiệu một phương pháp đột phá sử dụng Mô hình Ngôn ngữ Lớn (LLM) để tự động thiết kế lại kiến trúc mạng thần kinh nhằm cải thiện hiệu suất, thay thế cho việc tinh chỉnh siêu tham số tốn kém tài nguyên. Thông qua quy trình làm việc đa tác nhân (sử dụng LangGraph và Amazon Bedrock), hệ thống sẽ phân tích các chỉ số đào tạo như chuẩn gradient để phát hiện điểm nghẽn, từ đó cho phép LLM đóng vai trò \u0026ldquo;chuyên gia\u0026rdquo; đưa ra các điều chỉnh cấu trúc mạng một cách linh hoạt. Kết quả thực nghiệm trên tập dữ liệu CIFAR chứng minh tính hiệu quả vượt trội khi kiến trúc do LLM tối ưu hóa đạt độ chính xác tới 83% (so với mức 10% của mô hình cơ sở), khẳng định tiềm năng của việc ứng dụng AI để tự động hóa quá trình phát triển các mô hình học máy phức tạp.\nBlog 9 - Góc nhìn thống nhất của bạn về du khách và khách hàng từ Amazon Connect Customer Profiles Bài viết giới thiệu Amazon Connect Customer Profiles dành riêng cho ngành du lịch và khách sạn, giải pháp giúp khắc phục tình trạng dữ liệu phân mảnh bằng cách tự động hợp nhất thông tin từ hơn 75 nguồn vào một hồ sơ khách hàng 360 độ thống nhất theo thời gian thực. Công cụ này không chỉ đảm bảo tuân thủ các tiêu chuẩn bảo mật toàn cầu mà còn tích hợp AI tạo sinh để phân tích dữ liệu và dự đoán hành vi, giúp nhân viên cung cấp dịch vụ cá nhân hóa sâu sắc hơn. Với khả năng xử lý độ trễ cực thấp và mô hình thanh toán linh hoạt theo mức sử dụng, đây là chìa khóa giúp doanh nghiệp nâng cao trải nghiệm và gia tăng lòng trung thành của khách hàng một cách hiệu quả.\nBlog 10 - Tăng tốc phát triển Microservices với DAPR và Amazon EKS Bài viết trình bày giải pháp tăng tốc phát triển microservices bằng cách kết hợp Dapr (Distributed Application Runtime) và Amazon EKS, giúp các nhà phát triển tập trung vào logic nghiệp vụ thay vì lo lắng về cơ sở hạ tầng phức tạp. Dapr cung cấp các khối xây dựng đa nền tảng để xử lý các vấn đề kỹ thuật chung như quản lý trạng thái hay giao tiếp dịch vụ, khi kết hợp với khả năng quản lý cụm và mở rộng linh hoạt của Amazon EKS sẽ tạo nên một hệ thống có tính di động cao, khả năng tự phục hồi mạnh mẽ và dễ dàng tích hợp với hệ sinh thái AWS (như DynamoDB, S3). Giải pháp này giúp trừu tượng hóa sự phức tạp của hệ thống phân tán, mang lại một nền tảng vận hành cấp doanh nghiệp ổn định, an toàn và sẵn sàng cho sản xuất.\nBlog 11 - Theo dõi, phân tích, và quản lý cách sử dụng công suất từ một giao diện duy nhất với Amazon EC2 Capacity Manager Bài viết giới thiệu Amazon EC2 Capacity Manager, một giải pháp quản lý tập trung miễn phí giúp giám sát và phân tích dung lượng EC2 trên toàn bộ các tài khoản và khu vực AWS mà không cần các công cụ tổng hợp thủ công phức tạp. Dịch vụ này hợp nhất dữ liệu từ On-Demand, Spot và Capacity Reservations vào một giao diện duy nhất, cung cấp cái nhìn sâu sắc về xu hướng sử dụng và tự động phát hiện các tài nguyên lãng phí để tối ưu hóa chi phí. Bên cạnh khả năng điều chỉnh trực tiếp các đặt chỗ dung lượng và xuất dữ liệu sang S3 để phân tích nâng cao, công cụ còn tích hợp chặt chẽ với AWS Organizations, giúp doanh nghiệp đưa ra các quyết định hạ tầng chính xác và hiệu quả hơn.\nBlog 12 - Giới thiệu Amazon EBS Volume Clones: Tạo các bản sao tức thì cho EBS volumes của bạn Bài viết giới thiệu Amazon EBS Volume Clones, tính năng mới giúp tạo bản sao tức thời của volume EBS trong cùng một Availability Zone chỉ với một thao tác đơn giản, cho phép truy cập dữ liệu ngay lập tức với độ trễ thấp mà không ảnh hưởng đến hiệu suất của volume nguồn. Giải pháp này lý tưởng cho việc thiết lập nhanh môi trường kiểm thử hoặc phát triển từ dữ liệu thực tế, thay thế hiệu quả cho quy trình tạo snapshot thủ công tốn thời gian trước đây. Mặc dù yêu cầu volume nguồn phải được mã hóa và áp dụng phí khởi tạo một lần dựa trên dung lượng, Volume Clones được định vị là công cụ tăng tốc quy trình làm việc chứ không thay thế vai trò sao lưu và bảo vệ dữ liệu dài hạn của EBS Snapshots.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.5-deployfe/5.5.3-custom-domain-be/",
	"title": "Cấu hình Custom Domain với Route53 và xác thực SSL với AWS Certificate Manager",
	"tags": [],
	"description": "",
	"content": "Chuẩn bị Domain của bạn Đầu tiên bạn cần phải mua 1 Domain ở bất kì nhà cung cấp Domain nào mà bạn muốn, ở đây mình đã mua 1 Domain có tên là webchat.mom của Porkbun. Tạo Hosted Zone trong Route53 và trỏ Domain đó về HostedZone này. Truy cập vào Route53 và chọn Create hosted zones -\u0026gt; Get Started Nhập tên domain bạn đã mua vào ô Domain Name . Rồi nhấn Create hosted zone. Nhập tên domain bạn đã mua vào ô Domain Name . Rồi nhấn Create hosted zone. Sau khi tạo xong Hosted Zone , nhấn Hosted zone details vừa tạo , rồi copy lại 4 dòng Name Servers. Quay trở lại trang quản lý Domain mà bạn đã mua Domain ,ở đây mình mua ở Pokbun , mình sẽ tiến hành đổi 4 Name Servers của domain thành 4 Name Servers của Hosted Zone. Chọn NameServers Xóa 4 DNS có sẵn trong NameServers. Thay bằng 4 DNS của Hosted Zone lúc nãy. Rồi nhấn Submit. Yêu cầu chứng chỉ cho Domain Với Amazon Certificate Manager Truy cập vào Amazon Certificate Manager , chọn Request a certificate. Chọn Request a public certificate, rồi nhấn Next. Chúng ta tiến hành nhập Domain vào Domain names với dòng 1 là Domain dành cho backend và Domain 2 là dành cho frontend . Kéo xuống dưới và chọn Request. Chọn Create records in Route53 và nhấn Create Record để thêm 2 dòng Domain đó vào Hosted Zone của Route53. Chọn 2 Domain và nhấn Create records. Đợi vài phút status sẽ hoành thành tạo Certificate. Quay trở lại Route53 , tìm Hosted Zone đã tạo , tiến hành chọn Create record để tạo Alias tới DNS của ALB Backend. Tiến hành nhập subdomain cho backend và bật Alias rồi chọn Alas to Application and Classic Load Balancer , rồi chọn Region và ALB mà bạn đã tạo trước đó cho Backend .Rồi nhấn Create records. Chúng ta đã hoàn tất cấu hình DNS trên Route 53 bằng cách tạo một Alias record trỏ domain api.webchat.mom tới Application Load Balancer. Vậy là chúng ta đã hoàn tất thiết lập và cấp chứng chỉ SSL cho Domain đã mua. Tiếp theo chúng ta sẽ cấu hình các bước cần thiết để kết nối giữa Frontend và Backend.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-infra-terraform/5.3.3-env-variable/",
	"title": "Cấu hình Variables cục bộ",
	"tags": [],
	"description": "",
	"content": "Định nghĩa các biến xài cục bộ File dev.tfvars chứa các giá trị cụ thể cho các variables xài cục bộ được định nghĩa:\nproject_name = \u0026#34;webchat-app-dev\u0026#34; aws_region = \u0026#34;ap-southeast-2\u0026#34; mongodb_uri = \u0026#34;mongodb+srv://username:password@cluster.mongodb.net/\u0026#34; uploads_bucket_name = \u0026#34;webchat-app-dev-uploads-2025-sg123456\u0026#34; backend_image_tag = \u0026#34;latest\u0026#34; node_env = \u0026#34;production\u0026#34; jwt_secret = \u0026#34;your-secret-key-here\u0026#34; jwt_expires_in = \u0026#34;7d\u0026#34; jwt_refresh_expires_in = \u0026#34;30d\u0026#34; email_host = \u0026#34;smtp.gmail.com\u0026#34; email_port = 587 email_secure = false email_user = \u0026#34;your-email@gmail.com\u0026#34; email_pass = \u0026#34;your-app-password\u0026#34; default_tags = { managed-by = \u0026#34;terraform\u0026#34; env = \u0026#34;dev\u0026#34; app = \u0026#34;webchat-app\u0026#34; } File dev.tfvars cần được điều chỉnh với các giá trị thực tế của bạn: Thay thế MongoDB URI với connection string thực tế. Đặt tên S3 bucket unique (S3 bucket names phải globally unique). Cung cấp VPC ID và subnet IDs từ AWS account của bạn. Cấu hình email SMTP credentials. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-infra-terraform/",
	"title": "Thiết lập Infrastructure với Terraform",
	"tags": [],
	"description": "",
	"content": "Tổng quan về Infrastructure as Code Trong phần này, chúng ta sẽ sử dụng Terraform để định nghĩa và triển khai toàn bộ hạ tầng AWS cho ứng dụng WebChat. Terraform cho phép chúng ta quản lý infrastructure một cách nhất quán, có thể tái sử dụng và dễ dàng version control.\nHạ tầng được triển khai bao gồm các thành phần chính sau:\nS3 Bucket: Lưu trữ files được upload từ users ECR Repository: Registry cho Docker images của backend ECS Cluster và Service: Container orchestration cho backend application Application Load Balancer: Phân phối lưu lượng và routing IAM Roles và Policies: Quản lý quyền truy cập CloudWatch Logs: Thu thập và lưu trữ logs AWS Budgets: Giám sát chi phí Nội dung Cấu hình Provider Cấu hình Variables Cấu hình Variables cục bộ Cấu hình S3 Bucket Cấu hình ECR Repository Cấu hình ECS Cluster Cấu hình Application Load Balancer và Target Group Cấu hình IAM Roles và Policies Cấu hình CloudWatch Logs \u0026amp; ECS Service Cấu hình AWS Budgets Cấu hình VPC Triển khai Infrastructure Sau khi đã cấu hình tất cả các files Terraform, thực hiện các bước sau để deploy infrastructure:\nBước 1: Khởi tạo Terraform\ncd terraform terraform init Lệnh này sẽ download AWS provider và khởi tạo backend. Kết quả sẽ hiển thị \u0026ldquo;Terraform has been successfully initialized!\u0026rdquo;:\nBước 2: Xem kế hoạch triển khai\nterraform plan -var-file=\u0026#34;dev.tfvars\u0026#34; Lệnh này sẽ hiển thị tất cả các resources sẽ được tạo. Kiểm tra kỹ để đảm bảo không có lỗi và resources đúng như mong đợi:\nBước 3: Triển khai infrastructure\nterraform apply -var-file=\u0026#34;dev.tfvars\u0026#34; Terraform sẽ hỏi xác nhận. Nhập yes để tiếp tục. Quá trình triển khai có thể mất 5-10 phút:\nBước 4: Kiểm tra kết quả\nterraform output Lệnh này sẽ hiển thị các outputs quan trọng như ALB DNS name, ECR repository URL, S3 bucket name:\nSau khi triển khai thành công, bạn sẽ có:\n1 S3 bucket với encryption và versioning. 1 ECR repository. 1 ECS cluster. 1 VPC với public subnets. 1 Application Load Balancer với target group. IAM roles và policies. CloudWatch log group. AWS Budgets. Sau khi triển khai thành công, bạn có thể kiểm tra nhanh bằng AWS CLI:\naws s3 ls aws ecr describe-repositories aws ecs list-clusters aws elbv2 describe-load-balancers aws iam list-roles aws logs describe-log-groups # Thay \u0026lt;ACCOUNT_ID\u0026gt; bằng AWS account ID của bạn aws budgets describe-budgets --account-id \u0026lt;ACCOUNT_ID\u0026gt; Kết quả sẽ hiển thị các resources đã tạo nếu CLI của bạn đã cấu hình đúng quyền và region: "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.4-docker-deploybe/",
	"title": "Build Docker Image và Deploy Backend",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Build Docker image backend (NestJS) bằng Dockerfile viết sẵn. Push image lên ECR. Cập nhật ECS service dùng image mới. Kiểm tra health check và chức năng sau deploy. 1. Kiểm tra Dockerfile File: backend/Dockerfile Command start: node dist/main.js. FROM node:20-alpine AS deps WORKDIR /app COPY package*.json ./ RUN npm ci --no-audit --no-fund FROM node:20-alpine AS build WORKDIR /app COPY --from=deps /app/node_modules ./node_modules COPY package*.json ./ COPY tsconfig*.json ./ COPY src ./src RUN npm run build FROM node:20-alpine AS prod WORKDIR /app COPY package*.json ./ RUN npm ci --omit=dev --no-audit --no-fund COPY --from=build /app/dist ./dist ENV NODE_ENV=production # Port Nest lắng nghe – ECS/ALB đang trỏ port 3000 ENV PORT=3000 EXPOSE 3000 # Start Nest app HTTP (main.ts) CMD [\u0026#34;node\u0026#34;, \u0026#34;dist/main.js\u0026#34;] 2. Đăng nhập ECR aws ecr get-login-password --region ap-southeast-2 \\ | docker login --username AWS --password-stdin 986446886396.dkr.ecr.ap-southeast-2.amazonaws.com Thay repository URI nếu khác account/region. Terminal login ECR thành công: 3. Build image docker build -t webchat-app-dev-backend . Thực thi tại thư mục backend/. Output build thành công:\n4. Kiểm tra repository image trên AWS ECR Đăng nhập AWS Console và mở ECR repository. Kiểm tra repository, ảnh dưới hiển thị image webchat-app-dev-backend. Nhấp vào image webchat-app-dev-backend để xem chi tiết. Trong hình trên, có nhiều tag cho image webchat-app-dev-backend. Tag latest là image mới nhất được push. Chọn \u0026ldquo;View push commands\u0026rdquo; để xem lệnh push image. 5. Tag image với ECR docker tag webchat-app-dev-backend:latest \\ 986446886396.dkr.ecr.ap-southeast-2.amazonaws.com/webchat-app-dev-backend:latest 6. Push image lên ECR docker push 986446886396.dkr.ecr.ap-southeast-2.amazonaws.com/webchat-app-dev-backend:latest ECR repository với tag/digest mới:\n7. Kiểm tra sau deploy Kiểm tra API nhanh qua /api/auth/login: "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": "Trong thời gian thực tập, em đã tham gia sự kiện cung cấp những hiểu biết có giá trị về công nghệ AWS Cloud và các thực tiễn trong ngành.\nSự kiện 1 Tên sự kiện: Kick-off AWS FCJ Workforce - OJT FALL 2025\nNgày \u0026amp; Giờ: 09:00, ngày 06 tháng 9 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, Số 02 Đường Hải Triều, Phường Bến Nghé, Thành phố Hồ Chí Minh\nVai trò: Người tham dự\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-infra-terraform/5.3.4-s3-bucket/",
	"title": "Cấu hình S3 Bucket",
	"tags": [],
	"description": "",
	"content": "Tạo S3 Bucket cho File Storage File s3.tf định nghĩa S3 bucket với các cấu hình bảo mật và versioning:\nresource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;uploads\u0026#34; { bucket = var.uploads_bucket_name tags = merge( var.default_tags, { Name = \u0026#34;${var.project_name}-uploads\u0026#34; } ) } resource \u0026#34;aws_s3_bucket_versioning\u0026#34; \u0026#34;uploads\u0026#34; { bucket = aws_s3_bucket.uploads.id versioning_configuration { status = \u0026#34;Enabled\u0026#34; } } resource \u0026#34;aws_s3_bucket_server_side_encryption_configuration\u0026#34; \u0026#34;uploads\u0026#34; { bucket = aws_s3_bucket.uploads.id rule { apply_server_side_encryption_by_default { sse_algorithm = \u0026#34;AES256\u0026#34; } } } resource \u0026#34;aws_s3_bucket_public_access_block\u0026#34; \u0026#34;uploads\u0026#34; { bucket = aws_s3_bucket.uploads.id block_public_acls = true block_public_policy = true ignore_public_acls = true restrict_public_buckets = true } S3 bucket được cấu hình với:\nVersioning: Enabled để lưu trữ multiple versions của files Encryption: AES256 server-side encryption để bảo mật data Public Access Block: Tất cả public access bị chặn để đảm bảo security Bucket name phải globally unique. Đảm bảo uploads_bucket_name trong dev.tfvars là unique.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.5-deployfe/5.5.4-custom-domain-fe/",
	"title": "Tùy chỉnh Domain cho Amplify Frontend",
	"tags": [],
	"description": "",
	"content": "Thêm Custom Domain cho Amplify Frontend. Truy cập vào Amplify , chọn Add custom domain. Tiếp tục chọn Add domain. Chọn tên miền đã thêm vào Hosted Zone trong Route53 rồi chọn Configure domain. Tích vào Set up redirect v.v để đảm bảo rằng bất kỳ người dùng nào nhập www.webchat.mom cũng sẽ tự động được đưa đến webchat.mom, giúp trải nghiệm đồng nhất và tối ưu .Sau đó nhấn Add domain.\nĐợi vài phút , để Custom Domain sẵn sàng. Vậy là xong. Vào trình duyệt nhập webchat.mom để xem kết quả. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-infra-terraform/5.3.5-ecr/",
	"title": "Cấu hình ECR Repository",
	"tags": [],
	"description": "",
	"content": "Tạo ECR Repository cho Docker Images File ecr.tf định nghĩa ECR repository để lưu trữ Docker images:\nresource \u0026#34;aws_ecr_repository\u0026#34; \u0026#34;backend\u0026#34; { name = \u0026#34;${var.project_name}-backend\u0026#34; image_scanning_configuration { scan_on_push = true } tags = merge( var.default_tags, { Name = \u0026#34;${var.project_name}-backend-ecr\u0026#34; } ) } ECR repository được cấu hình với:\nImage Scanning: Enabled để tự động scan images khi push. Repository name: ${var.project_name}-backend. Sau khi tạo repository, bạn sẽ sử dụng repository URL để push Docker images trong phần deploy backend.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.5-deployfe/",
	"title": "Triển khai Frontend với Amazon Amplify và thực hiện kết nối an toàn với API của Backend",
	"tags": [],
	"description": "",
	"content": "Tổng quan về triển khai Frontend với Amazon Amplify và thực hiện kết nối với API của Backend . Trong phần này , chúng ta sẽ từng bước triển khai ứng dụng Frontend (sử dụng Vue.js) lên dịch vụ Hosting tĩnh của AWS Amplify, đồng thời thiết lập kết nối an toàn và hiệu quả với Backend API đang chạy trên ECS/ALB bằng cách sử dụng Tên miền Tùy chỉnh (Custom Domain), AWS Route 53, AWS Certificate Manager (ACM) và cơ chế Rewrite/Redirect của Amplify.\nCác dịch vụ chúng ta sẽ cần sử dụng trong quá trình triển khai :\nAmazon Amplify : Dùng để triển khai Frontend Vue.js lên Amplify Hosting, tự động xây dựng và phân phối nội dung Frontend đến người dùng thông qua CDN (dịch vụ cơ sở của Amplify Hosting, bao gồm CloudFront). Đồng thời, sử dụng cơ chế Rewrite/Redirects để chuyển tiếp yêu cầu API tới Backend. Route 53 : Dùng để tạo Hosted Zone và quản lý các bản ghi DNS cho tên miền tùy chỉnh (ví dụ: webchat.mom). Dùng để trỏ Name Servers từ nhà cung cấp tên miền bên thứ ba (Porkbun) về Route 53. Cuối cùng là tạo bản ghi Alias để trỏ subdomain API (api.webchat.mom) về Application Load Balancer (ALB) của Backend. Amazon Certificate Management : Dùng để yêu cầu và cấp chứng chỉ SSL/TLS công cộng (Public Certificate) cho các tên miền (Frontend và Backend). Chứng chỉ này sau đó được gắn vào ALB của Backend và được sử dụng bởi Amplify Hosting để bật HTTPS. Nội dung Triển khai Frontend lên AWS Amplify Cấu hình để kết nối giữa Frontend và Backend Cấu hình Custom Domain với Route53 và xác thực SSL với AWS Certificate Manager Tùy chỉnh Domain cho Amplify Frontend "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Phát triển ứng dụng Web Chat sử dụng các dịch vụ AWS Tổng quan Workshop này cung cấp hướng dẫn chi tiết để xây dựng một ứng dụng WebChat hoàn chỉnh, sử dụng các công nghệ và dịch vụ hiện đại. Ứng dụng được phát triển theo kiến trúc monorepo với backend được containerized và deploy trên nền tảng đám mây AWS.\nVề mặt công nghệ, workshop sử dụng NestJS làm framework backend, được đóng gói trong Docker containers và triển khai trên Amazon ECS Fargate để đảm bảo khả năng mở rộng và quản lý tự động. Phía frontend được xây dựng bằng VueJS với công cụ build Vite và được triển khai trên CloudFront, sử dụng Socket.io-client để kết nối real-time với backend và sử dụng Pinia để quản lý state.\nTính năng real-time messaging được triển khai thông qua Socket.io, cho phép giao tiếp hai chiều giữa client và server một cách hiệu quả. Amazon S3 đóng vai trò là kho lưu trữ tập trung cho các file được người dùng upload, đảm bảo tính sẵn sàng và độ bền của dữ liệu.\nNội dung Tổng quan về workshop Chuẩn bị Thiết lập Infrastructure với Terraform Build Docker Image và Deploy Backend Triển khai Frontend Dọn dẹp tài nguyên "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-infra-terraform/5.3.6-ecs-cluster/",
	"title": "Cấu hình ECS Cluster",
	"tags": [],
	"description": "",
	"content": "Tạo ECS Cluster File ecs-cluster.tf định nghĩa ECS cluster:\nresource \u0026#34;aws_ecs_cluster\u0026#34; \u0026#34;backend\u0026#34; { name = \u0026#34;${var.project_name}-ecs-cluster\u0026#34; tags = var.default_tags } ECS cluster là container orchestration platform, nơi các ECS tasks sẽ chạy. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "1. Dọn dẹp dịch vụ backend được tạo bởi terraform Để dọn dẹp dịch vụ backend được tạo bởi terraform, chạy lệnh sau trong terminal:\nterraform destroy -var-file=\u0026#34;dev.tfvars\u0026#34; Lệnh này sẽ yêu cầu bạn xác nhận việc phá hủy các tài nguyên. Nhập yes và nhấn Enter để tiếp tục.\nKhi hoàn tất thành công, bạn sẽ thấy thông báo cho biết các tài nguyên đã được phá hủy, nhưng trong trường hợp này có 2 lỗi là deleting-s3-bucket và ECR-Repository. Điều này là do S3 bucket không trống và ECR repository chứa images.\nĐể xóa hoàn toàn S3 bucket và ECR repository, bạn cần xóa thủ công các đối tượng trong S3 bucket và các images trong ECR repository trên AWS Management Console.\n2. Xóa các đối tượng trong S3 bucket Truy cập S3 console.\nTìm bucket có tên webchat-app-dev-uploads-2025-sg123456 như trong ảnh chụp màn hình bên dưới và nhấp vào nó.\nChúng ta cần làm trống bucket trước khi xóa nó. Nhấp vào nút \u0026ldquo;Empty\u0026rdquo;.\nXác nhận hành động bằng cách nhập \u0026ldquo;permanently delete\u0026rdquo; vào ô input và nhấp vào nút \u0026ldquo;Empty bucket\u0026rdquo;. Sau một vài phút, bucket sẽ được làm trống.\nBây giờ, quay lại danh sách S3 bucket, chọn lại bucket và nhấp vào nút \u0026ldquo;Delete\u0026rdquo; để xóa bucket trống.\nXác nhận việc xóa bằng cách nhập tên bucket và nhấp vào nút \u0026ldquo;Delete\u0026rdquo;.\n3. Xóa images trong ECR repository Truy cập ECR console.\nTìm repository có tên webchat-app-dev-backend và nhấp vào nó.\nChọn tất cả images trong repository bằng cách đánh dấu vào checkbox bên cạnh \u0026ldquo;Image Tag\u0026rdquo;.\nNhấp vào nút \u0026ldquo;Delete\u0026rdquo; để xóa các images đã chọn.\nXác nhận việc xóa image bằng cách nhập \u0026ldquo;delete\u0026rdquo; vào ô input và nhấp vào nút \u0026ldquo;Delete\u0026rdquo;.\nSau khi xóa tất cả images trong repository, quay lại terminal và chạy lại lệnh terraform destroy:\nterraform destroy -var-file=\u0026#34;dev.tfvars\u0026#34; Lần này, lệnh sẽ hoàn thành thành công mà không có lỗi nào.\nSau khi hoàn thành các bước này, bạn đã dọn dẹp thành công dịch vụ backend và tất cả các tài nguyên liên quan được tạo bởi terraform.\n4. Dọn dẹp dịch vụ Frontend đã triển khai với Amplify. Truy cập vào Amazon Amplify , chọn App bạn đã deploy. Từ thanh bên trái chọn App Settings -\u0026gt; General settings. Ở mục Delete app ,chọn nút Delete app. Nhập \u0026ldquo;delete\u0026rdquo; để xác nhận muốn xóa App này, rồi nhấn nút Delete app. Thông báo xóa App thành công, vậy là App Frontend đã được dọn dẹp. Sau khi xong các bước trên, chúng ta đã dọn dẹp xong Frontend trên dịch vụ Amplify, tiếp theo chúng ta sẽ dọn dẹp Hosted Zone mà chúng ta đã tạo để Domain trỏ đến Hosted Zone này.\n5. Dọn dẹp Hosted Zone trong Route53. Truy cập vào Route53 -\u0026gt; Hosted Zone , chọn Hosted Zone bạn cần dọn dẹp. Chọn tất cả các Record ngoại trừ 2 Record mặc định là NS và SOA. Chọn Delete records. Kiểm tra lại và nhấn Delete. Sau khi xóa thành công , quay trở lại Hosted Zone, chọn Hosted Zone cần dọn dẹp, nhấn Delete. Nhập delete để xác nhận muốn xóa Hosted Zone này, nhấn Delete. Vậy là đã dọn dẹp thành công các tài nguyên đã sử dụng của dịch vụ AWS.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt kỳ thực tập tại Công ty TNHH Amazon Web Services Việt Nam từ 08/09/2025 đến 12/12/2025, tôi có cơ hội vận dụng kiến thức đã học vào môi trường làm việc thực tế, đồng thời tích lũy thêm nhiều trải nghiệm quý giá.\nTôi tham gia vào quá trình phát triển ứng dụng Web Chat và triển khai sản phẩm trên nền tảng dịch vụ AWS, qua đó trau dồi kỹ năng lập trình, nâng cao khả năng đọc hiểu các công nghệ mới, làm chủ việc cấu hình dự án và triển khai các dịch vụ AWS đồng thời trau dồi thêm kĩ năng giao tiếp giữa các thành viên trong nhóm với nhau.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ✅ ☐ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ☐ ✅ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tư duy giải quyết vấn đề. Rèn luyện kỹ năng giao tiếp hằng ngày và trong công việc, đặc biệt khi xử lý tình huống. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-infra-terraform/5.3.7-alb/",
	"title": "Cấu hình Application Load Balancer và Target Group",
	"tags": [],
	"description": "",
	"content": "Tạo Application Load Balancer và Target Group File alb.tf định nghĩa ALB, security groups, target group và listener:\nresource \u0026#34;aws_security_group\u0026#34; \u0026#34;alb_sg\u0026#34; { name = \u0026#34;${var.project_name}-alb-sg\u0026#34; description = \u0026#34;ALB security group\u0026#34; vpc_id = module.vpc.vpc_id ingress { from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } tags = var.default_tags } resource \u0026#34;aws_lb\u0026#34; \u0026#34;app_alb\u0026#34; { name = \u0026#34;${var.project_name}-alb\u0026#34; load_balancer_type = \u0026#34;application\u0026#34; security_groups = [aws_security_group.alb_sg.id] subnets = module.vpc.public_subnets tags = var.default_tags } resource \u0026#34;aws_lb_target_group\u0026#34; \u0026#34;backend_tg\u0026#34; { name = \u0026#34;${var.project_name}-tg\u0026#34; port = 3000 protocol = \u0026#34;HTTP\u0026#34; vpc_id = module.vpc.vpc_id target_type = \u0026#34;ip\u0026#34; health_check { path = \u0026#34;/api/ping\u0026#34; healthy_threshold = 2 unhealthy_threshold = 2 matcher = \u0026#34;200\u0026#34; interval = 30 timeout = 5 } tags = var.default_tags } resource \u0026#34;aws_lb_listener\u0026#34; \u0026#34;http\u0026#34; { load_balancer_arn = aws_lb.app_alb.arn port = 80 protocol = \u0026#34;HTTP\u0026#34; default_action { type = \u0026#34;forward\u0026#34; target_group_arn = aws_lb_target_group.backend_tg.arn } } ALB configuration bao gồm:\nSecurity Group: Cho phép inbound HTTP (port 80) từ mọi nơi, outbound tất cả traffic Load Balancer: Application Load Balancer type, deploy trên public subnets Target Group: Listen trên port 3000 (backend port), health check tại /api/ping Listener: HTTP listener trên port 80, forward traffic đến target group Health check path /api/ping cần được implement trong code Backend để ALB có thể verify tasks đang healthy.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": "Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\nLà cảm giác được học hỏi, tiếp thu kiến thức mới mỗi ngày,\nĐiều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau?\nCó thể chuẩn bị trước một lộ trình học tập chi tiết hơn ngay từ tuần đầu (ví dụ: tuần 1-2 học tool gì, tuần 3-4 làm task nào…), để các bạn mới không bị “ngợp” trong 1-2 tuần đầu.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\nChắc chắn là có. Ở đây không chỉ dạy kỹ thuật mà còn dạy cách làm việc, cách tư duy giải quyết vấn đề.\nĐề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập?\nCần thống nhất trong cách đưa ra quyết định của các mentor với nhau.\nBạn có muốn tiếp tục chương trình này trong tương lai?\nChắc chắn có.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-infra-terraform/5.3.8-iam/",
	"title": "Cấu hình IAM Roles và Policies",
	"tags": [],
	"description": "",
	"content": "Tạo IAM Roles và Policies File alb.tf định nghĩa ALB, security groups, target group và listener:\ndata \u0026#34;aws_iam_policy_document\u0026#34; \u0026#34;lambda_assume_role\u0026#34; { statement { effect = \u0026#34;Allow\u0026#34; principals { type = \u0026#34;Service\u0026#34; identifiers = [ \u0026#34;lambda.amazonaws.com\u0026#34;, \u0026#34;ecs-tasks.amazonaws.com\u0026#34;, ] } actions = [\u0026#34;sts:AssumeRole\u0026#34;] } } resource \u0026#34;aws_iam_role\u0026#34; \u0026#34;lambda_exec\u0026#34; { name = \u0026#34;${var.project_name}-lambda-exec\u0026#34; assume_role_policy = data.aws_iam_policy_document.lambda_assume_role.json tags = var.default_tags } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;lambda_basic_execution\u0026#34; { role = aws_iam_role.lambda_exec.name policy_arn = \u0026#34;arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\u0026#34; } data \u0026#34;aws_iam_policy_document\u0026#34; \u0026#34;lambda_app\u0026#34; { statement { effect = \u0026#34;Allow\u0026#34; actions = [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, ] resources = [\u0026#34;${aws_s3_bucket.uploads.arn}/*\u0026#34;] } } resource \u0026#34;aws_iam_policy\u0026#34; \u0026#34;lambda_app\u0026#34; { name = \u0026#34;${var.project_name}-lambda-app\u0026#34; policy = data.aws_iam_policy_document.lambda_app.json } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;lambda_app\u0026#34; { role = aws_iam_role.lambda_exec.name policy_arn = aws_iam_policy.lambda_app.arn } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;ecs_task_execution\u0026#34; { role = aws_iam_role.lambda_exec.name policy_arn = \u0026#34;arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\u0026#34; } IAM role được cấu hình với:\nAssume Role Policy: Cho phép ECS tasks và Lambda assume role này AWSLambdaBasicExecutionRole: Managed policy cho CloudWatch Logs permissions AmazonECSTaskExecutionRolePolicy: Managed policy cho ECR pull permissions Custom Policy: Permissions cho S3 (get/put/delete object) Role này được sử dụng làm cả execution role và task role cho ECS tasks.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-infra-terraform/5.3.9-cloudwatch-ecsservices/",
	"title": "Cấu hình CloudWatch Logs &amp; ECS Service",
	"tags": [],
	"description": "",
	"content": "CloudWatch Logs \u0026amp; ECS Service CloudWatch Log Group (trong ecs-service.tf):\nresource \u0026#34;aws_cloudwatch_log_group\u0026#34; \u0026#34;backend\u0026#34; { name = \u0026#34;/ecs/${var.project_name}-backend\u0026#34; retention_in_days = 14 tags = var.default_tags } Tên log group: /ecs/${var.project_name}-backend Retention: 14 ngày (tự động xóa để tiết kiệm chi phí) ECS Task \u0026amp; Service (trong ecs-service.tf):\nresource \u0026#34;aws_security_group\u0026#34; \u0026#34;ecs_service_sg\u0026#34; { name = \u0026#34;${var.project_name}-ecs-sg\u0026#34; description = \u0026#34;ECS service security group\u0026#34; vpc_id = module.vpc.vpc_id ingress { from_port = 3000 to_port = 3000 protocol = \u0026#34;tcp\u0026#34; security_groups = [aws_security_group.alb_sg.id] } egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } tags = var.default_tags } resource \u0026#34;aws_cloudwatch_log_group\u0026#34; \u0026#34;backend\u0026#34; { name = \u0026#34;/ecs/${var.project_name}-backend\u0026#34; retention_in_days = 14 tags = var.default_tags } resource \u0026#34;aws_ecs_task_definition\u0026#34; \u0026#34;backend\u0026#34; { family = \u0026#34;${var.project_name}-backend-task\u0026#34; requires_compatibilities = [\u0026#34;FARGATE\u0026#34;] network_mode = \u0026#34;awsvpc\u0026#34; cpu = \u0026#34;512\u0026#34; memory = \u0026#34;1024\u0026#34; # Có thể tạo riêng 1 role ECS task; tạm tái sử dụng role Lambda để đơn giản execution_role_arn = aws_iam_role.lambda_exec.arn task_role_arn = aws_iam_role.lambda_exec.arn container_definitions = jsonencode([ { name = \u0026#34;backend\u0026#34; image = \u0026#34;${aws_ecr_repository.backend.repository_url}:${var.backend_image_tag}\u0026#34; essential = true portMappings = [ { containerPort = 3000 protocol = \u0026#34;tcp\u0026#34; } ] environment = [ { name = \u0026#34;NODE_ENV\u0026#34; value = var.node_env }, { name = \u0026#34;MONGODB_URI\u0026#34; value = var.mongodb_uri }, { name = \u0026#34;UPLOADS_BUCKET_NAME\u0026#34; value = var.uploads_bucket_name }, { name = \u0026#34;JWT_SECRET\u0026#34; value = var.jwt_secret }, { name = \u0026#34;JWT_EXPIRES_IN\u0026#34; value = var.jwt_expires_in }, { name = \u0026#34;JWT_REFRESH_EXPIRES_IN\u0026#34; value = var.jwt_refresh_expires_in }, { name = \u0026#34;EMAIL_HOST\u0026#34; value = var.email_host }, { name = \u0026#34;EMAIL_PORT\u0026#34; value = tostring(var.email_port) }, { name = \u0026#34;EMAIL_SECURE\u0026#34; value = tostring(var.email_secure) }, { name = \u0026#34;EMAIL_USER\u0026#34; value = var.email_user }, { name = \u0026#34;EMAIL_PASS\u0026#34; value = var.email_pass }, ] logConfiguration = { logDriver = \u0026#34;awslogs\u0026#34; options = { awslogs-group = aws_cloudwatch_log_group.backend.name awslogs-region = var.aws_region awslogs-stream-prefix = \u0026#34;backend\u0026#34; } } } ]) tags = var.default_tags } resource \u0026#34;aws_ecs_service\u0026#34; \u0026#34;backend\u0026#34; { name = \u0026#34;${var.project_name}-ecs-service\u0026#34; cluster = aws_ecs_cluster.backend.id task_definition = aws_ecs_task_definition.backend.arn desired_count = 1 launch_type = \u0026#34;FARGATE\u0026#34; network_configuration { subnets = module.vpc.public_subnets security_groups = [aws_security_group.ecs_service_sg.id] assign_public_ip = true } load_balancer { target_group_arn = aws_lb_target_group.backend_tg.arn container_name = \u0026#34;backend\u0026#34; container_port = 3000 } depends_on = [aws_lb_listener.http] tags = var.default_tags } Security Group: chỉ cho phép traffic từ ALB vào port 3000; outbound mở để ECS task truy cập internet/AWS services. Task Definition: Fargate, 0.5 vCPU, 1GB RAM; dùng chung role lambda_exec cho execution/task; inject toàn bộ env cho DB, S3, JWT, email. Logging: awslogs driver, log group /ecs/${var.project_name}-backend, stream prefix backend. Service: chạy 1 task, gắn ALB target group trên port 3000, cấp public IP qua public subnets. Phụ thuộc: service phụ thuộc listener HTTP của ALB (depends_on = [aws_lb_listener.http]). "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-infra-terraform/5.3.10-budgets/",
	"title": "Cấu hình AWS Budgets",
	"tags": [],
	"description": "",
	"content": "Tạo AWS Budgets bill-n-cost.tf cấu hình nhiều ngân sách để giám sát chi phí:\n# Ngân sách tháng cho toàn bộ services resource \u0026#34;aws_budgets_budget\u0026#34; \u0026#34;monthly_cost\u0026#34; { name = \u0026#34;monthly-cost\u0026#34; limit_amount = 120 budget_type = \u0026#34;COST\u0026#34; limit_unit = \u0026#34;USD\u0026#34; time_unit = \u0026#34;MONTHLY\u0026#34; notification { comparison_operator = \u0026#34;GREATER_THAN\u0026#34; threshold = 80 threshold_type = \u0026#34;PERCENTAGE\u0026#34; notification_type = \u0026#34;ACTUAL\u0026#34; subscriber_email_addresses = var.budget_alert_emails } } # Ngân sách ngày cho toàn bộ services resource \u0026#34;aws_budgets_budget\u0026#34; \u0026#34;daily_cost\u0026#34; { name = \u0026#34;daily-cost\u0026#34; limit_amount = 3 budget_type = \u0026#34;COST\u0026#34; limit_unit = \u0026#34;USD\u0026#34; time_unit = \u0026#34;DAILY\u0026#34; notification { comparison_operator = \u0026#34;GREATER_THAN\u0026#34; threshold = 80 threshold_type = \u0026#34;PERCENTAGE\u0026#34; notification_type = \u0026#34;ACTUAL\u0026#34; subscriber_email_addresses = var.budget_alert_emails } } # Ngân sách theo service (daily \u0026amp; monthly) resource \u0026#34;aws_budgets_budget\u0026#34; \u0026#34;cost_by_service\u0026#34; { name = \u0026#34;cost-by-service\u0026#34; limit_amount = 0.5 budget_type = \u0026#34;COST\u0026#34; limit_unit = \u0026#34;USD\u0026#34; time_unit = \u0026#34;DAILY\u0026#34; } resource \u0026#34;aws_budgets_budget\u0026#34; \u0026#34;cost_by_service_monthly\u0026#34; { name = \u0026#34;cost-by-service-monthly\u0026#34; limit_amount = 5 budget_type = \u0026#34;COST\u0026#34; limit_unit = \u0026#34;USD\u0026#34; time_unit = \u0026#34;MONTHLY\u0026#34; } # Ngân sách theo region resource \u0026#34;aws_budgets_budget\u0026#34; \u0026#34;cost_by_region\u0026#34; { name = \u0026#34;cost-by-region\u0026#34; budget_type = \u0026#34;COST\u0026#34; limit_unit = \u0026#34;USD\u0026#34; limit_amount = 150 time_unit = \u0026#34;MONTHLY\u0026#34; notification { comparison_operator = \u0026#34;GREATER_THAN\u0026#34; threshold = 100 threshold_type = \u0026#34;PERCENTAGE\u0026#34; notification_type = \u0026#34;ACTUAL\u0026#34; subscriber_email_addresses = var.budget_alert_emails } } Monthly: 120 USD, cảnh báo 80% (toàn bộ services). Daily: 3 USD, cảnh báo 80% (toàn bộ services). By service: 0.5 USD/day, 5 USD/month (theo từng service). By region: 150 USD/month, cảnh báo 100%. Email nhận cảnh báo: var.budget_alert_emails. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-infra-terraform/5.3.11-vpc/",
	"title": "Cấu hình VPC",
	"tags": [],
	"description": "",
	"content": "Tạo VPC File vpc.tf định nghĩa một VPC cơ bản với các subnet công cộng:\nmodule \u0026#34;vpc\u0026#34; { source = \u0026#34;terraform-aws-modules/vpc/aws\u0026#34; version = \u0026#34;~\u0026gt; 5.0\u0026#34; name = \u0026#34;${var.project_name}-vpc\u0026#34; cidr = \u0026#34;10.0.0.0/16\u0026#34; azs = [\u0026#34;ap-southeast-2a\u0026#34;, \u0026#34;ap-southeast-2b\u0026#34;] public_subnets = [\u0026#34;10.0.101.0/24\u0026#34;, \u0026#34;10.0.102.0/24\u0026#34;] private_subnets = [\u0026#34;10.0.1.0/24\u0026#34;, \u0026#34;10.0.2.0/24\u0026#34;] enable_nat_gateway = false enable_vpn_gateway = false tags = var.default_tags } Tạo VPC với module terraform-aws-modules/vpc/aws giúp đơn giản hóa việc cấu hình mạng. Trong ví dụ này, chúng ta tạo một VPC với CIDR 10.0.0.0/16, hai Availability Zones, và các subnet công cộng. Các tham số như enable_nat_gateway và enable_vpn_gateway được đặt thành false để giữ cấu hình đơn giản. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/workshop-template/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]